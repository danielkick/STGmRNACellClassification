---
title: "Analysis for Northcutt et al. 2018"
author: "Daniel R. Kick"
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=F)

tic <- Sys.time()

# General + Plotting ----------------------------------------------------------
library(tidyverse) #ggplot2, purrr, dplyr, tidyr mostly
library(cowplot) #clean up ggplots ands plotgrid
library(M3Drop) #for BrenneckeGetVariableGenes


# install_github("vqv/ggbiplot")
library(ggbiplot)

# Cluster Determination -------------------------------------------------------
library(factoextra) #for fviz_nbclust
library(NbClust) #to automate cluster determination for each dataset
# Clustering ------------------------------------------------------------------
library(BiocGenerics) # This is used for clustering assessment
library(pvclust) #for pvclust
library(dendextend) #for cutree coloring dendrograms
library(NMF) #used for calculating purity metric
library(clues) #used for calculating concurrance metrics

# Classification --------------------------------------------------------------
  #install.packages("caret", dependencies = c("Depends", "Suggests"))
library(caret) # for preProcess and supervised ML models

library(devtools)
devtools::load_all() #needed to have access to SNN.R
```

```{r eval=FALSE, include=FALSE}
#general

library("rgl") #for 3d plots


#used in unsupervised ml
library("corrplot") #for corrplot
library("heatmap3") #for heatmap3
library("cluster") #for pam and clusplot
#library(sscClust) #Can't get installed
# For clustering comparison

library("Rtsne") #for t-SNE

#used supervised ml

library("matrixStats")
library("M3Drop")
#devtools::load_all()

#from esynvmod
library("extrafont") #help with plotting
#font_import()
#loadfonts(device = "win")
library("lemon") #clean up ggplots
library("ggthemes") #color plots



# 
# 
# library("tidyverse") #ggplot2, purrr, dplyr, tidyr mostly
# library("cowplot") #clean up ggplots ands plotgrid
# library("M3Drop") #for BrenneckeGetVariableGenes
# 
# # Cluster Determination -------------------------------------------------------
# library("factoextra") #for fviz_nbclust
# library("NbClust") #to automate cluster determination for each dataset
# # Clustering ------------------------------------------------------------------
# library("BiocGenerics") # This is used for clustering assessment
# library("pvclust") #for pvclust
# library("dendextend") #for cutree coloring dendrograms
# library("NMF") #used for calculating purity metric
# library("clues") #used for calculating concurrance metrics
# 
# # Classification --------------------------------------------------------------
#   #install.packages("caret", dependencies = c("Depends", "Suggests"))
# library("caret") # for preProcess and supervised ML models
# 
# library("devtools")
```




# Setup
## Control what code blocks are run.

```{r Conrol block}
#What should happen to plots?
#save
#show

#What should happen to output data?
#save
#show

#Which sections should be run?
# Visualizations
## Cluster.estimation ====
run.estimate <- T
save.estimate <- T
load.estimate <- T

# Clustering
# Classification

run.snn.cliq <- TRUE # SNN Cliq depend on python. This script is written to work on windows and hasn't been tested on Unix/Macos. Needed file is in ../Py. At the point of writing, python version 3.7 has beed tested.
write.to.dir <- paste0(getwd(), "/inst/extdata/output_files/")
use.seed <- 8743436
```

```{r eval=FALSE, include=FALSE}
#28,459 
M <- read.csv(paste0(getwd(),"/inst/extdata/scSeq.csv"), row.names = "id", header = TRUE)
N <- read.csv("C:/Users/drk8b9/Desktop/singleCell_kallisto_counts.csv", row.names = "id", header = TRUE)

dim(M)
M <- as.matrix(M) 
M[rowSums(M) != 0, ] %>% dim()
M <- t(M)
predict(preProcess(M, method = c("zv")), M) %>% dim()
predict(preProcess(M, method = c("nzv")), M) %>% dim()

dim(N)
N <- as.matrix(N) 
N[rowSums(N) != 0, ] %>% dim()
N <- t(N)
predict(preProcess(N, method = c("zv")), N) %>% dim()
predict(preProcess(N, method = c("nzv")), N) %>% dim()

```


## Load Datasets:
```{r Pull in datasets}
# Read in all data ------------------------------------------------------------
mrna_raw <- read.csv(paste0(getwd(),"/inst/extdata/RTqPCR.csv"), row.names = "Sample", header = TRUE) %>% as.data.frame()

seq_raw <- read.csv(paste0(getwd(),"/inst/extdata/scSeq.csv"), row.names = "id", header = TRUE) %>% t() %>% as.data.frame()

k2 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto0.2.csv"), header = F) %>% as.data.frame()
k05 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto0.05.csv"), header = F) %>% as.data.frame()




# Transform RTqPCR data -------------------------------------------------------
mrna_raw <- predict(preProcess(mrna_raw, method = c("medianImpute", "zv")), mrna_raw)
mrna_target <- predict(preProcess(mrna_raw, method = c("center", "scale")), mrna_raw)

# mrna_cell <- mrna_raw[,-1]
# mrna_cell <- as.data.frame(t(mrna_cell))
# mrna_cell <- predict(preProcess(mrna_cell, method = c("center", "scale")), mrna_cell)
# mrna_cell <- cbind(Cell = mrna_raw$Cell, as.data.frame(t(mrna_cell)))

# Transform Seq data ----------------------------------------------------------

seq_raw <- predict(preProcess(seq_raw, method = c("zv")), seq_raw)
seq_target <- predict(preProcess(seq_raw, method = c("center", "scale")), seq_raw)

# # center and scale by cell
# seq_cell <- seq_raw
# seq_cell <- as.data.frame(t(seq_cell))
# seq_cell <- predict(preProcess(seq_cell, method = c("center", "scale")), seq_cell)
# seq_cell <- as.data.frame(t(seq_cell))

# Set up a cell id vector to use in each dataframe
split.names <- rownames(seq_raw) %>% strsplit("[.]")
split.names <- unlist(split.names)
Cell.ids <- split.names[seq(1, to = length(split.names), by = 2)]
# Give each dataset a `Cell` column
seq_raw <- cbind(Cell = Cell.ids, seq_raw)
seq_target <- cbind(Cell = Cell.ids, seq_target)
# seq_cell <- cbind(Cell = Cell.ids, seq_cell)


## PCA ========================================================================
# PCA can capture most of the variance

# #because the full seq is too much to work with locally:
# seq_pca <- prcomp(seq_cell[,-1], scale = FALSE)
# #fviz_eig(seq_pca, addlabels = TRUE)
# #factoextra::get_eigenvalue(seq_pca)
# 
# seq_pca <- cbind(seq_cell$Cell, as.data.frame(seq_pca$x))
# seq_pca <- rename(seq_pca, Cell = `seq_cell$Cell`)

## HVG ========================================================================
#TODO determine if HVG is useful or if we should drop it.
# temp <- seq_raw[,-1]
# temp <- t(temp)
# 
# x.data <- rowMeans(temp)
# y.data <- matrixStats::rowVars(temp)
# 
# ggplot()+geom_point(aes(x = log10(x.data), y = log10(y.data)), shape = 1)
# 
# #https://hemberg-lab.github.io/scRNA.seq.course/biological-analysis.html#feature-selection
# 
# Brennecke_HVG <- M3Drop::BrenneckeGetVariableGenes(
#   temp,
#   fdr = 0.01,
#   minBiolDisp = 0.5
# )
# 
# temp <- temp[(rownames(temp) %in% Brennecke_HVG), ]
# temp <- temp %>% t()
# seq_hvg <- cbind(Cell = seq_raw[,1], as.data.frame(temp))

## Generate reduced seq sets ==================================================
seq_raw_k05 <- seq_raw[, k05$V1]
seq_target_k05 <- seq_target[, k05$V1]
# seq_cell_k05 <- seq_cell[, k05$V1]

seq_raw_k2 <- seq_raw[, k2$V1]
seq_target_k2 <- seq_target[, k2$V1]
# seq_cell_k2 <- seq_cell[, k2$V1]
```

## Reduced the RNA-Seq Data's dimensions
```{r}
# TODO determine if HVG is useful or if we should drop it.
temp <- seq_raw[,-1]
temp <- t(temp)

# x.data <- rowMeans(temp)
# y.data <- matrixStats::rowVars(temp)
# 
# ggplot()+geom_point(aes(x = log10(x.data), y = log10(y.data)), shape = 1)

#https://hemberg-lab.github.io/scRNA.seq.course/biological-analysis.html#feature-selection

Brennecke_HVG <- M3Drop::BrenneckeGetVariableGenes(
  temp,
  fdr = 0.2, #changed to .2 to match the FDR Dr. HH provided us
  minBiolDisp = 0.5
)

seq_hvg <- seq_raw[, names(seq_raw) %in% c("Cell", Brennecke_HVG)]

# temp <- temp[(rownames(temp) %in% Brennecke_HVG), ]
# temp <- temp %>% t()
# seq_hvg <- cbind(Cell = seq_raw[,1], as.data.frame(temp))

seq_hvg_target <- predict(preProcess(seq_hvg, method = c("center", "scale")), seq_hvg)



library(edgeR)
# https://combine-australia.github.io/RNAseq-R/06-rnaseq-day1.html
y <- seq_raw[,2:ncol(seq_raw)]
y <- as.matrix(y)
y <- t(y)

# Get log2 counts per million
logcounts <- cpm(y,log=TRUE)
# Check distributions of samples using boxplots
# boxplot(logcounts, xlab="", ylab="Log2 counts per million",las=2)
# # Let's add a blue horizontal line that corresponds to the median logCPM
# abline(h=median(logcounts),col="blue")
# title("Boxplots of logCPMs (unnormalised)")

# We estimate the variance for each row in the logcounts matrix
var_genes <- apply(logcounts, 1, var)
# head(var_genes)

# Get the gene names for the top 500 most variable genes
select_var <- names(sort(var_genes, decreasing=TRUE))[1:2000]
# head(select_var)

seq_h2k <- seq_raw[, names(seq_raw) %in% c("Cell", select_var)]
seq_h2k_target <- predict(preProcess(seq_h2k, method = c("center", "scale")), seq_h2k)
```

## Add PCA transforms
```{r}
mk_pca_transform <- function(d = input.df){
  Cell <- d[,1]
  d <- prcomp(d[,-1], scale = FALSE)
  d <- cbind(Cell, d$x)
  return(d)
}

pca_mrna <- mk_pca_transform(d = mrna_raw)
pca_mrna_target <- mk_pca_transform(d = mrna_target)
pca_seq <- mk_pca_transform(d = seq_raw)
pca_seq_target <- mk_pca_transform(d = seq_target)
pca_hvg <- mk_pca_transform(d = seq_hvg)
pca_hvg_target <- mk_pca_transform(d = seq_hvg_target)
pca_h2k <- mk_pca_transform(d = seq_h2k)
pca_h2K_target <- mk_pca_transform(d = seq_h2k_target)

```


```{r round count data}
#make sure data is in the right type
mrna_raw[, 2:ncol(mrna_raw)] <- round(mrna_raw[, 2:ncol(mrna_raw)])
seq_hvg[, 2:ncol(seq_hvg)] <- round(seq_hvg[, 2:ncol(seq_hvg)])
seq_h2k[, 2:ncol(seq_h2k)] <- round(seq_h2k[, 2:ncol(seq_h2k)])
```



# Visualizations of the data


code from djs to adapt
```{r eval=FALSE, include=FALSE}
# list.files("S:/Data_Daniel/ActiveProjects/stgmcc/inst/extdata/")
# 
# "Preamp_vs_noamp.csv"                   
# "STG-4genesSeqComp-qPCR.csv"             
# "STG-4genesSeqComp-SEQ.csv"             
# # "STG_LC_Absolute_Counts_allSTG-GM2f.csv"
# 
# 
# 
# 
data1 <- read.csv("S:/Data_Daniel/ActiveProjects/stgmcc/inst/extdata/Preamp_vs_noamp.csv", header = TRUE)

names(data1) <- c("Target", "Sample", "Unamp", "Amp")

plt1 <- ggplot(data1, aes(x = Unamp, y = Amp, color = Target))+
geom_point(size = 5, shape = 1, na.rm = TRUE)+
labs(x = "Unamplified Cq", y = "Amplified Cq")+
xlim(29,37)+
ylim(17,27)
#geom_smooth(method=lm)
plot(plt1)


plt2 <- ggplot(data1, aes(x = Unamp, y = Amp))+
geom_point(size = 5, shape = 1, na.rm = TRUE)+
labs(x = "Unamplified Cq", y = "Amplified Cq")+
xlim(29,37)+
ylim(17,27)+

geom_smooth(method=lm)
plot(plt2)

corrPRE <- cor(data1[,3:4], use="complete.obs", method="pearson")


data2 <- read.csv("S:/Data_Daniel/ActiveProjects/stgmcc/inst/extdata/STG-4genesSeqComp-qPCR.csv", header = TRUE)
data3 <- read.csv("S:/Data_Daniel/ActiveProjects/stgmcc/inst/extdata/STG-4genesSeqComp-SEQ.csv", header = TRUE)
data3 <- data3[, !(names(data3) %in% c("KCNK1",  "NMDA2B", "ChAT", "vAChT"))]
names(data2)[1] <- names(data3)[1] <- "Cell"
names(data3) <- c("Cell", "Sample", "vAChT", "NMDA2B", "ChAT", "KCNK1")

data2$type <- "PCR"
data3$type <- "SEQ"

data4 <- full_join(data2, data3)
# data4 <- gather(data4, "target", "Count", 3:6)
# data4 <- data4[, -2]

# ggplot(data4, aes(x = type, y = Count))+
#   geom_point(size = 5, shape = 1, na.rm = TRUE)+
#   facet_grid(Cell ~ target)
#   # labs(x = "Unamplified Cq", y = "Amplified Cq")+
#   # xlim(29,37)+
#   # ylim(17,27)+
#   # geom_smooth(method=lm)


plot_grid(plotlist = list(
  ggplot(data4[data4$type == "SEQ", ], aes(x = Cell, y = ChAT, fill = Cell)) +
    geom_boxplot() +
    geom_point(size = 2, shape = 1, na.rm = TRUE) + theme(legend.position = "")+     scale_fill_brewer(type = "qual", palette = 3),
  ggplot(data4[data4$type == "PCR", ], aes(x = Cell, y = ChAT, fill = Cell)) +
    geom_boxplot() +
    geom_point(size = 2, shape = 1, na.rm = TRUE) + theme(legend.position = "")+     scale_fill_brewer(type = "qual", palette = 3),
  ggplot(data4[data4$type == "SEQ", ], aes(x = Cell, y = vAChT, fill = Cell)) +
    geom_boxplot() +
    geom_point(size = 2, shape = 1, na.rm = TRUE) + theme(legend.position = "")+     scale_fill_brewer(type = "qual", palette = 3),
  ggplot(data4[data4$type == "PCR", ], aes(x = Cell, y = vAChT, fill = Cell)) +
    geom_boxplot() +
    geom_point(size = 2, shape = 1, na.rm = TRUE) + theme(legend.position = "")+     scale_fill_brewer(type = "qual", palette = 3),
  ggplot(data4[data4$type == "SEQ", ], aes(x = Cell, y = NMDA2B, fill = Cell)) +
    geom_boxplot() +
    geom_point(size = 2, shape = 1, na.rm = TRUE) + theme(legend.position = "")+     scale_fill_brewer(type = "qual", palette = 3),
  ggplot(data4[data4$type == "PCR", ], aes(x = Cell, y = NMDA2B, fill = Cell)) +
    geom_boxplot() +
    geom_point(size = 2, shape = 1, na.rm = TRUE) + theme(legend.position = "")+     scale_fill_brewer(type = "qual", palette = 3),
  ggplot(data4[data4$type == "SEQ", ], aes(x = Cell, y = KCNK1, fill = Cell)) +
    geom_boxplot() +
    geom_point(size = 2, shape = 1, na.rm = TRUE) + theme(legend.position = "")+     scale_fill_brewer(type = "qual", palette = 3),

  ggplot(data4[data4$type == "PCR", ], aes(x = Cell, y = KCNK1, fill = Cell)) +
    geom_boxplot() +
    geom_point(size = 2, shape = 1, na.rm = TRUE) + theme(legend.position = "")+    scale_fill_brewer(type = "qual", palette = 3)
), nrow = 2, ncol = 4)



data4 <- data4[,-2]
for (cell in unique(data4$Cell)){
  for (i in 2:5){
  data4[data4$type == "PCR" & data4$Cell == cell, i] <- mean(data4[data4$type == "PCR" & data4$Cell == cell, i], na.rm = T)#/sd(data4[data4$type == "PCR" & data4$Cell == cell, i], na.rm = T)

  data4[data4$type == "SEQ" & data4$Cell == cell, i] <- mean(data4[data4$type == "SEQ" & data4$Cell == cell, i], na.rm = T)#/sd(data4[data4$type == "SEQ" & data4$Cell == cell, i], na.rm = T)
  }
}
data4 <- data4[!duplicated(data4),]
data4.seq <- data4[data4$type == "SEQ", ]
data4.pcr <- data4[data4$type == "PCR", ]

data4.ratio <- data4.pcr[,-6]
data4.ratio[, 2:5] <- data4.seq[, 2:5] / data4.pcr[, 2:5]


ggplot(gather(data4.ratio, target, seqTOpcr, 2:5), 
       aes(x = Cell, y = seqTOpcr, group = Cell, color = Cell))+
  geom_point(size = 2)+
  facet_grid(.~target)+
  scale_color_brewer(type = "qual", palette = 3)



data5 <- gather(data4, target, mean, 2:5)
ggplot(data5, aes(x = type, y = mean, group = Cell, color = Cell))+
  geom_line(size = 2)+
  facet_grid(.~target)+
  scale_color_brewer(type = "qual", palette = 3)


data6 <- spread(data5, type, mean)
ggplot(data6, aes(x = PCR, y = SEQ, color = Cell))+
  geom_smooth(method = lm)+
  geom_point(size = 2)+
  facet_grid(.~Cell)+
  scale_color_brewer(type = "qual", palette = 3)


ggplot(data6, aes(x = PCR, y = SEQ))+
  geom_smooth(method = lm)+
  geom_point(aes(color = Cell), size = 2)+
  #facet_grid(.~Cell)+
  scale_color_brewer(type = "qual", palette = 3)

```



```{r eval=FALSE, include=FALSE}
# Heatmaps ----
## qRT-PCR ====
d <- mrna_target
d <- gather(d, key = "Transcript", value = "Count", 2:ncol(d))

ggplot(d, aes(x = Transcript, y = Cell))+
  geom_tile(aes(fill = Count))+
  scale_fill_gradient(low = "white", high = "steelblue")

## RNA-Seq ====
d <- seq_target
d <- gather(d, key = "Transcript", value = "Count", 2:ncol(d))

ggplot(d, aes(x = Transcript, y = Cell))+
  geom_tile(aes(fill = Count))+
  scale_fill_gradient(low = "white", high = "steelblue")


d <- seq_hvg_target
d <- gather(d, key = "Transcript", value = "Count", 2:ncol(d))

ggplot(d, aes(x = Transcript, y = Cell))+
  geom_tile(aes(fill = Count))+
  scale_fill_gradient(low = "white", high = "steelblue")


# Scree plots ----
## qRT-PCR ====
d <- mrna_raw
d.id <- d[,1]
d <- prcomp(d[,-1], scale = FALSE)
fviz_eig(d, addlabels = TRUE)
factoextra::get_eigenvalue(d)
# factoextra::fviz_pca_biplot(d)

# ggbiplot(d, obs.scale = 1, var.scale = 1,
#   groups = mrna_target$Cell, ellipse = TRUE, circle = TRUE) +
#   scale_color_discrete(name = '') +
#   theme(legend.direction = 'horizontal', legend.position = 'top')
# 
# library(car)
# d <- cbind(d.id, d$x)
# fm <- lm(d.id ~ ., data = as.data.frame(d))
# d.anova <- Anova(fm)
# d.anova$`Pr(>F)`

# library(dunn.test)
# dunn.test::dunn.test(d.anova$`Pr(>F)`, g=NA, method = "sidak", label = T, wrap = F, alpha = 0.05)
# TODO: I've left off here to complete H's suggestion we need to
# TODO: get significant PCs for each dataset
# TODO: wrtie out a table of the top 10 or so genes that differentiate cell types


# d <- mrna_raw
# d.id <- d[,1]
# d <- prcomp(d[,-1], scale = TRUE)
# fviz_eig(d, addlabels = TRUE)
# factoextra::get_eigenvalue(d)
# 
# 
# ## RNA-Seq ====
# d <- seq_raw
# d.id <- d[,1]
# d <- prcomp(d[,-1], scale = FALSE)
# fviz_eig(d, addlabels = TRUE)
# factoextra::get_eigenvalue(d)
# 
# 
# d <- seq_raw
# d.id <- d[,1]
# d <- prcomp(d[,-1], scale = TRUE)
# fviz_eig(d, addlabels = TRUE)
# factoextra::get_eigenvalue(d)






```

# Cluster Estimation 
```{r automated approach}
# ## using NbClust to churn out predictions =====================================
# automated_clust_k <- function(current.df = use.input.df[, -1], current.max.k = max.k) {
#   # nb <- NbClust(use.input.df, diss="NULL", distance = "euclidean",
#   #        min.nc=2, max.nc=max.k, method = "kmeans",
#   #        index = "alllong", alphaBeale = 0.1)
#   # hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])))
# 
#   # nb <- NbClust(use.input.df[, -1], distance = "euclidean", min.nc=2, max.nc=max.k, method = "ward.D", index = "all")
#   # hist(nb$Best.nc[1,],
#   #     breaks = max(na.omit(nb$Best.nc[1,])))
# 
#   avail.methods <- c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans") #TODO this is fucking up the seq data. at least one of the methods (maybe "single"?) is breaking the loop
#   avail.distances <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
#   #Ideally this should be vectorized to speed up the process
#   cluster.estimates <- list()
#   for (use.method in avail.methods) {
#     list1 <- list()
#     for (use.distance in avail.distances) {
#       nb <- NbClust(current.df,
#         distance = use.distance,
#         min.nc = 2, max.nc = current.max.k,
#         method = use.method, index = "all" #FIXME shouldn't method be use.method?
#       )
#       list1[[length(list1) + 1]] <- nb$Best.nc["Number_clusters", ]
#     }
#     cluster.estimates[[length(cluster.estimates) + 1]] <- list1
#   }
# 
#   new.df <- as.data.frame(matrix(nrow = length(avail.methods) * length(avail.distances), ncol = 28))
#   new.df.names <- c("Method", "Distance", names(cluster.estimates[[1]][[1]]))
#   names(new.df) <- new.df.names
#   for (i in seq_along(avail.methods)) {
#     for (j in seq_along(avail.distances)) {
#       row.num.to.use <- length(avail.methods) * (i - 1) + j
#       len.obj <- length(cluster.estimates[[i]][[j]])
# 
#       new.df[row.num.to.use, 1] <- avail.methods[i]
#       new.df[row.num.to.use, 2] <- avail.distances[j]
# 
#       new.df[row.num.to.use, seq(from = 3, length.out = len.obj)] <- cluster.estimates[[i]][[j]]
#     }
#   }
#   return(new.df)
# }
```

```{r iteratively call function}
# # Initial Setup ---------------------------------------------------------------
# #use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw
# #name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
# #max.k <- (nrow(use.input.df)/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.
# 
# use.datasets <- list(mrna_raw, mrna_target, mrna_cell, 
#                      seq_pca, seq_target, seq_cell, seq_hvg,
#                      seq_raw_k05, seq_target_k05, seq_cell_k05,
#                      seq_raw_k2, seq_target_k2, seq_cell_k2
#                      )
# use.names <- list("mrna_raw", "mrna_target", "mrna_cell", 
#                      "seq_pca", "seq_target", "seq_cell", "seq_hvg", 
#                      "seq_raw_k05", "seq_target_k05", "seq_cell_k05", 
#                      "seq_raw_k2", "seq_target_k2", "seq_cell_k2")
# # guess_clust_list <- list()
# # for (i in seq(from = 1, to = length(use.datasets))){
# #   max.k <- (nrow(use.datasets[[i]])/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.
# #   guess_clust_list[[length(guess_clust_list)+1]] <- try(
# #     automated_clust_k(current.df = use.datasets[[i]][,-1], current.max.k = max.k)
# #   )
# # }
# 
# # TODO uncomment to get csv 
# # walk(seq_along(guess_clust_list), function(x){
# #   write.csv(guess_clust_list[[x]], file = paste0(write.to.dir, use.names[[x]], "_kEstimate.csv"))
# # })
# 
# 
# # estimated time to run
# # ((4.004993/8)*702)/60
# # 5.857302 hours
# 
# avail.methods <- c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans") #TODO this is fucking up the seq data. at least one of the methods (maybe "single"?) is breaking the loop
# avail.distances <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# 
# tic <- Sys.time()
# output.list <- list()
# for (i in seq_along(use.datasets)){
#   max.k <- (nrow(use.datasets[[i]])/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.
#   
#   list_j <- list()
# 
#   for (j in seq_along(avail.methods)){
#     list_k <- list()
#     
#     for (k  in seq_along(avail.distances)){
#       # i = j = k = 1
#       current.df <- use.datasets[[i]][,-1]
#       use.method <- avail.methods[j]
#       use.distance <- avail.distances[k]
#       
#       list_k[[k]] <-  try(
#         NbClust(current.df,
#         distance = use.distance,
#         min.nc = 2, max.nc = max.k,
#         method = use.method, index = "all"
#         )$Best.nc["Number_clusters", ]
#       )
#     }
#     list_j[[j]] <- list_k
#   }
#   output.list[[i]] <- list_j
# }
# print(Sys.time()-tic)
# 
# 
# #saveRDS(output.list, file = paste0(write.to.dir,"clustering_list.RDS"))
```

```{r}
# #backup <- output.list
# 
# i = 1
# j = 1
# k = 1
# 
# 
# 
# # for (i in seq_along(use.datasets)){
# for (i in 1:3){
#   
#   df_j <- data.frame(matrix(NA, nrow = 0, ncol = 5))
#   names(df_j) <- c("k.method", "method", "data", "distance", "prediction")
# for (j in seq_along(avail.methods)){
# 
#   df_k <- as.data.frame(matrix(NA, nrow = 26, ncol = length(avail.distances)))
#   names(df_k) <- avail.distances
# for (k in seq_along(avail.distances)){
#   print(paste0(as.character(i), "-",
#                as.character(j), "-",
#                as.character(k)))
#   df_k[, k] <- try(
#     output.list[[i]][[j]][[k]] %>% as.data.frame()
#     )
#   
# }
#   df_k$k.method <- c("KL", "CH", "Hartigan", "CCC", "Scott", 
#                    "Marriot", "TrCovW", "TraceW", "Friedman", "Rubin", 
#                    "Cindex", "DB", "Silhouette", "Duda", "PseudoT2", 
#                    "Beale", "Ratkowsky", "Ball", "PtBiserial", "Frey", 
#                    "McClain", "Dunn", "Hubert", "SDindex", "Dindex", 
#                    "SDbw")
#   # distance is already taken care of with naming
#   df_k$method <- avail.methods[[j]]
#   df_k$data <- use.names[[i]]
#   df_k_long <- gather(df_k, key = distance, value = prediction, 1:6)
# 
#   df_j <-   base::rbind(df_j, df_k_long)
# }
# 
# }
# 
# ggplot(df_j, aes(x = method, y = prediction, color = (df_j$prediction == 11)))+
#   geom_point(position = position_jitter(width = 0.1, height = 0.0),
#              alpha = 0.5)+
#   #geom_violin()+
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))+
#   theme(legend.position = "")+
#   facet_grid(.~distance)
# 
# 
# 
# ggplot(df_j, aes(x = method, y = k.method, color = (df_j$prediction == 11)))+
#   geom_point(shape = 15, size = 2)+
#   #geom_violin()+
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))+
#   theme(legend.position = "")+
#   facet_grid(.~distance)
# 
# ggplot(df_j, aes(x = method, y = k.method, color = as.factor(prediction)))+
#   geom_point(data = df_j[df_j$prediction == 11, ], aes(x = method, y = k.method),
#              #shape = 0, 
#              shape = 15, alpha = 1,
#              size = 2, color = "black")+
#   geom_point(shape = 15, 
#              size = 2)+
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))+
#   facet_grid(.~distance)
# 
# 
# ggplot(df_j, aes(x = method, y = k.method, color = as.factor(prediction)))+
#   geom_point(data = df_j[df_j$prediction == 11, ], aes(x = method, y = k.method),
#              #shape = 0, 
#              shape = 15, alpha = 1,
#              size = 2, color = "black")+
#   theme_dark()+
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))+
#   facet_grid(.~distance)
# 
# ggplot(df_j, aes(x = prediction))+
#   geom_histogram(binwidth = 1)+
#   geom_histogram(data = df_j[df_j$prediction == 11, ], 
#                  aes(x = prediction), 
#                  binwidth = 1, 
#                  fill = "red")
# 
# 

```

I'm packageing the above to (idealy) get a clean way to process and visualize each of these

```{r}
# 
# use.datasets <- list(mrna_raw, mrna_target, 
#                      # seq_pca, seq_target, 
#                      seq_hvg, seq_hvg_target)
# 
# use.names <- list("mrna_raw", "mrna_target", 
#                   # "seq_pca", "seq_target",  
#                    "seq_hvg", "seq_hvg_target")
# 
# 
# 
# explict_iter_nbclust <- function(
#   use.datasets = mrna_raw, #note this should only ever be one value
#   avail.methods = c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"),
#   avail.distances = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# ){
#   tic <- Sys.time()
#   output.list <- list()
#     max.k <- (nrow(use.datasets)/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.
#     
#     list_j <- list()
#   
#     for (j in seq_along(avail.methods)){
#       list_k <- list()
#       
#       for (k  in seq_along(avail.distances)){
#         # i = j = k = 1
#         current.df <- use.datasets[,-1]
#         use.method <- avail.methods[j]
#         use.distance <- avail.distances[k]
#         
#         print(paste0(use.method, "-",
#                      use.distance))
#         
#         list_k[[k]] <-  try(
#           NbClust(current.df,
#           distance = use.distance,
#           min.nc = 2, max.nc = max.k,
#           method = use.method, index = "all"
#           )$Best.nc["Number_clusters", ]
#         )
#       }
#       list_j[[j]] <- list_k
#     }
#   return(list_j)
#     
#   print(Sys.time()-tic)
# }
# 
# # d01 <- 
# # explict_iter_nbclust(
# #   use.datasets = mrna_raw,
# #   avail.methods = c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"),
# #   avail.distances = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# # )
# # 
# # d02 <- 
# # explict_iter_nbclust(
# #   use.datasets = mrna_target,
# #   avail.methods = c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"),
# #   avail.distances = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# # )
# # 
# # d03 <- 
# # explict_iter_nbclust(
# #   use.datasets = mrna_cell,
# #   avail.methods = c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"),
# #   avail.distances = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# # )
# 
# # for PCA claims there are too many missing values. Is this because some are near zero? That doe
# 
# explict_iter_nbclust(
#   use.datasets = seq_hvg_target[,-1],
#   avail.methods = c("ward.D"),
#   avail.distances = c("euclidean")
#   )
# 
# for (i in c("kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew", "friedman", "rubin", "cindex", "db", "silhouette", "duda", "pseudot2", "beale", "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw")){
# try(
# NbClust(seq_hvg[,-1],
#           distance = "euclidean",
#           min.nc = 1, max.nc = 12,
#           method = "ward.D", index = i
#           ) 
# )
# }
# 
# d04 <- 
# explict_iter_nbclust(
#   use.datasets = seq_pca,
#   avail.methods = c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"),
#   avail.distances = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# )
# 
# d05 <- 
# explict_iter_nbclust(
#   use.datasets = seq_target,
#   avail.methods = c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"),
#   avail.distances = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# )
# 
# d06 <- 
# explict_iter_nbclust(
#   use.datasets = seq_cell,
#   avail.methods = c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"),
#   avail.distances = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# )
# 
# d07 <- 
# explict_iter_nbclust(
#   use.datasets = seq_hvg,
#   avail.methods = c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"),
#   avail.distances = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
# )
#                      
# 
# 
# 

```

```{r eval=FALSE, include=FALSE}
library(optCluster)
# avail.methods <- c("agnes", "clara", "diana", "fanny", "hierarchical", "kmeans", "model", "pam", "som", "sota", "em.nbinom", "da.nbinom", "sa.nbinom", "em.poisson", "da.poisson", "sa.poisson")

# #All methods here seem  to work fine

# avail.methods.count <- c("em.nbinom", "da.nbinom", "sa.nbinom", "em.poisson", "da.poisson","sa.poisson")
# 
# input.df <- seq_hvg[,-1]
# min.k <- 2
# max.k <- 10
# 
# for (i in avail.methods.count){
#   print(i)
#   try(
#     print(optCluster(input.df,
#                    seq(from = min.k, to = max.k, by = 1),
#                    clMethods = i,
#                    countData = T,
#                    validation = "internal", #internal", "stability", "biological", "all"
#                    hierMethod = "ward", #"average", "complete", "single", and "ward"
#                    annotation = NULL, #Used in biological validation
#                    clVerbose = FALSE, #If TRUE, the progress of cluster validation will be produced as output.
#                    rankMethod = "CE", #cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
#                    distance = "Spearman", #The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
#                    importance = NULL, 
#                    rankVerbose = FALSE))
#   )
# }

avail.methods.conti <- c("agnes", "clara", "diana", "fanny", "hierarchical", "kmeans", "model", "pam", "som", "sota")

  
input.df <- seq_hvg_target[,-1]
min.k <- 2
max.k <- 10
conti.block <- expand.grid(method = avail.methods.conti,
            hier.method = c("average", "complete", "single", "ward"))
conti.block$worked <- 0

for(i in 1:nrow(conti.block)){
  optCluster(input.df,
             seq(from = min.k, to = max.k, by = 1),
             clMethods = avail.methods.conti[1],
             countData = F,
             validation = "internal", #internal", "stability", "biological", "all"
             hierMethod = as.character(conti.block[i, "hier.method"]), #"average", "complete", "single", and "ward"
             annotation = NULL, #Used in biological validation
             clVerbose = FALSE, #If TRUE, the progress of cluster validation will be produced as output.
             rankMethod = "CE", #cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
             distance = "Spearman", #The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
             importance = NULL, 
             rankVerbose = FALSE) %>% print()
}







# for a dataset
# find what methods work
# then run all of them together to
oo <- optCluster(input.df,
             seq(from = min.k, to = max.k, by = 1),
             clMethods = avail.methods.conti[1],
             countData = F,
             validation = "internal", #internal", "stability", "biological", "all"
             hierMethod = as.character(conti.block[i, "hier.method"]), #"average", "complete", "single", and "ward"
             annotation = NULL, #Used in biological validation
             clVerbose = FALSE, #If TRUE, the progress of cluster validation will be produced as output.
             rankMethod = "CE", #cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
             distance = "Spearman", #The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
             importance = NULL, 
             rankVerbose = FALSE)
pp <- optCluster(input.df,
             seq(from = min.k, to = max.k, by = 1),
             clMethods = avail.methods.conti[2],
             countData = F,
             validation = "internal", #internal", "stability", "biological", "all"
             hierMethod = as.character(conti.block[i, "hier.method"]), #"average", "complete", "single", and "ward"
             annotation = NULL, #Used in biological validation
             clVerbose = FALSE, #If TRUE, the progress of cluster validation will be produced as output.
             rankMethod = "CE", #cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
             distance = "Spearman", #The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
             importance = NULL, 
             rankVerbose = FALSE)
qq <- optCluster(input.df,
             seq(from = min.k, to = max.k, by = 1),
             clMethods = avail.methods.conti[1:2],
             countData = F,
             validation = "internal", #internal", "stability", "biological", "all"
             hierMethod = as.character(conti.block[i, "hier.method"]), #"average", "complete", "single", and "ward"
             annotation = NULL, #Used in biological validation
             clVerbose = FALSE, #If TRUE, the progress of cluster validation will be produced as output.
             rankMethod = "CE", #cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
             distance = "Spearman", #The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
             importance = NULL, 
             rankVerbose = FALSE)

RankAggreg::RankAggreg(
                        # x = as.matrix(oo@ranksWeights$ranks[3, 1:9]), #appears to be using silhouette
                        # k = 9, 
                        # weights = as.matrix(oo@ranksWeights$weights[3, 1:9]), 
                       x = oo@ranksWeights$ranks,
                       k = 9, #nList,
                       weights = oo@ranksWeights$weights,
                       method = "CE", 
                       distance = "Spearman", 
                       importance = NULL, 
                       verbose = F)

oo@clVal
oo@rankAgg
oo@ranksWeights

d <- data.frame(
  ranks = c(oo@ranksWeights$ranks[3,], pp@ranksWeights$ranks[3,]),
  weights = c(oo@ranksWeights$weights[3,], pp@ranksWeights$weights[3,])
  
)

d[base::order(d$weights, decreasing = T), ]$ranks












  

```

```{r eval=FALSE, include=FALSE}
avail.methods.conti <- c("agnes", "clara", "diana", #"fanny", 
                         "hierarchical.average", "hierarchical.complete", "hierarchical.single", "hierarchical.ward", 
                         "kmeans", "model", "pam"#, #"som", 
                         #"sota"
                         )

input.df <- seq_hvg_target[,-1]
min.k <- 2
max.k <- 10

# output.list <- list()
output.list <- vector("list", length = length(avail.methods.conti))
for (i in seq_along(avail.methods.conti)){
  print(avail.methods.conti[i])
  
  if (avail.methods.conti[i] == "hierarchical.average"){
    use.clMethods <- "hierarchical"
    use.hierMethod <- "average"
  }else if(avail.methods.conti[i] == "hierarchical.complete"){
    use.clMethods <- "hierarchical"
    use.hierMethod <- "complete"
  }else if(avail.methods.conti[i] == "hierarchical.single"){
    use.clMethods <- "hierarchical"
    use.hierMethod <- "single"    
  }else if(avail.methods.conti[i] == "hierarchical.ward"){
    use.clMethods <- "hierarchical"
    use.hierMethod <- "ward"
  }else{
    use.clMethods <- avail.methods.conti[i]
    use.hierMethod <- "average"
  }
  temp.out <- NA
  temp.out <- optCluster(input.df,
             seq(from = min.k, to = max.k, by = 1),
             clMethods = use.clMethods,
             countData = F,
             validation = "internal", #internal", "stability", "biological", "all"
             hierMethod = use.hierMethod, #"average", "complete", "single", and "ward"
             annotation = NULL, #Used in biological validation
             clVerbose = FALSE, #If TRUE, the progress of cluster validation will be produced as output.
             rankMethod = "CE", #cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
             distance = "Spearman", #The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
             importance = NULL, 
             rankVerbose = FALSE)
  
  if (typeof(temp.out) == "S4"){
    output.list[[i]]$ranks <- temp.out@ranksWeights$ranks
    output.list[[i]]$weights <- temp.out@ranksWeights$weights
  
  }else if (typeof(temp.out) == "logical"){
    output.list[[i]]$ranks <- NA
    output.list[[i]]$weights <- NA
  }else{
    warning(paste0("At i=", as.character(i), " temp.out is neither type S4 nor logical."))
  }
  
}

#Make sure that the hierarchical values get the appropriate method

for (i in seq_along(avail.methods.conti)){
  if (stringr::str_starts(avail.methods.conti[i], "hierarchical")){
    add.to.name <- stringr::str_remove(avail.methods.conti[i], "hierarchical.")
    for (j in seq(from = 1, to =  length(output.list[[i]][[1]][3, ]))){
      temp.str <- stringr::str_split(output.list[[i]][[1]][3, j], "-")
      output.list[[i]][[1]][3, j] <- paste0(as.character(temp.str[[1]][1]), ".", add.to.name, "-", as.character(temp.str[[1]][2]))
    }
  }
}

# Prepare output
d <- list()
for (i in seq_along(output.list)){
  d$ranks <- c(d$ranks,  output.list[[i]][[1]][3, ])
  d$weights <- c(d$weights,  output.list[[i]][[2]][3, ])
}

d <- as.data.frame(d)
d <- separate(d, ranks, c("Method", "k"), "-")
d$k <- as.numeric(d$k)

  
library(ggstance) # for position_dodgev
ggplot(d, aes(x = weights, y = k))+
  geom_hline(yintercept = seq(0,10), color = "gray")+
  
  geom_line(aes(color = Method), position = ggstance::position_dodgev(height = 0.5))+
  # geom_line(aes(group = Method, color = Method), position = position_jitter(width = 0, height = 0.2))+
  geom_point(aes(color = Method), position = ggstance::position_dodgev(height = 0.5), alpha = 0.7, size = 2)+
  geom_hline(yintercept = 4, linetype = 2)+
  coord_cartesian(ylim = c(0, 10))+
  theme(legend.position = "bottom")


# ggplot(d, aes(x = weights, y = k))+
#   geom_hline(yintercept = seq(0,10), color = "gray")+
#   
#   geom_line(aes(color = Method), position = ggstance::position_dodgev(height = 0.5))+
#   # geom_line(aes(group = Method, color = Method), position = position_jitter(width = 0, height = 0.2))+
#   geom_point(aes(color = Method), position = ggstance::position_dodgev(height = 0.5), alpha = 0.7, size = 2)+
#   geom_hline(yintercept = 4, linetype = 2)+
#   coord_cartesian(ylim = c(2, 6))+
#   theme(legend.position = "bottom")


out2 <- optCluster(input.df,
             seq(from = min.k, to = max.k, by = 1),
             clMethods = c("agnes", "clara", "diana", 
                         "hierarchical", 
                         "kmeans", "model", "pam"),
             countData = F,
             validation = "internal", #internal", "stability", "biological", "all"
             hierMethod = "ward", #"average", "complete", "single", and "ward"
             annotation = NULL, #Used in biological validation
             clVerbose = FALSE, #If TRUE, the progress of cluster validation will be produced as output.
             rankMethod = "CE", #cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
             distance = "Spearman", #The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
             importance = NULL, 
             rankVerbose = FALSE)
out2
```


```{r eval=FALSE, include=FALSE}
input.df = pca_hvg
min.k = 2
max.k = 10
clMethods = c("agnes", "clara", "diana", 
                         "hierarchical", 
                         "kmeans", "model", "pam")
is.count = F
  
out2 <- optCluster(input.df,
             seq(from = min.k, to = max.k, by = 1),
             clMethods =clMethods,
             countData = is.count,
             validation = "internal", #internal", "stability", "biological", "all"
             hierMethod = "ward", #"average", "complete", "single", and "ward"
             annotation = NULL, #Used in biological validation
             clVerbose = FALSE, #If TRUE, the progress of cluster validation will be produced as output.
             rankMethod = "CE", #cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
             distance = "Spearman", #The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
             importance = NULL, 
             rankVerbose = FALSE)
out2
```






```{r get clusters for each dataset}
# # Test of tryCatch
# mylist <- list(1, 2, 3, "e", 4)
# outlist <- mylist
# for(i in seq_along(mylist)){
# 
#     tryCatch({
#       print(mylist[[i]]/2)
#       outlist[[i]] <- (mylist[[i]]/2)
#     }, error=function(e){
#       print("e")
#       print(unlist(outlist))
#       outlist[[i]] <<- "!"
#       print(unlist(outlist))
#       } )
# }
# mylist
# outlist %>% unlist()

# input.df = pca_hvg
test_clMethods <- function(input.df = mrna_raw[, 2:5],
                           min.k = 2,
                           max.k = 10,
                           is.count = T) {
  if (is.count) {
    clMethods <- c("em.nbinom", "da.nbinom", "sa.nbinom", "em.poisson", "da.poisson", "sa.poisson")
  } else if (!(is.count)) {
    clMethods <- c("agnes", "clara", "diana", "fanny", "hierarchical", "kmeans", "model", "pam", "som", "sota")
  } else {
    warning(paste0("is.count is not of type logical!"))
  }
  outMethods <- clMethods

  for (i in clMethods) {
    # print(i)
    tryCatch({
      optCluster(input.df,
        seq(from = min.k, to = max.k, by = 1),
        clMethods = i,
        countData = is.count,
        validation = "internal", # internal", "stability", "biological", "all"
        hierMethod = "ward", # "average", "complete", "single", and "ward"
        annotation = NULL, # Used in biological validation
        clVerbose = FALSE, # If TRUE, the progress of cluster validation will be produced as output.
        rankMethod = "CE", # cross-entropy Monte Carlo algorithm ("CE") or Genetic algorithm ("GA"). Selection of only one method is allowed
        distance = "Spearman", # The two available methods are the weighted Spearman footrule distance ("Spearman") or the weighted Kendall’s tau distance ("Kendall"). Selection of only one distance is allowed.
        importance = NULL,
        rankVerbose = FALSE
      )
    }, error = function(e) {
      print(paste0(
        "Error for ", i
      ))
      outMethods <<- outMethods[!(outMethods == i)]
    })
  }
  return(outMethods)
}

if (run.estimate){


data.sets <- list(
  mrna_raw,
  mrna_target,
  pca_mrna,
  pca_mrna_target,
  
  seq_hvg,
  seq_hvg_target,
  seq_h2k,
  seq_h2k_target,
  
  pca_seq,
  pca_seq_target,
  pca_hvg,
  pca_hvg_target,
  pca_h2k,
  pca_h2K_target
)

data.options <- data.frame(
  name = c(
  "mrna_raw",
  "mrna_target",
  "pca_mrna",
  "pca_mrna_target",
  
  "seq_hvg",
  "seq_hvg_target",
  "seq_h2k",
  "seq_h2k_target",
  
  "pca_seq",
  "pca_seq_target",
  "pca_hvg",
  "pca_hvg_target",
  "pca_h2k",
  "pca_h2K_target"
  ), 
  min.k = rep(2, times = length(data.sets)), 
  max.k = c(
    rep(32, times = 4),
    rep(10, times = 10)
  ),
  is.count = c(
    T,F,F,F,
    T,F,T,F,
    F,F,F,F,F,F
  )
)

## Figure out which clMethods to use for each dataset

clMethods.list <- list(length(data.sets))
for (i in seq_along(data.sets)){
  clMethods.list[[i]] <- test_clMethods(
    input.df = data.sets[[i]][,-1],
    min.k = data.options[i, "min.k"],
    max.k = data.options[i, "max.k"],
    is.count = data.options[i, "is.count"]
    )
}

## Find optimal cluster for each

# clMethods.list[[1]] <- "all" #TODO

optCluster.list <- list(length(data.sets))
for (i in seq_along(data.sets)){
  tic <- Sys.time()
optCluster.list[[i]] <- 
  optCluster(
      obj = data.sets[[i]][,-1], 
      nClust = seq(from = data.options[i, "min.k"], to = data.options[i, "max.k"], by = 1),
      clMethods = clMethods.list[[i]], 
      countData = data.options[i, "is.count"],
      validation = "internal", #internal", "stability", "biological", "all"
      hierMethod = "ward", #"average", "complete", "single", and "ward"
      annotation = NULL, #Used in biological validation
      clVerbose = FALSE, 
      rankMethod = "CE", 
      distance = "Spearman", 
      importance = NULL, 
      rankVerbose = FALSE)

}




  
}

if (save.estimate){
  
  saveRDS(clMethods.list, file = paste0(write.to.dir,"clMethods.list.RDS"))
  saveRDS(optCluster.list, file = paste0(write.to.dir,"optCluster.list.RDS"))
  
}

if (load.estimate){
  
}


# 
# out1 <- optCluster(
#       obj = mrna_raw[1:20,2:4], 
#       nClust = seq(from = data.options[i, "min.k"], to = 13, by = 1),
#       clMethods = c("da.nbinom", "sa.nbinom"), 
#       countData = T,
#       validation = "internal", #internal", "stability", "biological", "all"
#       hierMethod = "ward", #"average", "complete", "single", and "ward"
#       annotation = NULL, #Used in biological validation
#       clVerbose = FALSE, 
#       rankMethod = "CE", 
#       distance = "Spearman", 
#       importance = NULL, 
#       rankVerbose = FALSE)
# 
# 
# out1.a <- out1@rankAgg$top.list %>% as.data.frame()
# names(out1.a) <- "output"
# out1.a$rank <- 1:nrow(out1.a)
# 
# 
# d <- separate(out1.a, output, c("Method", "k"), "-")
# d$k <- as.numeric(d$k)
# 
# ggplot(d, aes(x = rank, y = k))+
#   lemon::geom_pointline()+
#   geom_point(aes(color = Method))

```




```{r}

```






# Unsupervised Machine Learning
```{r automate clustering}
# Methods ---------------------------------------------------------------------

## k means ====================================================================
get_kmeans_clustering <- function(input.df = mrna_raw,
                                  target.nclusters = 11) {
  kmeans.m <- kmeans(input.df[, -1], centers = 11)
  return(kmeans.m$cluster)
}

## H cluster ==================================================================
#https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html #great reference!
get_hierarchical_clustering <- function(input.df = mrna_target,
                                        target.nclusters = 12,
                                        use.method.dist = "cor",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10) {
  temp <- input.df[, -1]

  temp.clust <- pvclust(t(temp),
    method.dist = use.method.dist,
    method.hclust = use.method.hclust,
    nboot = use.nboot
  )
  temp.clust <- as.dendrogram(temp.clust$hclust)

  assignment <- cutree(temp.clust, k = target.nclusters)[order.dendrogram(temp.clust)]

  return(assignment)
}
#hclust_methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")
#dist_methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", #"correlation", "uncentered")

## SNN-Cliq ===================================================================
#2 tuning parameters (k, distance)
get_SNN_clustering <- function(input.df = mrna_raw,
                               use.k = 3,
                               use.distance = "euclidean") {
  temp <- input.df[, -1]
  SNN(temp,
    outfile = paste0(getwd(), "/inst/extdata/output_files/temp_edges.txt"),
    k = use.k,
    distance = use.distance
  )

  if (Sys.info()['sysname'] == "Windows"){
    # in CMD run:
    # Py\Cliq.py -i inst\extdata\output_files\temp_edges.txt -o inst\extdata\output_files\temp_clust.txt
    shell("Py\\Cliq.py -i inst\\extdata\\output_files\\temp_edges.txt -o inst\\extdata\\output_files\\temp_clust.txt")
  } else if (Sys.info()['sysname'] == "Darwin"){
    warning("get_SNN_clustering() hasn't been checked on macos!")
    #TODO edit this to work on unix systems
    shell("Python3 Py/Cliq.py -i inst/extdata/output_files/temp_edges.txt -o inst/extdata/output_files/temp_clust.txt")
    
  } else {
    warning("get_SNN_clustering() hasn't been checked on linux!")
    #TODO edit this to work on unix systems
    shell("Python3 Py/Cliq.py -i inst/extdata/output_files/temp_edges.txt -o inst/extdata/output_files/temp_clust.txt")
  }

  assignment <- read.table(paste0(getwd(), "/inst/extdata/output_files/temp_clust.txt"),
    header = FALSE, sep = "", dec = "."
  )
  return(assignment)
}

## Evaluate clustering performance ==========================================
get_cluster_comparisons <- function(reference.clustering = mrna_raw$Cell,
                                    generated.clustering) {
  if (length(reference.clustering) != length(generated.clustering)) {
    warning("Input vectors are not of the same length!")
  } else {
    # reference.clustering = mrna_raw$Cell
    # generated.clustering = kmeans.m$cluster
    output <- array(0, dim = 6)

    reference.clustering <- as.numeric(reference.clustering) %>% as.factor()
    generated.clustering <- as.numeric(generated.clustering) %>% as.factor()

    output <- NMF::purity(reference.clustering, generated.clustering)
    names(output) <- "Purity"
    # Get a lot of concurrance measures
    # https://davetang.org/muse/2017/09/21/adjusted-rand-index/
    output <- c(
      output,
      clues::adjustedRand(
        BiocGenerics::as.vector(reference.clustering),
        BiocGenerics::as.vector(generated.clustering)
      )
    )
    return(output)
  }
}

## sweep over free clustering parameters ======================================
evaluate_clust_params <- function(use.input.df = mrna_raw, # mrna_cell #mrna_target #mrna_raw
                                 #name.prefix = "raw_qpcr", # "cell_qpcr" #"target_qpcr" #"raw_qpcr"
                                 use.k.param.kmeans = c(11),
                                 use.k.param.hclust = c(11),
                                 use.k.param.snncliq = c(3:9) # number of neighbors to consider
) {

  # Generate Clusterings --------------------------------------------------------
  ## K Means Clustering =========================================================
  # use.k.param <- c(11)

  temp <- map(use.k.param.kmeans, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })

  param.combinations <- paste("K", as.character(
    rep(use.k.param.kmeans, each = length(use.k.param.kmeans))
  ), sep = ".")

  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations

  ## Hierarchical Clustering ====================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.hclust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df,
        target.nclusters = use.k.param.hclust,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = 10
      )
    })
  })

  param.combinations <- paste("H", as.character(
    rep(use.dist.methods, each = length(use.hclust.methods))
  ), as.character(
    rep(use.hclust.methods, times = length(use.dist.methods))
  ), sep = ".")

  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations
  ## SNN Clustering =============================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.k.param.snncliq, function(iter.k.param) {
      print(iter.dist)

      get_SNN_clustering(
        input.df = use.input.df,
        use.k = iter.k.param, # number of neigbhors should go up to 9 for scPCRc
        use.distance = iter.dist
      ) #
    })
  })

  param.combinations <- paste("SNN", as.character(
    rep(use.dist.methods, each = length(use.k.param.snncliq))
  ), as.character(
    rep(use.k.param.snncliq, times = length(use.dist.methods))
  ), sep = ".")


  SNN.clusters <- do.call(cbind.data.frame, temp)
  names(SNN.clusters) <- param.combinations

  # Evaluate and summarize clusters ---------------------------------------------
  ## Merge Data Frames ==========================================================
  all.clusters <- cbind(K.clusters, H.clusters) %>% cbind(SNN.clusters)
  # some clusterings fail and assing all values zero
  # Some have a TON of clusters
  num.clusters <- map(all.clusters, function(x) {
    print(max(x))
  }) %>% unlist() # get number of clusters in each group
  real.num <- use.input.df$Cell %>% as.numeric() %>% max()
  selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.

  all.clusters <- all.clusters[, selection.vector]
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(use.input.df$Cell), all.clusters[])

  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = use.input.df$Cell, generated.clustering = iter.param)
  })

  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)

  all.clusters.scores.long <- gather(all.clusters.scores, Metric, Value, 1:6)

  ## Return long version of scores ============================================
  return(list(all.clusters.scores, all.clusters.scores.long))
}
```

```{r}
#all.clusters.scores.long <- evaluate_clust_params(
#  use.input.df = mrna_raw, # mrna_cell #mrna_target #mrna_raw
#  use.k.param.kmeans = c(11),
#  use.k.param.hclust = c(11),
#  use.k.param.snncliq = c(3:9)
#)
#all.clusters.scores <- all.clusters.scores.long[[1]]

## Run for RTqPCR =============================================================
use.datasets <- list(mrna_raw, mrna_target, mrna_cell) # , mrna_target, mrna_cell, seq_pca, seq_target, seq_cell, seq_hvg)
use.names.1 <- list("mrna_raw", "mrna_target", "mrna_cell") #TODO
clust_score_list <- list()
for (i in seq_along(use.datasets)) {
  list.index <- length(clust_score_list) + 1
  clust_score_list[[list.index]] <- evaluate_clust_params(
    use.input.df = mrna_raw, # mrna_cell #mrna_target #mrna_raw
    # name.prefix = "raw_qpcr", # "cell_qpcr" #"target_qpcr" #"raw_qpcr"
    use.k.param.kmeans = c(11),
    use.k.param.hclust = c(11),
    use.k.param.snncliq = c(3:9)
  )[[1]]
}
## Repeat for seq =============================================================
use.datasets <- list(seq_pca, seq_target, seq_cell, seq_hvg, 
                     seq_raw_k05, seq_target_k05, seq_cell_k05, 
                     seq_raw_k2, seq_target_k2, seq_cell_k2) # , mrna_target, mrna_cell, seq_pca, seq_target, seq_cell, seq_hvg)
use.names.2 <- list("seq_pca", "seq_target", "seq_cell", "seq_hvg", 
                     "seq_raw_k05", "seq_target_k05", "seq_cell_k05", 
                     "seq_raw_k2", "seq_target_k2", "seq_cell_k2") #TODO

for (i in seq_along(use.datasets)) {
  list.index <- length(clust_score_list) + 1
  clust_score_list[[list.index]] <- evaluate_clust_params(
    use.input.df = mrna_raw, # mrna_cell #mrna_target #mrna_raw
    # name.prefix = "raw_qpcr", # "cell_qpcr" #"target_qpcr" #"raw_qpcr"
    use.k.param.kmeans = c(4),
    use.k.param.hclust = c(4),
    use.k.param.snncliq = c(3:9)
  )[[1]]
}
## Write out scores ===========================================================
use.names <- c(use.names.1, use.names.2)
walk(seq_along(use.names), function(x){
  write.csv(clust_score_list[[x]], file = paste0(write.to.dir, use.names[[x]], "_clustScore.csv"))
})
```


# Supervised Machine Learning
```{r}
#use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw

#name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
```

```{r Automate ML functions}
#Note: Must contain a column called "Cell"
run_supervised_models <- function(use.seed = 8743436,
                                  input.df = use.input.df,
                                  train.control = "cv" #loocv
                                  ){
if (train.control == "cv"){
  #use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)


#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA
set.seed(use.seed)
ldam <- train(
  Cell ~ . ,
  data = input.df,
  method = "lda",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

return(list(GLMNet=glmnetm,
                          kNN=knnm,
                          LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad,
                          SVM.Linear=svm.lin))
}else if(train.control == "loocv"){
#use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "LOOCV", verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)


#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "LOOCV", verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA
set.seed(use.seed)
ldam <- train(
  Cell ~ . ,
  data = input.df,
  method = "lda",
  trControl = trainControl(method = "LOOCV", verboseIter = TRUE)
)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "LOOCV", verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "LOOCV", verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "LOOCV", verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "LOOCV", verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "LOOCV", verboseIter = TRUE)
)

return(list(GLMNet=glmnetm,
                          kNN=knnm,
                          LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad,
                          SVM.Linear=svm.lin))
}else{
  warning("train.control is neither cv or loocv")
}
  
#return(list(knnm,ldam,nnmm,nnm,rfm,svm.rad,svm.lin))

}

```

```{r}
ml_models <- map(1:2, function(i){
  use.input.df <- list(
mrna_raw, mrna_target, 
pca_mrna, pca_mrna_target, 
pca_seq, pca_seq_target, 
pca_hvg, pca_hvg_target, 
seq_raw_k2, seq_target_k2, 
seq_raw_k05, seq_target_k05
  ) #seq_pca[, 1:38]
  #out <- run_supervised_models(use.seed = 8743436, input.df = use.input.df)
  run_supervised_models(use.seed = 8743436, input.df = use.input.df[[i]])
})
name.prefix <- c(
  "mrna_raw", "mrna_target", 
  "pca_mrna", "pca_mrna_target", 
  "pca_seq", "pca_seq_target", 
  "pca_hvg", "pca_hvg_target", 
  "seq_raw_k2", "seq_target_k2", 
  "seq_raw_k05", "seq_target_k05")

for(i in seq_along(ml_models)){

out <- ml_models[[i]]



rValues <- resamples(out)

#save the accuracies for future use
write.csv(as.data.frame(rValues$values),
          file = paste0(write.to.dir, name.prefix[[i]],"_model_accuracy.csv"),
          row.names = FALSE)

pdf(file = paste0(write.to.dir, name.prefix[i],"_Accuracy", ".pdf"))
  bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0,1))
  dev.off()

pdf(file = paste0(write.to.dir, name.prefix[i],"_Kappa", ".pdf"))
  bwplot(rValues, metric="Kappa", ylab = c("Models"), xlim = c(0,1))
  dev.off()
}
```

```{r}
toc <- Sys.time()
print(toc - tic)
save.image(file = paste0(write.to.dir, "session_post_ml.Rdata"))
```



Plot selected models
```{r}
#out <- ml_models[[2]]

#pdf(file = paste0(write.to.dir, "pcr_SVM", ".pdf"))
#  varImp(out$SVM.Linear, scale=TRUE) %>%plot()
#  dev.off()

#pdf(file = paste0(write.to.dir, "pcr_glmnet", ".pdf"))
#  varImp(out$GLMNet, scale=TRUE) %>%plot()
#  dev.off()
```

# Repeat with Seq
```{r}
all.dfs <- list(seq_raw, seq_target, seq_cell, seq_hvg)
all.prefixes <- c("raw_seq", "target_seq", "cell_seq", "hvg_seq")

all.dfs <- list(seq_hvg)
all.prefixes <- c("hvg_seq")

for (JJ in seq_along(all.dfs)) {
  if (length(all.dfs) != length(all.prefixes)) {
    warning("Dfs and Names of inequal length!")
  }
  # Data Setup ------------------------------------------------------------------
  use.input.df <- all.dfs[[JJ]]
  name.prefix <- all.prefixes[JJ]

  # Perform clusterings ---------------------------------------------------------
  ## K Means Clustering =========================================================
  use.k.param <- c(4)

  temp <- map(use.k.param, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })

  param.combinations <- paste("K", as.character(
    rep(use.k.param, each = length(use.k.param))
  ), sep = ".")

  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations

  ## Hierarchical Clustering ====================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.hclust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df,
        target.nclusters = 4,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = 10
      )
    })
  })


  param.combinations <- paste("H", as.character(
    rep(use.dist.methods, each = length(use.hclust.methods))
  ), as.character(
    rep(use.hclust.methods, times = length(use.dist.methods))
  ), sep = ".")

  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations
  ## SNN Clustering =============================================================

  use.k.param <- c(3:8) # 8 is the nubmer of the least common cell present
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.k.param, function(iter.k.param) {
      print(iter.dist)

      get_SNN_clustering(
        input.df = use.input.df,
        use.k = iter.k.param, #
        use.distance = iter.dist
      ) #
    })
  })

  param.combinations <- paste("SNN", as.character(
    rep(use.dist.methods, each = length(use.k.param))
  ), as.character(
    rep(use.k.param, times = length(use.dist.methods))
  ), sep = ".")


  SNN.clusters <- do.call(cbind.data.frame, temp)
  names(SNN.clusters) <- param.combinations



  # Figure and table write out --------------------------------------------------
  ## Merge Data Frames ==========================================================
  all.clusters <- cbind(K.clusters, H.clusters) %>% cbind(SNN.clusters) # TODO add SCRATTCH
  # some clusterings fail and assing all values zero
  # Some have a TON of clusters
  num.clusters <- map(all.clusters, function(x) {
    print(max(x))
  }) %>% unlist() # get number of clusters in each group
  real.num <- use.input.df$Cell %>% as.numeric() %>% max()
  selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.

  all.clusters <- all.clusters[, selection.vector]
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(use.input.df$Cell), all.clusters[])

  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = use.input.df$Cell, generated.clustering = iter.param)
  })

  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)

  all.clusters.scores.long <- gather(all.clusters.scores, Metric, Value, 1:6)

  ## Make plots of scores =======================================================

  score.list <- map(1:6, function(current.col) {
    # metric.labels <- c("Purity", "Rand", "HA", "MA", "FM", "Jaccard")
    metric.labels <- c("Purity", "Rand index", "Hubert and Arabie's ARI", "Morey and Agresti's ARI", "Fowlkes and Mallows's index", "Jaccard index")
    ggplot(all.clusters.scores, aes(x = Clustering, y = all.clusters.scores[, current.col])) +
      geom_point(size = 3, aes(color = all.clusters.scores[, current.col])) +
      scale_color_continuous(low = "steelblue", high = "firebrick") +
      geom_segment(aes(
        x = Clustering,
        xend = Clustering,
        y = 0,
        yend = all.clusters.scores[, current.col]
      )) +
      labs(y = metric.labels[current.col]) +
      theme(
        axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = ""
      )
  })

  # cowplot::plot_grid(plotlist = score.list)
  score.heatmap <- ggplot(all.clusters.scores.long, aes(x = Clustering, y = Metric)) +
    geom_tile(aes(fill = Value), color = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

  score.list[[length(score.list) + 1]] <- score.heatmap


  ## write out diagnostic plots =================================================

  walk(1:length(score.list), function(i) {
    plot.list <<- score.list

    ggsave(plot = plot.list[[i]], device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_", i, ".pdf"), width = 12.8, height = 8.04)
  })

  # clusters
  write.csv(all.clusters, file = paste0(write.to.dir, name.prefix, "_clusterings.csv"))
  # cluster scores
  write.csv(all.clusters.scores, file = paste0(write.to.dir, name.prefix, "_cluster_scores.csv"))
}
```
Once we know the best clusterings...seq
```{r plot best pcr, eval=FALSE}
## Plot the best scoring clusters =============================================

#for pcr best are h clust with correlation and ward.d2

#"E:/MolecularCellClassification/inst/extdata/output_files/hvg_seq_clusterings.csv"
r.df <- read.csv(paste0(write.to.dir, "raw_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.euclidean.ward.D2",
  "H.maximum.ward.D2",
  "H.manhattan.ward.D2",
  "H.minkowski.ward.D2"
)]
t.df <- read.csv(paste0(write.to.dir, "target_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.canberra.ward.D"
)]
c.df <- read.csv(paste0(write.to.dir, "cell_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.canberra.ward.D"
)]
h.df <- read.csv(paste0(write.to.dir, "hvg_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.correlation.mcquitty"
)]

names(r.df) <- c(
  "Cell.Type",
  "r.H.euclidean.ward.D2",
  "r.H.maximum.ward.D2",
  "r.H.manhattan.ward.D2",
  "r.H.minkowski.ward.D2"
)
names(t.df) <- c("Cell.Type", "t.H.canberra.ward.D")
names(c.df) <- c("Cell.Type", "c.H.canberra.ward.D")
names(h.df) <- c("Cell.Type", "h.H.correlation.mcquitty")

r.df$Cell.Index <- 1:nrow(r.df)
#best.clusters$cell.index <- 1:nrow(best.clusters)
best.clusters <- full_join(r.df, t.df) %>% full_join(c.df) %>% full_join(h.df)
best.clusters <- best.clusters %>% gather(Clustering, Group, names(best.clusters)[!(names(best.clusters) %in% c( "Cell.Index"))])

ggplot(best.clusters, aes(x=Clustering, y=Cell.Index, fill=as.factor(Group)))+
  geom_raster()+
  theme(axis.text.x=element_text(angle = 45, hjust=1), legend.position = "")

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr", "_best", ".pdf"), width = 12.8, height = 8.04)

## Plot heatmap ===============================================================
pdf(file = paste0(write.to.dir, "qpcr", "_heatmap", ".pdf"))
  heatmap3::heatmap3(mrna_raw[,-1], method = "ward.D2")
  dev.off()

## Plot dendrograms of best ===================================================
tree.0 <- pvclust(t(seq_target[,-1]),
    method.dist = "canberra",
    method.hclust = "ward.D",
    nboot = 100
  )$hclust %>% as.dendrogram() %>%
  dendextend::set("labels_cex", 1) %>%
  dendextend::color_branches(k = 4) %>%
  dendextend::set("labels_col", value = 1:4, k=4)
  #dendextend::rect.dendrogram(k=12) %>%
as.ggdend(tree.0)


tree.1 <- pvclust(t(seq_raw[,-1]),
    method.dist = "euclidean",
    method.hclust = "ward.D2",
    nboot = 100
  )$hclust %>% as.dendrogram() %>%
  dendextend::set("labels_cex", 1) %>%
  dendextend::color_branches(k = 4) %>%
  dendextend::set("labels_col", value = 1:4, k=4)
  #dendextend::rect.dendrogram(k=12) %>%
as.ggdend(tree.1)


tree.2 <- pvclust(t(seq_hvg[,-1]),
    method.dist = "correlation",
    method.hclust = "mcquitty",
    nboot = 100
  )$hclust %>% as.dendrogram() %>%
  dendextend::set("labels_cex", 1) %>%
  dendextend::color_branches(k = 4) %>%
  dendextend::set("labels_col", value = 1:4, k=4)
  #dendextend::rect.dendrogram(k=12) %>%
as.ggdend(tree.2)


ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr_raw", "_tree", ".pdf"), width = 12.8, height = 8.04)



```


```{r Show info to aid reproducibility}
sessionInfo()
```
