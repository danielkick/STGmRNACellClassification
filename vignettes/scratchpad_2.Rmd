---
title: "Untitled"
author: "Daniel R. Kick"
date: "September 21, 2018"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)

tic <- Sys.time()

# General + Plotting ----------------------------------------------------------
library(tidyverse) #ggplot2, purrr, dplyr, tidyr mostly
library(cowplot) #clean up ggplots ands plotgrid
library(lemon) #further clean up ggplots
library(M3Drop) #for BrenneckeGetVariableGenes

# Cluster Determination -------------------------------------------------------
library(factoextra) #for fviz_nbclust
library(NbClust) #to automate cluster determination for each dataset
library(proxy) #to generate similarity/distance matrices for correlation
# Clustering ------------------------------------------------------------------
library(BiocGenerics) # This is used for clustering assessment
library(pvclust) #for pvclust
library(dendextend) #for cutree coloring dendrograms
library(NMF) #used for calculating purity metric
library(clues) #used for calculating concurrance metrics

# Classification --------------------------------------------------------------
  #install.packages("caret", dependencies = c("Depends", "Suggests"))
library(caret) # for preProcess and supervised ML models

library(devtools)
source(paste0(getwd(),"/R/SNN.R"))
#devtools::load_all() #needed to have access to SNN.R
```

```{r eval=FALSE, include=FALSE}
#general

library(rgl) #for 3d plots


#used in unsupervised ml
library(corrplot) #for corrplot
library(heatmap3) #for heatmap3
library(cluster) #for pam and clusplot
#library(sscClust) #Can't get installed
# For clustering comparison

library(Rtsne) #for t-SNE

#used supervised ml

library(matrixStats)
library(M3Drop)
devtools::load_all()

#from esynvmod
library("extrafont") #help with plotting
#font_import()
loadfonts(device = "win")
library("lemon") #clean up ggplots
library("ggthemes") #color plots
```


```{r Show info to aid reproducibility}
sessionInfo()
```

# User set up -----------------------------------------------------------------
```{r Conrol block}
#What should happen to plots?
#save
#show

#What should happen to output data?
#save
#show


# SNN Cliq depend on python. This scritp is written to work on windows and hasn't been tested on Unix/Macos. Needed file is in ../Py. At the point of writing, python version 3.7 has beed tested and works
write.to.dir <- paste0(getwd(), "/inst/extdata/output_files/")
write.out.clusterings <- TRUE
write.out.classifications <- TRUE
write.out.cluster.estimates <- TRUE
use.seed <- 8743436
```

## our inputs: ================================================================
```{r Pull in datasets}
## Read in all data ===========================================================
k05 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto0.05.csv"), header = F) %>% as.data.frame()
k2 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto0.2.csv"), header = F) %>% as.data.frame()
mrna_raw <- read.csv(paste0(getwd(),"/inst/extdata/RTqPCR.csv"), row.names = "Sample", header = TRUE) %>% as.data.frame()
seq_raw <- read.csv(paste0(getwd(),"/inst/extdata/scSeq.csv"), row.names = "id", header = TRUE) %>% t() %>% as.data.frame()

## Transform RTqPCR data ======================================================
### Test optimal performance (median interpolate within transcript by cell type)

#################################### This is used for cluster estimation #################################### 
#If you want to see Which values are replaced, run "nans <- is.na(M)" before this code block and "M[nans]" after. Alternatively import dplyr and use setdiff()
M <- mrna_raw
print(paste(as.character(sum(is.na(M))), " NAs to remove"))
cell_types <- unique(M$Cell)
for (i in 1:length(cell_types)){
  for (ii in 2:ncol(M)){
    
    if (sum(is.na(M[M$Cell== cell_types[i], ii])) > 0){
      for (iii in 1:length(M[M$Cell== cell_types[i], ii])){
        if(is.na(M[M$Cell== cell_types[i], ii][iii]) == TRUE){
          M[M$Cell== cell_types[i], ii][iii] <- median(M[M$Cell== cell_types[i], ii], na.rm = TRUE)
        }
      }
    }
  }
}
if (sum(is.na(M) == 0)){
  print("NAs removed")
}
mrna_raw_optimal <- M
mrna_target_optimal <- predict(preProcess(mrna_raw_optimal, method = c("center", "scale")), mrna_raw_optimal)


### Test under expected conditions
mrna_raw <- predict(preProcess(mrna_raw, method = c("medianImpute", "zv")), mrna_raw)
mrna_target <- predict(preProcess(mrna_raw, method = c("center", "scale")), mrna_raw)

mrna_cell <- mrna_raw[,-1]
mrna_cell <- as.data.frame(t(mrna_cell))
mrna_cell <- predict(preProcess(mrna_cell, method = c("center", "scale")), mrna_cell)
mrna_cell <- cbind(Cell = mrna_raw$Cell, as.data.frame(t(mrna_cell)))

## Transform Seq data =========================================================
seq_raw <- predict(preProcess(seq_raw, method = c("zv")), seq_raw)
seq_target <- predict(preProcess(seq_raw, method = c("center", "scale")), seq_raw)
# center and scale by cell
seq_cell <- seq_raw
seq_cell <- as.data.frame(t(seq_cell))
seq_cell <- predict(preProcess(seq_cell, method = c("center", "scale")), seq_cell)
seq_cell <- as.data.frame(t(seq_cell))
# Set up a cell id vector to use in each dataframe
split.names <- rownames(seq_raw) %>% strsplit("[.]")
split.names <- unlist(split.names)
Cell.ids <- split.names[seq(1, to = length(split.names), by = 2)]
# Give each dataset a `Cell` column
seq_raw <- cbind(Cell = Cell.ids, seq_raw)
seq_target <- cbind(Cell = Cell.ids, seq_target)
seq_cell <- cbind(Cell = Cell.ids, seq_cell)

## PCA ========================================================================
# PCA can capture most of the variance
#because the full seq is too much to work with locally:
seq_pca <- prcomp(seq_cell[,-1], scale = FALSE)
#fviz_eig(seq_pca, addlabels = TRUE)
#factoextra::get_eigenvalue(seq_pca)
seq_pca <- cbind(seq_cell$Cell, as.data.frame(seq_pca$x))
seq_pca <- rename(seq_pca, Cell = `seq_cell$Cell`)

## HVG ========================================================================
temp <- seq_raw[,-1]
temp <- t(temp)
# x.data <- rowMeans(temp)
# y.data <- matrixStats::rowVars(temp)
# ggplot()+geom_point(aes(x = log10(x.data), y = log10(y.data)), shape = 1)
#https://hemberg-lab.github.io/scRNA.seq.course/biological-analysis.html#feature-selection
Brennecke_HVG <- M3Drop::BrenneckeGetVariableGenes(
  temp,
  fdr = 0.01,
  minBiolDisp = 0.5
)

temp <- temp[(rownames(temp) %in% Brennecke_HVG), ]
temp <- temp %>% t()
seq_hvg <- cbind(Cell = seq_raw[,1], as.data.frame(temp))

seq_target_hvg <- seq_target[, names(seq_target) %in% names(seq_hvg)]
seq_cell_hvg <- seq_cell[, names(seq_cell) %in% names(seq_hvg)]

## Generate reduced seq sets ==================================================
seq_raw_k05 <- seq_raw[, (names(seq_raw) %in% c("Cell", as.character(k05$V1)))]
seq_target_k05 <- seq_target[, (names(seq_target) %in% c("Cell", as.character(k05$V1)))]
seq_cell_k05 <- seq_cell[, (names(seq_cell) %in% c("Cell", as.character(k05$V1)))]

seq_raw_k2 <- seq_raw[, (names(seq_raw) %in% c("Cell", as.character(k2$V1)))]
seq_target_k2 <- seq_target[, (names(seq_target) %in% c("Cell", as.character(k2$V1)))]
seq_cell_k2 <- seq_cell[, (names(seq_cell) %in% c("Cell", as.character(k2$V1)))]
```



# Clustering
## k means
```{r def k }
get_kmeans_clustering <- function(input.df = mrna_raw[, -1],
                                  target.nclusters = 11) {
  kmeans.m <- kmeans(input.df, centers = target.nclusters)
  return(kmeans.m$cluster)
}
```
get_kmeans_clustering(input.df = mrna_raw[, -1])
get_kmeans_clustering(input.df = seq_raw_k05[, -1])

## Hierarchical Clustering
```{r def hierachical}
#https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html #great reference!
get_hierarchical_clustering <- function(input.df = mrna_target[,-1],
                                        target.nclusters = 11,
                                        use.method.dist = "cor",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10) {
  temp <- input.df

  temp.clust <- pvclust(t(temp),
    method.dist = use.method.dist,
    method.hclust = use.method.hclust,
    nboot = use.nboot
  )
  temp.clust <- as.dendrogram(temp.clust$hclust)

  assignment <- cutree(temp.clust, k = target.nclusters)[order.dendrogram(temp.clust)]

  return(assignment)
}
#hclust_methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")
#dist_methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", #"correlation", "uncentered")
```
get_hierarchical_clustering(input.df = mrna_raw[, -1],
                                        target.nclusters = 11,
                                        use.method.dist = "cor",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10)
get_hierarchical_clustering(input.df = seq_raw_k05[, -1],
                                        target.nclusters = 4,
                                        use.method.dist = "euclidean",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10)


## SNN-Cliq #2 tuning parameters (k, distance)
```{r def snn}
get_SNN_clustering <- function(input.df = mrna_raw[, -1],
                               use.k = 3,
                               use.distance = "euclidean") {
  temp <- input.df
  SNN(temp,
    outfile = paste0(getwd(), "/inst/extdata/output_files/temp_edges.txt"),
    k = use.k,
    distance = use.distance
  )
  #warning("Verifying output is recommended -- Old temp_clust.txt files can return nonsensical clusterings. \nThis code has been tested on 64 bit Windows 10 but not on other versions or systems.")
  if (Sys.info()['sysname'] == "Windows"){
    # in CMD run:
    # Py\Cliq.py -i inst\extdata\output_files\temp_edges.txt -o inst\extdata\output_files\temp_clust.txt
    
    shell("Py\\Cliq.py -i inst\\extdata\\output_files\\temp_edges.txt -o inst\\extdata\\output_files\\temp_clust.txt")
  } else if (Sys.info()['sysname'] == "Darwin"){
    warning("get_SNN_clustering() hasn't been tested on macos!")
    #TODO edit this to work on unix systems
  } else {
    warning("get_SNN_clustering() hasn't been tested on linux!")
    #TODO edit this to work on unix systems
  }

  assignment <- read.table(paste0(getwd(), "/inst/extdata/output_files/temp_clust.txt"),
    header = FALSE, sep = "", dec = "."
  )
  return(assignment)
}
```
get_SNN_clustering(input.df = mrna_raw[, -1],
                               use.k = 3,
                               use.distance = "euclidean")

get_SNN_clustering(input.df = seq_raw_k05[, -1],
                               use.k = 3,
                               use.distance = "euclidean")



## Evaluation
```{r def eval}
get_cluster_comparisons <- function(reference.clustering = mrna_raw$Cell,
                                    generated.clustering) {
  if (length(reference.clustering) != length(generated.clustering)) {
    warning("Input vectors are not of the same length!")
  } else {
    # reference.clustering = mrna_raw$Cell
    # generated.clustering = kmeans.m$cluster
    output <- array(0, dim = 6)
    
    reference.clustering <- as.numeric(reference.clustering) %>% as.factor()
    generated.clustering <- as.numeric(generated.clustering) %>% as.factor()

    output <- NMF::purity(reference.clustering, generated.clustering)
    names(output) <- "Purity"
    # Get a lot of concurrance measures
    # https://davetang.org/muse/2017/09/21/adjusted-rand-index/
    output <- c(
      output,
      clues::adjustedRand(
        BiocGenerics::as.vector(reference.clustering),
        BiocGenerics::as.vector(generated.clustering)
      )
    )
    return(output)
  }
}
```
get_cluster_comparisons(
  reference.clustering = seq_raw_k05[, 1],
  generated.clustering = get_SNN_clustering(input.df = seq_raw_k05[, -1],
                               use.k = 3,
                               use.distance = "euclidean") %>% t() #note that because of the formatting of get_SNN_clustering's output, transpose is required when alone to make sure the dims are the same.
)


## Generate Clusterings
```{r}
generate_clusterings <- function(use.input.df = mrna_raw[, -1],
                                 kmeans_k.param = 11,
                                 hclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered"),
                                 hclust_clust.methods = c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2"),
                                 hclust_k.param = 11,
                                 hclust_nboot = 10,
                                 snnclust_verfied = FALSE,
                                 snnclust_k.param = c(3:9),
                                 snnclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski"),
                                 winnow.clusterings = FALSE) {

  ## K Means Clustering =========================================================
  temp <- map(kmeans_k.param, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })

  param.combinations <- paste("K", as.character(
    rep(kmeans_k.param, each = length(kmeans_k.param))
  ), sep = ".")

  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations


  ## Hierarchical Clustering ====================================================
  # use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  # use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")

  temp <- map(hclust_dist.methods, function(iter.dist) {
    map(hclust_clust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df,
        target.nclusters = hclust_k.param,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = hclust_nboot
      )
    })
  })

  param.combinations <- paste("H", as.character(
    rep(hclust_dist.methods, each = length(hclust_clust.methods))
  ), as.character(
    rep(hclust_clust.methods, times = length(hclust_dist.methods))
  ), sep = ".")

  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations


  ## SNN Clustering =============================================================
  if (snnclust_verfied == TRUE) {
    # use.k.param <- c(3:9)
    # use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.

    temp <- map(snnclust_dist.methods, function(iter.dist) {
      map(snnclust_k.param, function(iter.k.param) {
        print(iter.dist)

        get_SNN_clustering(
          input.df = use.input.df,
          use.k = iter.k.param, # number of neigbhors should go up to 9 for scPCRc
          use.distance = iter.dist
        ) #
      })
    })

    param.combinations <- paste("SNN", as.character(
      rep(snnclust_dist.methods, each = length(snnclust_k.param))
    ), as.character(
      rep(snnclust_k.param, times = length(snnclust_dist.methods))
    ), sep = ".")

    SNN.clusters <- do.call(cbind.data.frame, temp)
    names(SNN.clusters) <- param.combinations
  }

  # Merge Data Frames -----------------------------------------------------------
  if (snnclust_verfied == TRUE) {
    all.clusters <- cbind(K.clusters, H.clusters) %>% cbind(SNN.clusters)
  } else {
    all.clusters <- cbind(K.clusters, H.clusters)
  }
  
  
  if (winnow.clusterings == TRUE) {
    # some clusterings fail and pass all values zero
    # Some have a TON of clusters
    num.clusters <- map(all.clusters, function(x) {
      print(max(x))
    }) %>% unlist() # get number of clusters in each group
    real.num <- use.input.df$Cell %>% as.numeric() %>% max()
    selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.
    all.clusters <- all.clusters[, selection.vector]
  }
  return(all.clusters)
}

score_cluster_df <- function(generated.cluster.df = out1,
                             true.clusters = mrna_raw[, 1]) {
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(true.clusters), generated.cluster.df)

  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = true.clusters, generated.clustering = iter.param)
  })

  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)

  return(all.clusters.scores)
}
```
out1 <- generate_clusterings(use.input.df = mrna_raw[, -1],
                                 kmeans_k.param = 11,
                                 hclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered"),
                                 hclust_clust.methods = c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2"),
                                 hclust_k.param = 11,
                                 hclust_nboot = 10,
                             snnclust_verfied = TRUE,
                                 snnclust_k.param = c(3:9),
                                 snnclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski"),
                                 winnow.clusterings = FALSE)
                                 
out2 <- generate_clusterings(use.input.df = seq_cell_k05[, -1],
                                 kmeans_k.param = 4,
                                 hclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered"),
                                 hclust_clust.methods = c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2"),
                                 hclust_k.param = 4,
                                 hclust_nboot = 10,
                             snnclust_verfied = TRUE,
                                 snnclust_k.param = c(3:9),
                                 snnclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski"),
                                 winnow.clusterings = FALSE)

out3 <- score_cluster_df(generated.cluster.df = out2,
                             true.clusters = seq_cell_k05[, 1])


```{r}
use.data <- list(mrna_raw, mrna_cell, mrna_target,
                 seq_pca, 
                 seq_hvg, seq_target_hvg, seq_cell_hvg, 
                 seq_raw_k05, seq_target_k05,  seq_cell_k05, 
                 seq_raw_k2,  seq_target_k2, seq_cell_k2)
use.num.cells <- c(rep(11, times = 3), rep(4, times = 10))

clusterings.list <- list()
cluster.scores.list <- list()
for (i in seq_along(use.data)){
  current.cluster <- generate_clusterings(use.input.df = use.data[[i]][, -1],
                                 kmeans_k.param = use.num.cells[[i]],
                                 hclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered"),
                                 hclust_clust.methods = c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2"),
                                 hclust_k.param = use.num.cells[[i]],
                                 hclust_nboot = 10,
                             snnclust_verfied = TRUE,
                                 snnclust_k.param = c(3:9),
                                 snnclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski"),
                                 winnow.clusterings = FALSE)
  current.score <- score_cluster_df(generated.cluster.df = current.cluster,
                             true.clusters = use.data[[i]][, 1])
  clusterings.list[[i]] <- current.cluster
  cluster.scores.list[[i]] <- current.score
}

if (write.out.clusterings == TRUE) {
  use.data.names <- c(
    "mrna_raw", "mrna_cell", "mrna_target",
    "seq_pca",
    "seq_hvg", "seq_target_hvg", "seq_cell_hvg",
    "seq_raw_k05", "seq_target_k05", "seq_cell_k05",
    "seq_raw_k2", "seq_target_k2", "seq_cell_k2"
  )

  for (i in seq_along(use.data.names)) {
    write.csv(clusterings.list[[i]], paste0(write.to.dir, "clusterings_", use.data.names[i], ".csv"))
    write.csv(cluster.scores.list[[i]], paste0(write.to.dir, "clustering_scores_", use.data.names[i], ".csv"))
  }
}

```


# Classification

```{r}
#Note: Must contain a column called "Cell"
run_supervised_models <- function(use.seed = 8743436,
                                  input.df = use.input.df){

#use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)

  
#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA
set.seed(use.seed)
ldam <- train(
  Cell ~ . ,
  data = input.df,
  method = "lda",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#return(list(knnm,ldam,nnmm,nnm,rfm,svm.rad,svm.lin))
return(list(GLMNet=glmnetm,
                          kNN=knnm,
                          LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad, 
                          SVM.Linear=svm.lin))
}
  input.df <- seq_pca[,1:38] 
input.df <- seq_hvg 
input.df <- seq_target_hvg 
input.df <- seq_cell_hvg 
input.df <- seq_raw_k05 
input.df <- seq_target_k05  
input.df <- seq_cell_k05 
input.df <- seq_raw_k2  
input.df <- seq_target_k2 
input.df <- seq_cell_k2


run_supervised_models <- function(use.seed = 8743436,
                                  input.df = use.input.df,
                                  use.cv.folds = 3){

  



#use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "cv", number = use.cv.folds, verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)

  
#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "cv", number = use.cv.folds, verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA ---------- This was removed as it doesn't perform well and breaks on the tested seq dataset
#set.seed(use.seed)
#ldam <- train(
#  Cell ~ . ,
#  data = input.df,
#  method = "lda",
#  trControl = trainControl(method = "cv", number = use.cv.folds, verboseIter = TRUE)
#)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "cv", number = use.cv.folds, verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "cv", number = use.cv.folds, verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "cv", number = use.cv.folds, verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = use.cv.folds, verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "cv", number = use.cv.folds, verboseIter = TRUE)
)

#return(list(knnm,ldam,nnmm,nnm,rfm,svm.rad,svm.lin))
return(list(GLMNet=glmnetm,
                          kNN=knnm,
                          #LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad, 
                          SVM.Linear=svm.lin))
}
```



```{r}
#TODO the hvg datasets seem to not work for either of the NN or SVM methods. This does not appear to be due to number of columns.

use.data <- list(mrna_raw, mrna_cell, mrna_target,
                 seq_pca, 
                 #seq_hvg, seq_target_hvg, seq_cell_hvg, 
                 seq_raw_k05, seq_target_k05,  seq_cell_k05, 
                 seq_raw_k2,  seq_target_k2, seq_cell_k2)
ml.output <- list()
for(i in seq_along(use.data)){
  ml.output[[i]] <- run_supervised_models(use.seed = 8743436, input.df = use.data[[i]])
}



rValues <- resamples(ml.pca)
bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0, 1))
```

```{r eval=FALSE, include=FALSE}
o1 <- run_supervised_models(use.seed = 8743436, input.df = seq_pca) 
o2 <- run_supervised_models(use.seed = 8743436, input.df = seq_hvg[,1:50]) #reducing cols doesn't fix the problem.

o2 <- run_supervised_models(use.seed = 8743436, input.df = seq_raw[, (names(seq_raw)%in%names(seq_hvg))]) #Problem seems to be tied to predictor selection not the path by which we got seq_hvg or its derivatives.

#  o3 <- run_supervised_models(use.seed = 8743436, input.df = seq_target_hvg) 
#  o4 <- run_supervised_models(use.seed = 8743436, input.df = seq_cell_hvg) 

o5 <- run_supervised_models(use.seed = 8743436, input.df = seq_raw_k05)
o6 <- run_supervised_models(use.seed = 8743436, input.df = seq_target_k05)  
o7 <- run_supervised_models(use.seed = 8743436, input.df = seq_cell_k05)
o8 <- run_supervised_models(use.seed = 8743436, input.df = seq_raw_k2)
o9 <- run_supervised_models(use.seed = 8743436, input.df = seq_target_k2) 
o0 <- run_supervised_models(use.seed = 8743436, input.df = seq_cell_k2)

```

```{r}
name.prefix <- c("mrna_raw", "mrna_cell", "mrna_target",
                 "seq_pca", 
                 #seq_hvg, seq_target_hvg, seq_cell_hvg, 
                 "seq_raw_k05", "seq_target_k05",  "seq_cell_k05", 
                 "seq_raw_k2",  "seq_target_k2", "seq_cell_k2")

for(i in seq_along(ml.output)){

  out <- ml.output[[i]]
  
  rValues <- resamples(out)
  bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0, 1))
  
  
  #save the accuracies for future use
  write.csv(as.data.frame(rValues$values), 
            file = paste0(write.to.dir, name.prefix[i],"_model_accuracy.csv"), 
            row.names = FALSE)
  
  #TODO this is not writing out usable plots
  pdf(file = paste0(write.to.dir, name.prefix[i],"_Accuracy", ".pdf"))
    bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0,1))
    dev.off()
    
  pdf(file = paste0(write.to.dir, name.prefix[i],"_Kappa", ".pdf"))
    bwplot(rValues, metric="Kappa", ylab = c("Models"), xlim = c(0,1))
    dev.off()
  
}
```


# Evaluation of the work we've done so far.

 [1] "clustering_scores_mrna_cell.csv"     
 [2] "clustering_scores_mrna_raw.csv"      
 [3] "clustering_scores_mrna_target.csv"   
 [4] "clustering_scores_seq_cell_hvg.csv"  
 [5] "clustering_scores_seq_cell_k05.csv"  
 [6] "clustering_scores_seq_cell_k2.csv"   
 [7] "clustering_scores_seq_hvg.csv"       
 [8] "clustering_scores_seq_pca.csv"       
 [9] "clustering_scores_seq_raw_k05.csv"   
[10] "clustering_scores_seq_raw_k2.csv"    
[11] "clustering_scores_seq_target_hvg.csv"
[12] "clustering_scores_seq_target_k05.csv"
[13] "clustering_scores_seq_target_k2.csv"

[14] "clusterings_mrna_cell.csv"           
[15] "clusterings_mrna_raw.csv"            
[16] "clusterings_mrna_target.csv"         
[17] "clusterings_seq_cell_hvg.csv"        
[18] "clusterings_seq_cell_k05.csv"        
[19] "clusterings_seq_cell_k2.csv"         
[20] "clusterings_seq_hvg.csv"             
[21] "clusterings_seq_pca.csv"             
[22] "clusterings_seq_raw_k05.csv"         
[23] "clusterings_seq_raw_k2.csv"          
[24] "clusterings_seq_target_hvg.csv"      
[25] "clusterings_seq_target_k05.csv"      
[26] "clusterings_seq_target_k2.csv" 

[27] "mrna_cell_model_accuracy.csv"        
[28] "mrna_raw_model_accuracy.csv"         
[29] "mrna_target_model_accuracy.csv"      
[30] "seq_cell_k05_model_accuracy.csv"     
[31] "seq_cell_k2_model_accuracy.csv"      
[32] "seq_pca_model_accuracy.csv"          
[33] "seq_raw_k05_model_accuracy.csv"      
[34] "seq_raw_k2_model_accuracy.csv"       
[35] "seq_target_k05_model_accuracy.csv"   
[36] "seq_target_k2_model_accuracy.csv" 
```{r}
#From backup:
files <- list.files(paste0(getwd(),"/inst/extdata/output_files/all_clustScore"))

data.list <- map(files, function(x){
  read.csv(paste0(getwd(), "/inst/extdata/output_files/all_clustScore/",x))
})

output_scores <- as.data.frame(matrix(0, ncol = 4, nrow = 0))
names(output_scores) <- c("i", "X", "HA","file")

for(i in 1:13){
  print(i)

  local.max <- max(data.list[[i]][data.list[[i]]$HA != 1, "HA"])
  temp <- data.list[[i]][data.list[[i]]$HA == local.max, ][, c("X", "HA")]
  temp[, "file"] <- as.character(files[[i]])
  temp[, "i"] <- i
  
  output_scores <<- rbind(output_scores, temp)
}

output_scores[1:3, ]
#H.correlation.ward.D2 0.7566305 clustering_scores_mrna_target.csv
output_scores[output_scores$HA == max(output_scores[4:13, "HA"]), ]
#H.correlation.ward.D 0.8028427 clustering_scores_seq_cell_k05.csv 5
#H.correlation.ward.D 0.8028427  clustering_scores_seq_raw_k05.csv 9
```

## Plot the best trees
```{r}
tic <- Sys.time()
#TODO set to nboot =1000 for pub
use.nboot = 1000

plt_mrna <- pvclust(t(mrna_target[,-1]),
                    nboot = use.nboot, 
                    method.dist = "correlation",
                    method.hclust = "ward.D2")

plt_mrna %>% as.dendrogram %>% 
  set("branches_k_color", k = 11, value = c("Firebrick", "Steelblue", "darkolivegreen2", "gold1", "deepskyblue", "forestgreen", "darkslategray1", "navyblue", "orange3", "purple", "violetred")) %>%
  plot
plt_mrna %>% text


#Answer question for djs: does clustering improve with cell type based median interpolation?
t1 <- Sys.time()
M <- read.csv(paste0(getwd(),"/inst/extdata/STG_LC_Absolute_Counts_allSTG-GM2f.csv"))
rownames(M) <- M$Sample
M <- M[, -2]
M <- predict(preProcess(M, method = c("center", "scale")), M)

PCR_manual <- pvclust(t(M[, -1]),
                    nboot = use.nboot, 
                    method.dist = "correlation",
                    method.hclust = "ward.D2")

PCR_manual %>% as.dendrogram %>% 
  set("branches_k_color", k = 11, value = c("Firebrick", "Steelblue", "darkolivegreen2", "gold1", "deepskyblue", "forestgreen", "darkslategray1", "navyblue", "orange3", "purple", "violetred")) %>%
  plot
PCR_manual %>% text
t2 <- Sys.time()
print(t2-t1)
############################# end #############################


plt_seq1 <- pvclust(t(seq_cell_k05[,-1]),
                    nboot = use.nboot, 
                    method.dist = "correlation",
                    method.hclust = "ward.D")

plt_seq1 %>% as.dendrogram %>% 
  set("branches_k_color", k = 4, value = c("Firebrick", "Steelblue", "darkolivegreen2", "purple")) %>%
  plot
plt_mrna %>% text


plt_seq2 <- pvclust(t(seq_raw_k05[,-1]),
                    nboot = use.nboot, 
                    method.dist = "correlation",
                    method.hclust = "ward.D")
plt_seq2 %>% as.dendrogram %>% 
  set("branches_k_color", k = 4, value = c("Firebrick", "Steelblue", "darkolivegreen2", "purple")) %>%
  plot
plt_mrna %>% text

#Ask from djs -- Seq tree at 0.05 mirroring qpcr
plt_seq3 <- pvclust(t(seq_target_k05[,-1]),
                    nboot = use.nboot, 
                    method.dist = "correlation",
                    method.hclust = "ward.D2")

plt_seq3 %>% as.dendrogram %>% 
  set("branches_k_color", k = 4, value = c("Firebrick", "Steelblue", "darkolivegreen2", "purple")) %>%
  plot
plt_seq3 %>% text


toc <- Sys.time()
print(toc - tic)
```

#plot the ml results


```{r}
ml.vis <- as.data.frame(matrix(nrow = 0, ncol = 16))

for (i in 27:36){
  M <- data.list[[i]]
  M[, "Input"] <- files[[i]]
  ml.vis <<- rbind(ml.vis, M)
}
ml.vis$Input <- str_replace(ml.vis$Input, "_model_accuracy.csv", "")
ml.vis$Resample <- str_replace(ml.vis$Resample, "Fold", "")
ml.vis <- ml.vis[, c("Input", "Resample", "GLMNet.Accuracy", "kNN.Accuracy", "NNet.Accuracy", "NNet.Multinom.Accuracy", "Rand.Forest.Accuracy", "SVM.Radial.Accuracy", "SVM.Linear.Accuracy")]

ml.vis <- gather(ml.vis, "Method", "Accuracy", 3:9) 

ml.vis$Input <- str_replace(ml.vis$Input, "seq", "Seq")
ml.vis$Input <- str_replace(ml.vis$Input, "mrna", "PCR")

ml.vis$Input = factor(ml.vis$Input, levels = c("PCR_raw", "PCR_target", "PCR_cell", "Seq_pca", "Seq_raw_k2", "Seq_target_k2", "Seq_cell_k2", "Seq_raw_k05", "Seq_target_k05", "Seq_cell_k05"))

library(ggthemes)
library(ggsci)
library(lemon)

ggplot(ml.vis, aes(x = Method, y = Accuracy, fill = Method))+
  geom_boxplot()+
  geom_point(shape = 1, size =2)+
  stat_summary(fun.y = "median", colour = "black", size = 2, geom = "point")+
  coord_capped_cart(bottom='both', left='both')+
  facet_grid(.~Input)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(legend.position = "")+
  ggsci::scale_fill_locuszoom()
  
```

Which ml method consistently produces the best results?

Looking at all the data glmnet has hte hightest median followed closely by svm linear.
Random forest has the hightes minimum accuracy.
```{r}
ml.vis[, c("Method", "Input", "Accuracy")] %>% group_by(Method) %>% summarize(median(Accuracy))
ml.vis[, c("Method", "Input", "Accuracy")] %>% group_by(Method) %>% summarize(min(Accuracy))
```

```{r}
ggplot(ml.vis, aes(x = Input, y = Accuracy, fill = Method))+
  geom_boxplot()+
  geom_point(shape = 1, size =2)+
  stat_summary(fun.y = "median", colour = "black", size = 2, geom = "point")+
  coord_capped_cart(bottom='both', left='both')+
  facet_grid(.~Method)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(legend.position = "")+
  ggsci::scale_fill_locuszoom()
```








# Cluster Estimation ----------------------------------------------------------
```{r}
#H.correlation.ward.D2 0.7566305 clustering_scores_mrna_target.csv
#H.correlation.ward.D 0.8028427 clustering_scores_seq_cell_k05.csv 5
#H.correlation.ward.D 0.8028427  clustering_scores_seq_raw_k05.csv 9
#use.index <- c("kl", "ch", "hartigan", "cindex", "db", "silhouette", "duda", "pseudot2", "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw")

use.index1 <- c("kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew", "friedman", "rubin", "cindex", "db", "silhouette", #"duda", "pseudot2", "beale", 
               "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw")
out1 <- map(use.index1, function(i){
  print(i)
  data.use <- mrna_target[, -1]
  dis.matrix <- factoextra::get_dist(data.use, method = "pearson")
  try(
  NbClust(data = data.use,
          distance = NULL, 
          diss = dis.matrix,
          min.nc=2, 
          max.nc=20, 
          method = "ward.D2", 
          index = i)$Best.nc[1]
  )
})

use.index2 <- c("kl", "ch", "hartigan", 
               #"ccc", "scott", "marriot", "trcovw", "tracew", "friedman", "rubin", 
               "cindex", "db", "silhouette", "duda", "pseudot2", #"beale", 
               "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw"
               )
out2 <- map(use.index2, function(i){
  data.use <- seq_raw_k05[, -1]
  dis.matrix <- factoextra::get_dist(data.use, method = "pearson")
  print(i)
  try(
  NbClust(data = data.use,
          distance = NULL, 
          diss = dis.matrix,
          min.nc=2, 
          max.nc=20, 
          method = "ward.D", 
          index = i)$Best.nc[1]
  )
})

use.index3 <- c("kl", "ch", "hartigan", 
               #"ccc", "scott", "marriot", "trcovw", "tracew", "friedman", "rubin", 
               "cindex", "db", "silhouette", "duda", "pseudot2", #"beale", 
               "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex"
, "sdbw"
               )
out3 <- map(use.index3, function(i){
  data.use <- seq_cell_k05[, -1]
  dis.matrix <- factoextra::get_dist(data.use, method = "pearson")
  print(i)
  try(
  NbClust(data = data.use,
          distance = NULL, 
          diss = dis.matrix,
          min.nc=2, 
          max.nc=20, 
          method = "ward.D", 
          index = i)$Best.nc[1]
  )
})

################ Test optimal
use.index4 <- c("kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew", "friedman", "rubin", "cindex", "db", "silhouette", "duda", "pseudot2", #"beale", 
               "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw")

out4 <- map(use.index4, function(i){
  data.use <- mrna_target_optimal[, -1]
  dis.matrix <- factoextra::get_dist(data.use, method = "pearson")
  print(i)
  try(
  NbClust(data = data.use,
          distance = NULL, 
          diss = dis.matrix,
          min.nc=2, 
          max.nc=20, 
          method = "ward.D2", 
          index = i)$Best.nc[1]
  )
})

# DJS ask, similar to above tree
use.index5 <- c("kl", "ch", "hartigan", 
               #"ccc", "scott", "marriot", "trcovw", "tracew", "friedman", "rubin", 
               "cindex", "db", "silhouette", "duda", "pseudot2", #"beale", 
               "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex"
, "sdbw"
               )

out5 <- map(use.index5, function(i){
  data.use <- seq_target_k05[, -1]
  dis.matrix <- factoextra::get_dist(data.use, method = "pearson")
  print(i)
  try(
  NbClust(data = data.use,
          distance = NULL, 
          diss = dis.matrix,
          min.nc=2, 
          max.nc=20, 
          method = "ward.D2", 
          index = i)$Best.nc[1]
  )
})

convert_list2df <- function(input.list = out1, index.used = use.index1){
  #input.list <- out1
  temp <- matrix(nrow = 1, ncol = length(index.used))
  for(i in 1:length(input.list)){
    if(length(as.numeric(input.list[[i]])) == 0){
      temp[i] <- -1
    } else {
      temp[i] <- as.numeric(input.list[[i]])    
    }
  }  
  temp <- as.data.frame(temp)
  return(temp)
}

out1 <- convert_list2df(input.list = out1, index.used = use.index1)
out2 <- convert_list2df(input.list = out2, index.used = use.index2)
out3 <- convert_list2df(input.list = out3, index.used = use.index3)
out4 <- convert_list2df(input.list = out4, index.used = use.index4)
out5 <- convert_list2df(input.list = out5, index.used = use.index5)

names(out1) <- use.index1
names(out2) <- use.index2
names(out3) <- use.index3
names(out4) <- use.index4
names(out5) <- use.index5

plt.list <- map(list(out1, out2, out3, out4, out5), function(x){
  gather(x, Index, Clusters, 1:ncol(x))
})

plt.titles <- c("PCR Target", "Seq Raw 0.05", "Seq Cell 0.05", "PCR Target CellType", "Seq Target 0.05" )


for(i in 1:5){
  plt <- ggplot(plt.list[[i]][plt.list[[i]]$Clusters > 0, ], aes(x = Clusters))+
    geom_histogram(binwidth = 1, fill = "gray")+
    geom_vline(xintercept=seq(1.5, 20.5, 1), col="white", lwd=1)+
    geom_hline(yintercept=seq(1, 10, 1), col="white", lwd=1)+
    xlim(0, 20)+
    ylim(0, 10)+
    labs(title = plt.titles[i])+
    coord_capped_cart(bottom='both', left='both')
  plot(plt)
}

```


# Tested this far!! -----------------------------------------------------------

```{r}
#H.correlation.ward.D2 0.7566305 clustering_scores_mrna_target.csv

#Calculate similarity matrix and then convert to distance matrix
cor.dist.matrix01 <- proxy::simil(mrna_target, diag=FALSE)
cor.dist.matrix01 <- proxy::pr_simil2dist(cor.dist.matrix01)

estimates01 <- NbClust(data = mrna_target[,-1],
        distance = NULL, 
        diss = cor.dist.matrix01,
        min.nc=2, 
        max.nc=20, 
        method = "ward.D2", 
        index = "all")$Best.nc[1,]

#repeat for
#H.correlation.ward.D 0.8028427 clustering_scores_seq_cell_k05.csv 5
cor.dist.matrix02 <- proxy::simil(seq_cell_k05, diag=FALSE)
cor.dist.matrix02 <- proxy::pr_simil2dist(cor.dist.matrix02)

estimates02 <- NbClust(data = seq_cell_k05[,-1],
        distance = NULL, 
        diss = cor.dist.matrix02,
        min.nc=2, 
        max.nc=20, 
        method = "ward.D", 
        index = "all")$Best.nc[1,]

#repeat for
#H.correlation.ward.D 0.8028427  clustering_scores_seq_raw_k05.csv 9
cor.dist.matrix03 <- proxy::simil(seq_raw_k05, diag=FALSE)
cor.dist.matrix03 <- proxy::pr_simil2dist(cor.dist.matrix03)

estimates03 <- NbClust(data = seq_raw_k05[,-1],
        distance = NULL, 
        diss = cor.dist.matrix03,
        min.nc=2, 
        max.nc=20, 
        method = "ward.D", 
        index = "all")$Best.nc[1,]


plt.cluster.est <- data.frame(PCR_target = estimates01)

ggplot(plt.cluster.est, aes(x = PCR_target))+
  geom_histogram(bins = 20, fill = "gray")+
  #geom_vline(xintercept=seq(1.5, 20.5, 1), col="white", lwd=1)+
  geom_hline(yintercept=seq(1, 5, 1), col="white", lwd=1)+
  coord_capped_cart(bottom='both', left='both')


mm <- NbClust(data = seq_raw_k05[,-1],
        distance = NULL, 
        diss = cor.dist.matrix03,
        min.nc=2, 
        max.nc=20, 
        method = "ward.D", 
        index = "gap")$Best.nc[1,]

nn <- NbClust(data = seq_raw_k05[,-1],
        distance = NULL, 
        diss = factoextra::get_dist(seq_raw_k05[,-1], method = "kendall"),
        min.nc=2, 
        max.nc=20, 
        method = "ward.D", 
        index = "kl")$Best.nc[1,]

factoextra::get_dist(seq_raw_k05[,-1], method = "pearson")


nn <- 1-cor(current.df)

nn <- (1-cor(current.df, use = "complete.obs", method = "pearson"))

(1-cor(current.df, use = "pairwise.complete", method = "pearson"))




data.use <- seq_raw_k05[,-1]
dis.matrix <- dist.pvclust(seq_raw_k05[,-1], method = "correlation", use.cor="pairwise.complete.obs")

for (x in c("kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew", "friedman", "rubin", "cindex", "db", "silhouette", "duda", "pseudot2", "beale", "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw")){
  try(print(NbClust(data = data.use,
        distance = NULL, 
        diss = dis.matrix,
        min.nc=2, 
        max.nc=5, 
        method = "ward.D", 
        index = x)$Best.nc[1,]))
}

library(optCluster)
data("arabid")

count1 <- optCluster(arabid, 2:4, clMethods = "all", countData = TRUE)
summary(count1)
# Obtain optimal clustering assignment
optAssign(count1)

test <- optCluster::optCluster(data.use, 2:6, clMethods = "all", countData = T)
summary(test)

#minimal verison of cor based cluster?#
```


```{r}
#35 Error in solve.default(W) :   system is computationally singular: reciprocal condition number = 3.03073e-19
source(paste0(getwd(),"/R/NbClust_mod.R"))



for(x in c("kl", "ch", "hartigan", 
           #"ccc", "scott", "marriot", "trcovw", "tracew", "friedman", "rubin", 
           "cindex", "db", "silhouette", "duda", "pseudot2", 
           #"beale", 
           "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw")){
  print(x)
  data.use <- seq_raw_k05[, -1]#c(6,39:45)]
  dis.matrix <- factoextra::get_dist(data.use, method = "pearson")
  a <- try(NbClust_mod(data = data.use,
          distance = NULL, 
          diss = dis.matrix,
          min.nc=2, 
          max.nc=5, 
          method = "ward.D", 
          index = x,
          max.tol = 1e-22))
  
}


#from pvclust
dist.pvclust <- function(x, method="euclidean", use.cor="pairwise.complete.obs")
{
  if(!is.na(pmatch(method,"correlation"))){
    res <- as.dist(1 - cor(x, method="pearson", use=use.cor))
    attr(res,"method") <- "correlation"
    return(res)
  }
  else if(!is.na(pmatch(method,"abscor"))){
    res <- as.dist(1 - abs(cor(x,method="pearson",use=use.cor)))
    attr(res,"method") <- "abscor"
    return(res)
  }
  else if(!is.na(pmatch(method,"uncentered"))){
    if(sum(is.na(x)) > 0){
      x <- na.omit(x)
      warning("Rows including NAs were omitted")
    }
    x  <- as.matrix(x)
    P  <- crossprod(x)
    qq <- matrix(diag(P),ncol=ncol(P))
    Q  <- sqrt(crossprod(qq))
    res <- as.dist(1 - P/Q)
    attr(res,"method") <- "uncentered"
    return(res)
  }
  else
    dist(t(x),method)
}

oo <- map(c("kl", "ch", "hartigan", "cindex", "db", "silhouette", "duda", "pseudot2", "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw"),
    function(i){
  data.use <- seq_cell_k05[, -1]#c(6,39:45)]
  dis.matrix <- factoextra::get_dist(data.use, method = "pearson")
  #dis.matrix <- dist.pvclust(data.use, method = "correlation", method = "pearson") #This is how I wanted to do this
  try(NbClust(data = data.use,
          distance = NULL, 
          diss = dis.matrix,
          min.nc=2, 
          max.nc=5, 
          method = "ward.D", 
          index = i))
})

```


```{r automated approach}
## using NbClust to churn out predictions =====================================
automated_clust_k <- function(current.df = use.input.df[, -1], current.max.k = max.k) {
  # nb <- NbClust(use.input.df, diss="NULL", distance = "euclidean",
  #        min.nc=2, max.nc=max.k, method = "kmeans",
  #        index = "alllong", alphaBeale = 0.1)
  # hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])))

  # nb <- NbClust(use.input.df[, -1], distance = "euclidean", min.nc=2, max.nc=max.k, method = "ward.D", index = "all")
  # hist(nb$Best.nc[1,],
  #     breaks = max(na.omit(nb$Best.nc[1,])))

  avail.methods <- c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans") #TODO this is fucking up the seq data. at least one of the methods (maybe "single"?) is breaking the loop
  avail.distances <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
  #Ideally this should be vectorized to speed up the process
  cluster.estimates <- list()
  for (use.method in avail.methods) {
    list1 <- list()
    for (use.distance in avail.distances) {
      nb <- NbClust(current.df,
        distance = use.distance,
        min.nc = 2, max.nc = current.max.k,
        method = use.method, index = "all"
      )
      list1[[length(list1) + 1]] <- nb$Best.nc["Number_clusters", ]
    }
    cluster.estimates[[length(cluster.estimates) + 1]] <- list1
  }

  new.df <- as.data.frame(matrix(nrow = length(avail.methods) * length(avail.distances), ncol = 28))
  new.df.names <- c("Method", "Distance", names(cluster.estimates[[1]][[1]]))
  names(new.df) <- new.df.names
  for (i in seq_along(avail.methods)) {
    for (j in seq_along(avail.distances)) {
      row.num.to.use <- length(avail.methods) * (i - 1) + j
      len.obj <- length(cluster.estimates[[i]][[j]])

      new.df[row.num.to.use, 1] <- avail.methods[i]
      new.df[row.num.to.use, 2] <- avail.distances[j]

      new.df[row.num.to.use, seq(from = 3, length.out = len.obj)] <- cluster.estimates[[i]][[j]]
    }
  }
  return(new.df)
}

#H.correlation.ward.D2 0.7566305 clustering_scores_mrna_target.csv
estimate1 <- automated_clust_k(current.df = mrna_target[, -1], current.max.k = 22)

#H.correlation.ward.D 0.8028427 clustering_scores_seq_cell_k05.csv 5
#H.correlation.ward.D 0.8028427  clustering_scores_seq_raw_k05.csv 9

nbc1 <- NbClust(mrna_target[, -1], distance = "", min.nc=2, max.nc=22, 
            method = "ward.D2", index = "all")
nbc1$Best.nc[1,] %>% names()


tic <- Sys.time()
current.df = mrna_target[, -1]
current.df.name = "test"
current.max.k = 22




param.grid <- expand.grid(c("euclidean", "maximum", "manhattan", "canberra", 
                            #"binary", 
                            "minkowski"),
            c("ward.D", "ward.D2"
              #, "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"
              ))

cluster.votes <- as.data.frame(matrix(nrow = nrow(param.grid), ncol = 29))
names(cluster.votes) <- c(c("Data", "Distance", "Method"), 
                          c("KL", "CH", "Hartigan", "CCC", "Scott", "Marriot", "TrCovW", "TraceW", "Friedman", "Rubin", "Cindex", "DB", "Silhouette", "Duda", "PseudoT2", "Beale", "Ratkowsky", "Ball", "PtBiserial", "Frey", "McClain", "Dunn", "Hubert", "SDindex", "Dindex", "SDbw"))

for (i in 1:nrow(param.grid)){
  print(paste("iter", as.character(i)))
  temp <- rep(-1, times = 26)
  
  temp <- try(NbClust(current.df, 
                      distance = as.character(param.grid[i, 1]), 
                      min.nc=2, 
                      max.nc=current.max.k, 
                      method = as.character(param.grid[i, 2]), 
                      index = "all")$Best.nc[1,])
  
  cluster.votes[i,] <- c(current.df.name, param.grid[i, 1], param.grid[i, 2], temp)
  
}


toc <- Sys.time()
print(toc - tic)









clust1 <- automated_clust_k(mrna_raw[,-1], current.max.k = 11)
clust2 <- automated_clust_k(current.df = seq_raw_k05[,-1], current.max.k = 4)


for (i in c(
  "kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew", 
  "friedman", "rubin", "cindex", "db", "silhouette", "duda", "pseudot2", "beale", "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw"
)) {
  print(i)
  try(
    NbClust(as.matrix(seq_raw_k05[, -1]),
    distance = "euclidean",
    min.nc = 2, max.nc = 5,
    method = "kmeans", index = i
  )
  )
}

current.df = seq_pca[,-1]
current.max.k = current.max.k = 4





avail.methods <- c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans") #TODO this is fucking up the seq data. at least one of the methods (maybe "single"?) is breaking the loop
  avail.distances <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
  #Ideally this should be vectorized to speed up the process
  
avail.metrics <- c(  "kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew",   "friedman", "rubin", "cindex", "db", "silhouette", "duda", "pseudot2", "beale", "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw"
)
  
  cluster.estimates <- list()
  for (use.method in avail.methods) {
    list1 <- list()
    for (use.distance in avail.distances) {
      nbs <- vector()
      for (use.metric in avail.metrics){
        print(
          paste(as.character(use.method),
              as.character(use.distance),
              as.character(use.metric), sep = "."))
        
        try(
          nbs <<- NbClust(current.df,
        distance = use.distance,
        min.nc = 2, max.nc = current.max.k,
        method = use.method, index = use.metric
      )$Best.nc
        )
      }
      
      
      list1[[length(list1) + 1]] <- nb$Best.nc["Number_clusters", ]
    }
    cluster.estimates[[length(cluster.estimates) + 1]] <- list1
  }

  new.df <- as.data.frame(matrix(nrow = length(avail.methods) * length(avail.distances), ncol = 28))
  new.df.names <- c("Method", "Distance", names(cluster.estimates[[1]][[1]]))
  names(new.df) <- new.df.names
  for (i in seq_along(avail.methods)) {
    for (j in seq_along(avail.distances)) {
      row.num.to.use <- length(avail.methods) * (i - 1) + j
      len.obj <- length(cluster.estimates[[i]][[j]])

      new.df[row.num.to.use, 1] <- avail.methods[i]
      new.df[row.num.to.use, 2] <- avail.distances[j]

      new.df[row.num.to.use, seq(from = 3, length.out = len.obj)] <- cluster.estimates[[i]][[j]]
    }
  }
```

```{r iteratively call function}
# Initial Setup ---------------------------------------------------------------
#use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw
#name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
#max.k <- (nrow(use.input.df)/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.

use.datasets <- list(mrna_raw, mrna_target, mrna_cell, 
                     seq_pca, seq_target, seq_cell, seq_hvg, 
                     seq_raw_k05, seq_target_k05, seq_cell_k05, 
                     seq_raw_k2, seq_target_k2, seq_cell_k2)
use.names <- list("mrna_raw", "mrna_target", "mrna_cell", 
                     "seq_pca", "seq_target", "seq_cell", "seq_hvg", 
                     "seq_raw_k05", "seq_target_k05", "seq_cell_k05", 
                     "seq_raw_k2", "seq_target_k2", "seq_cell_k2")
guess_clust_list <- list()
for (i in seq(from = 1, to = length(guess_clust_list))){
  max.k <- (nrow(use.datasets[[i]])/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.
  guess_clust_list[[length(guess_clust_list)+1]] <- automated_clust_k(current.df = use.datasets[[i]][,-1], current.max.k = max.k)
}

walk(seq_along(guess_clust_list), function(x){
  write.csv(guess_clust_list[[x]], file = paste0(write.to.dir, use.names[[x]], "_kEstimate.csv"))
})
```


