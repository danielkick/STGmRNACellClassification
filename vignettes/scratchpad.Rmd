---
title: "Untitled"
author: "Daniel R. Kick"
date: "September 21, 2018"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)

tic <- Sys.time()

# General + Plotting ----------------------------------------------------------
library(tidyverse) #ggplot2, purrr, dplyr, tidyr mostly
library(cowplot) #clean up ggplots ands plotgrid
library(M3Drop) #for BrenneckeGetVariableGenes

# Cluster Determination -------------------------------------------------------
library(factoextra) #for fviz_nbclust
library(NbClust) #to automate cluster determination for each dataset
# Clustering ------------------------------------------------------------------
library(BiocGenerics) # This is used for clustering assessment
library(pvclust) #for pvclust
library(dendextend) #for cutree coloring dendrograms
library(NMF) #used for calculating purity metric
library(clues) #used for calculating concurrance metrics

# Classification --------------------------------------------------------------
  #install.packages("caret", dependencies = c("Depends", "Suggests"))
library(caret) # for preProcess and supervised ML models

library(devtools)
devtools::load_all() #needed to have access to SNN.R
```

```{r eval=FALSE, include=FALSE}
#general

library(rgl) #for 3d plots


#used in unsupervised ml
library(corrplot) #for corrplot
library(heatmap3) #for heatmap3
library(cluster) #for pam and clusplot
#library(sscClust) #Can't get installed
# For clustering comparison

library(Rtsne) #for t-SNE

#used supervised ml

library(matrixStats)
library(M3Drop)
devtools::load_all()

#from esynvmod
library("extrafont") #help with plotting
#font_import()
loadfonts(device = "win")
library("lemon") #clean up ggplots
library("ggthemes") #color plots
```


```{r Show info to aid reproducibility}
sessionInfo()
```

# User set up -----------------------------------------------------------------
```{r Conrol block}
#What should happen to plots?
#save
#show

#What should happen to output data?
#save
#show

run.snn.cliq <- TRUE # SNN Cliq depend on python. This scritp is written to work on windows and hasn't been tested on Unix/Macos. Needed file is in ../Py. At the point of writing, python version 3.7 has beed tested and works
write.to.dir <- paste0(getwd(), "/inst/extdata/output_files/")
use.seed <- 8743436
```

## our inputs: ================================================================
```{r Pull in datasets}
## Read in all data ===========================================================
k05 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto0.05.csv"), header = F) %>% as.data.frame()
k2 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto0.2.csv"), header = F) %>% as.data.frame()
mrna_raw <- read.csv(paste0(getwd(),"/inst/extdata/RTqPCR.csv"), row.names = "Sample", header = TRUE) %>% as.data.frame()
seq_raw <- read.csv(paste0(getwd(),"/inst/extdata/scSeq.csv"), row.names = "id", header = TRUE) %>% t() %>% as.data.frame()

## Transform RTqPCR data ======================================================
mrna_raw <- predict(preProcess(mrna_raw, method = c("medianImpute", "zv")), mrna_raw)
mrna_target <- predict(preProcess(mrna_raw, method = c("center", "scale")), mrna_raw)

mrna_cell <- mrna_raw[,-1]
mrna_cell <- as.data.frame(t(mrna_cell))
mrna_cell <- predict(preProcess(mrna_cell, method = c("center", "scale")), mrna_cell)
mrna_cell <- cbind(Cell = mrna_raw$Cell, as.data.frame(t(mrna_cell)))

## Transform Seq data =========================================================
seq_raw <- predict(preProcess(seq_raw, method = c("zv")), seq_raw)
seq_target <- predict(preProcess(seq_raw, method = c("center", "scale")), seq_raw)
# center and scale by cell
seq_cell <- seq_raw
seq_cell <- as.data.frame(t(seq_cell))
seq_cell <- predict(preProcess(seq_cell, method = c("center", "scale")), seq_cell)
seq_cell <- as.data.frame(t(seq_cell))
# Set up a cell id vector to use in each dataframe
split.names <- rownames(seq_raw) %>% strsplit("[.]")
split.names <- unlist(split.names)
Cell.ids <- split.names[seq(1, to = length(split.names), by = 2)]
# Give each dataset a `Cell` column
seq_raw <- cbind(Cell = Cell.ids, seq_raw)
seq_target <- cbind(Cell = Cell.ids, seq_target)
seq_cell <- cbind(Cell = Cell.ids, seq_cell)

## PCA ========================================================================
# PCA can capture most of the variance
#because the full seq is too much to work with locally:
seq_pca <- prcomp(seq_cell[,-1], scale = FALSE)
#fviz_eig(seq_pca, addlabels = TRUE)
#factoextra::get_eigenvalue(seq_pca)
seq_pca <- cbind(seq_cell$Cell, as.data.frame(seq_pca$x))
seq_pca <- rename(seq_pca, Cell = `seq_cell$Cell`)

## HVG ========================================================================
#TODO determine if HVG is useful or if we should drop it.
temp <- seq_raw[,-1]
temp <- t(temp)
# x.data <- rowMeans(temp)
# y.data <- matrixStats::rowVars(temp)
# ggplot()+geom_point(aes(x = log10(x.data), y = log10(y.data)), shape = 1)
#https://hemberg-lab.github.io/scRNA.seq.course/biological-analysis.html#feature-selection
Brennecke_HVG <- M3Drop::BrenneckeGetVariableGenes(
  temp,
  fdr = 0.01,
  minBiolDisp = 0.5
)

temp <- temp[(rownames(temp) %in% Brennecke_HVG), ]
temp <- temp %>% t()
seq_hvg <- cbind(Cell = seq_raw[,1], as.data.frame(temp))


## Generate reduced seq sets ==================================================
seq_raw_k05 <- seq_raw[, (names(seq_raw) %in% c("Cell", as.character(k05$V1)))]
seq_target_k05 <- seq_target[, (names(seq_target) %in% c("Cell", as.character(k05$V1)))]
seq_cell_k05 <- seq_cell[, (names(seq_cell) %in% c("Cell", as.character(k05$V1)))]

seq_raw_k2 <- seq_raw[, (names(seq_raw) %in% c("Cell", as.character(k2$V1)))]
seq_target_k2 <- seq_target[, (names(seq_target) %in% c("Cell", as.character(k2$V1)))]
seq_cell_k2 <- seq_cell[, (names(seq_cell) %in% c("Cell", as.character(k2$V1)))]
```


# Cluster Estimation ----------------------------------------------------------
```{r automated approach}
## using NbClust to churn out predictions =====================================
automated_clust_k <- function(current.df = use.input.df[, -1], current.max.k = max.k) {
  # nb <- NbClust(use.input.df, diss="NULL", distance = "euclidean",
  #        min.nc=2, max.nc=max.k, method = "kmeans",
  #        index = "alllong", alphaBeale = 0.1)
  # hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])))

  # nb <- NbClust(use.input.df[, -1], distance = "euclidean", min.nc=2, max.nc=max.k, method = "ward.D", index = "all")
  # hist(nb$Best.nc[1,],
  #     breaks = max(na.omit(nb$Best.nc[1,])))

  avail.methods <- c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans") #TODO this is fucking up the seq data. at least one of the methods (maybe "single"?) is breaking the loop
  avail.distances <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
  #Ideally this should be vectorized to speed up the process
  cluster.estimates <- list()
  for (use.method in avail.methods) {
    list1 <- list()
    for (use.distance in avail.distances) {
      nb <- NbClust(current.df,
        distance = use.distance,
        min.nc = 2, max.nc = current.max.k,
        method = use.method, index = "all"
      )
      list1[[length(list1) + 1]] <- nb$Best.nc["Number_clusters", ]
    }
    cluster.estimates[[length(cluster.estimates) + 1]] <- list1
  }

  new.df <- as.data.frame(matrix(nrow = length(avail.methods) * length(avail.distances), ncol = 28))
  new.df.names <- c("Method", "Distance", names(cluster.estimates[[1]][[1]]))
  names(new.df) <- new.df.names
  for (i in seq_along(avail.methods)) {
    for (j in seq_along(avail.distances)) {
      row.num.to.use <- length(avail.methods) * (i - 1) + j
      len.obj <- length(cluster.estimates[[i]][[j]])

      new.df[row.num.to.use, 1] <- avail.methods[i]
      new.df[row.num.to.use, 2] <- avail.distances[j]

      new.df[row.num.to.use, seq(from = 3, length.out = len.obj)] <- cluster.estimates[[i]][[j]]
    }
  }
  return(new.df)
}



clust1 <- automated_clust_k(mrna_raw[,-1], current.max.k = 11)
clust2 <- automated_clust_k(current.df = seq_raw_k05[,-1], current.max.k = 4)


for (i in c(
  "kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew", 
  "friedman", "rubin", "cindex", "db", "silhouette", "duda", "pseudot2", "beale", "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw"
)) {
  print(i)
  try(
    NbClust(as.matrix(seq_raw_k05[, -1]),
    distance = "euclidean",
    min.nc = 2, max.nc = 5,
    method = "kmeans", index = i
  )
  )
}

current.df = seq_pca[,-1]
current.max.k = current.max.k = 4





avail.methods <- c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans") #TODO this is fucking up the seq data. at least one of the methods (maybe "single"?) is breaking the loop
  avail.distances <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
  #Ideally this should be vectorized to speed up the process
  
avail.metrics <- c(  "kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew",   "friedman", "rubin", "cindex", "db", "silhouette", "duda", "pseudot2", "beale", "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw"
)
  
  cluster.estimates <- list()
  for (use.method in avail.methods) {
    list1 <- list()
    for (use.distance in avail.distances) {
      nbs <- vector()
      for (use.metric in avail.metrics){
        print(
          paste(as.character(use.method),
              as.character(use.distance),
              as.character(use.metric), sep = "."))
        
        try(
          nbs <<- NbClust(current.df,
        distance = use.distance,
        min.nc = 2, max.nc = current.max.k,
        method = use.method, index = use.metric
      )$Best.nc
        )
      }
      
      
      list1[[length(list1) + 1]] <- nb$Best.nc["Number_clusters", ]
    }
    cluster.estimates[[length(cluster.estimates) + 1]] <- list1
  }

  new.df <- as.data.frame(matrix(nrow = length(avail.methods) * length(avail.distances), ncol = 28))
  new.df.names <- c("Method", "Distance", names(cluster.estimates[[1]][[1]]))
  names(new.df) <- new.df.names
  for (i in seq_along(avail.methods)) {
    for (j in seq_along(avail.distances)) {
      row.num.to.use <- length(avail.methods) * (i - 1) + j
      len.obj <- length(cluster.estimates[[i]][[j]])

      new.df[row.num.to.use, 1] <- avail.methods[i]
      new.df[row.num.to.use, 2] <- avail.distances[j]

      new.df[row.num.to.use, seq(from = 3, length.out = len.obj)] <- cluster.estimates[[i]][[j]]
    }
  }
```

```{r iteratively call function}
# Initial Setup ---------------------------------------------------------------
#use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw
#name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
#max.k <- (nrow(use.input.df)/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.

use.datasets <- list(mrna_raw, mrna_target, mrna_cell, 
                     seq_pca, seq_target, seq_cell, seq_hvg, 
                     seq_raw_k05, seq_target_k05, seq_cell_k05, 
                     seq_raw_k2, seq_target_k2, seq_cell_k2)
use.names <- list("mrna_raw", "mrna_target", "mrna_cell", 
                     "seq_pca", "seq_target", "seq_cell", "seq_hvg", 
                     "seq_raw_k05", "seq_target_k05", "seq_cell_k05", 
                     "seq_raw_k2", "seq_target_k2", "seq_cell_k2")
guess_clust_list <- list()
for (i in seq(from = 1, to = length(guess_clust_list))){
  max.k <- (nrow(use.datasets[[i]])/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.
  guess_clust_list[[length(guess_clust_list)+1]] <- automated_clust_k(current.df = use.datasets[[i]][,-1], current.max.k = max.k)
}

walk(seq_along(guess_clust_list), function(x){
  write.csv(guess_clust_list[[x]], file = paste0(write.to.dir, use.names[[x]], "_kEstimate.csv"))
})
```



# Clustering
## k means
```{r def k }
get_kmeans_clustering <- function(input.df = mrna_raw[, -1],
                                  target.nclusters = 11) {
  kmeans.m <- kmeans(input.df, centers = target.nclusters)
  return(kmeans.m$cluster)
}

get_kmeans_clustering(input.df = mrna_raw[, -1])
get_kmeans_clustering(input.df = seq_raw_k05[, -1])


```

## Hierarchical Clustering
```{r def hierachical}
#https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html #great reference!
get_hierarchical_clustering <- function(input.df = mrna_target[,-1],
                                        target.nclusters = 11,
                                        use.method.dist = "cor",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10) {
  temp <- input.df

  temp.clust <- pvclust(t(temp),
    method.dist = use.method.dist,
    method.hclust = use.method.hclust,
    nboot = use.nboot
  )
  temp.clust <- as.dendrogram(temp.clust$hclust)

  assignment <- cutree(temp.clust, k = target.nclusters)[order.dendrogram(temp.clust)]

  return(assignment)
}
#hclust_methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")
#dist_methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", #"correlation", "uncentered")


get_hierarchical_clustering(input.df = mrna_raw[, -1],
                                        target.nclusters = 11,
                                        use.method.dist = "cor",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10)
get_hierarchical_clustering(input.df = seq_raw_k05[, -1],
                                        target.nclusters = 4,
                                        use.method.dist = "euclidean",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10)
```

## SNN-Cliq #2 tuning parameters (k, distance)
```{r def snn}
get_SNN_clustering <- function(input.df = mrna_raw[, -1],
                               use.k = 3,
                               use.distance = "euclidean") {
  temp <- input.df
  SNN(temp,
    outfile = paste0(getwd(), "/inst/extdata/output_files/temp_edges.txt"),
    k = use.k,
    distance = use.distance
  )
  warning("Ensure output makes sense: If directory permissions are not set correctly, this will return the most recently run clustering.")
  if (Sys.info()['sysname'] == "Windows"){
    # in CMD run:
    # Py\Cliq.py -i inst\extdata\output_files\temp_edges.txt -o inst\extdata\output_files\temp_clust.txt
    
    shell("Py\\Cliq.py -i inst\\extdata\\output_files\\temp_edges.txt -o inst\\extdata\\output_files\\temp_clust.txt")
  } else if (Sys.info()['sysname'] == "Darwin"){
    warning("get_SNN_clustering() hasn't been tested on macos!")
    #TODO edit this to work on unix systems
  } else {
    warning("get_SNN_clustering() hasn't been tested on linux!")
    #TODO edit this to work on unix systems
  }

  assignment <- read.table(paste0(getwd(), "/inst/extdata/output_files/temp_clust.txt"),
    header = FALSE, sep = "", dec = "."
  )
  return(assignment)
}


#TODO! this isn't actually running. output for the diff data is the same.
get_SNN_clustering(input.df = mrna_raw[, -1],
                               use.k = 3,
                               use.distance = "euclidean")

get_SNN_clustering(input.df = seq_raw_k05[, -1],
                               use.k = 3,
                               use.distance = "euclidean")
```

## Evaluation
```{r def eval}
get_cluster_comparisons <- function(reference.clustering = mrna_raw$Cell,
                                    generated.clustering) {
  if (length(reference.clustering) != length(generated.clustering)) {
    warning("Input vectors are not of the same length!")
  } else {
    # reference.clustering = mrna_raw$Cell
    # generated.clustering = kmeans.m$cluster
    output <- array(0, dim = 6)
    
    reference.clustering <- as.numeric(reference.clustering) %>% as.factor()
    generated.clustering <- as.numeric(generated.clustering) %>% as.factor()

    output <- NMF::purity(reference.clustering, generated.clustering)
    names(output) <- "Purity"
    # Get a lot of concurrance measures
    # https://davetang.org/muse/2017/09/21/adjusted-rand-index/
    output <- c(
      output,
      clues::adjustedRand(
        BiocGenerics::as.vector(reference.clustering),
        BiocGenerics::as.vector(generated.clustering)
      )
    )
    return(output)
  }
}

get_cluster_comparisons(
  reference.clustering = seq_raw_k05[, 1],
  generated.clustering = get_hierarchical_clustering(input.df = seq_raw_k05[, -1],
                                        target.nclusters = 4,
                                        use.method.dist = "euclidean",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10)
)

```

```{r}
generate_clusterings <- function(use.input.df = mrna_raw[, -1],
                                 kmeans_k.param = 11,
                                 hclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered"),
                                 hclust_clust.methods = c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2"),
                                 hclust_k.param = 11,
                                 hclust_nboot = 10,
                                 snnclust_k.param = c(3:9),
                                 snnclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski"),
                                 winnow.clusterings = FALSE) {

  ## K Means Clustering =========================================================
  temp <- map(kmeans_k.param, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })

  param.combinations <- paste("K", as.character(
    rep(kmeans_k.param, each = length(kmeans_k.param))
  ), sep = ".")

  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations


  ## Hierarchical Clustering ====================================================
  # use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  # use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")

  temp <- map(hclust_dist.methods, function(iter.dist) {
    map(hclust_clust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df,
        target.nclusters = hclust_k.param,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = hclust_nboot
      )
    })
  })

  param.combinations <- paste("H", as.character(
    rep(hclust_dist.methods, each = length(hclust_clust.methods))
  ), as.character(
    rep(hclust_clust.methods, times = length(hclust_dist.methods))
  ), sep = ".")

  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations


  ## SNN Clustering =============================================================
  if (TRUE == FALSE) {
    # TODO check this after SNN is running again

    # use.k.param <- c(3:9)
    # use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.

    temp <- map(snnclust_dist.methods, function(iter.dist) {
      map(snnclust_k.param, function(iter.k.param) {
        print(iter.dist)

        get_SNN_clustering(
          input.df = use.input.df,
          use.k = iter.k.param, # number of neigbhors should go up to 9 for scPCRc
          use.distance = iter.dist
        ) #
      })
    })

    param.combinations <- paste("SNN", as.character(
      rep(snnclust_dist.methods, each = length(snnclust_k.param))
    ), as.character(
      rep(snnclust_k.param, times = length(snnclust_dist.methods))
    ), sep = ".")

    SNN.clusters <- do.call(cbind.data.frame, temp)
    names(SNN.clusters) <- param.combinations
  }

  # Merge Data Frames -----------------------------------------------------------
  all.clusters <- cbind(K.clusters, H.clusters) # TODO %>% cbind(SNN.clusters)

  if (winnow.clusterings == TRUE) {
    # some clusterings fail and pass all values zero
    # Some have a TON of clusters
    num.clusters <- map(all.clusters, function(x) {
      print(max(x))
    }) %>% unlist() # get number of clusters in each group
    real.num <- use.input.df$Cell %>% as.numeric() %>% max()
    selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.
    all.clusters <- all.clusters[, selection.vector]
  }
  return(all.clusters)
}


out1 <- generate_clusterings(use.input.df = mrna_raw[, -1],
                                 kmeans_k.param = 11,
                                 hclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered"),
                                 hclust_clust.methods = c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2"),
                                 hclust_k.param = 11,
                                 hclust_nboot = 10,
                                 snnclust_k.param = c(3:9),
                                 snnclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski"),
                                 winnow.clusterings = FALSE)



score_cluster_df <- function(generated.cluster.df = out1,
                             true.clusters = mrna_raw[, 1]) {
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(true.clusters), generated.cluster.df)

  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = true.clusters, generated.clustering = iter.param)
  })

  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)

  return(all.clusters.scores)
}



out2 <- generate_clusterings(use.input.df = seq_cell_k05[, -1],
                                 kmeans_k.param = 4,
                                 hclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered"),
                                 hclust_clust.methods = c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2"),
                                 hclust_k.param = 4,
                                 hclust_nboot = 10,
                                 snnclust_k.param = c(3:9),
                                 snnclust_dist.methods = c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski"),
                                 winnow.clusterings = FALSE)

out3 <- score_cluster_df(generated.cluster.df = out2,
                             true.clusters = seq_cell_k05[, 1])
```



# Classification

```{r}
#Note: Must contain a column called "Cell"
run_supervised_models <- function(use.seed = 8743436,
                                  input.df = use.input.df){

#use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)

  
#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA
set.seed(use.seed)
ldam <- train(
  Cell ~ . ,
  data = input.df,
  method = "lda",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#return(list(knnm,ldam,nnmm,nnm,rfm,svm.rad,svm.lin))
return(list(GLMNet=glmnetm,
                          kNN=knnm,
                          LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad, 
                          SVM.Linear=svm.lin))
}

out_raw <- run_supervised_models(use.seed = 8743436, input.df = mrna_raw)

#run_supervised_models(use.seed = 8743436, input.df = (seq_cell))
out_pca <- run_supervised_models(use.seed = 8743436, input.df = seq_pca[, 1:38])
out_0.2 <- run_supervised_models(use.seed = 8743436, input.df = diff_0.2)
out_0.05 <- run_supervised_models(use.seed = 8743436, input.df = diff_0.05)




rValues <- resamples(out_pca)
bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0, 1))

rValues <- resamples(out_raw)
bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0, 1))






ml_models <- list(out_pca)

for(i in 1:length(ml_models)){

out <- ml_models[[i]]

name.prefix <- c("pca_seq", "", "")[i]

rValues <- resamples(out)
bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0, 1))


#save the accuracies for future use
write.csv(as.data.frame(rValues$values), 
          file = paste0(write.to.dir, name.prefix,"_model_accuracy.csv"), 
          row.names = FALSE)

pdf(file = paste0(write.to.dir, name.prefix,"_Accuracy", ".pdf"))
  bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0,1))
  dev.off()
  
pdf(file = paste0(write.to.dir, name.prefix,"_Kappa", ".pdf"))
  bwplot(rValues, metric="Kappa", ylab = c("Models"), xlim = c(0,1))
  dev.off()
  
}
```




# Cluster Estimation
```{r}
use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw

name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
```

## Scree
```{r screeplot functions}
max.k <- (nrow(use.input.df)/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.

# Use map_dbl to run many models with varying value of k (centers)
tot_withinss <- map_dbl(1:max.k,  function(k){
  model <- kmeans(x = use.input.df[,-1], centers = k)
  model$tot.withinss
})

# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
  k = 1:max.k ,
  tot_withinss = tot_withinss
)

find_elbow <- elbow_df
flm <- lm(tot_withinss ~ k, data = find_elbow[c(1, nrow(find_elbow)),])

find_elbow$linear.predict <- flm$coef[[2]]*find_elbow$k + flm$coef[[1]]

#from sscClust. reproduced here because the library was not installing.
#' Find the knee point of the scree plot
#'
#' @param pcs principal component values sorted decreasingly
#' @details Given sorted decreasingly PCs, find the knee point which have the largest distance to
#' the line defined by the first point and the last point in the scree plot
#' @return index of the knee plot
findKneePoint <- function(pcs)
{
  npts <- length(pcs)
  if(npts<=3){
    return(npts)
  }else{
    P1 <- c(1,pcs[1])
    P2 <- c(npts,pcs[npts])
    v1 <- P1 - P2
    dd <- sapply(2:(npts-1),function(i){
      Pi <- c(i, pcs[i])
      v2 <- Pi - P1
      m <- cbind(v1,v2)
      d <- abs(det(m))/sqrt(sum(v1*v1))
    })
    return(which.max(dd))
  }
}

estimated.knee <- findKneePoint(find_elbow$tot_withinss)
actual.number.cell <- use.input.df$Cell %>% as.numeric() %>%  max()
```

```{r}
# Plot the elbow plot
fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="wss")+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  geom_vline(xintercept = estimated.knee, color = "steelblue", linetype = 2)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Total Within Group Sum of Squares",
       title  = paste0("Estimated Number of Clusters by Scree Plot", 
                       #"\n", as.character(estimated.knee), " Clusters Predicted", 
                       "\n", as.character(actual.number.cell), " Cell Types Present"))


ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_scree", ".pdf"), width = 12.8, height = 8.04)
```

## Silhouette
```{r}
fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="silhouette")+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Average Silhouette Width",
       title  = paste0("Estimated Number of Clusters by Silhouette", 
                       #"\n", as.character(estimated.knee), " Clusters Predicted", 
                       "\n", as.character(actual.number.cell), " Cell Types Present"))

ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_silhouette", ".pdf"), width = 12.8, height = 8.04)
#This shows the silhouettes for k=1
#pam(use.input.df[,-1], k = 11) %>% silhouette() %>% plot()
```

## Gap Statistic
```{r}
#Gap stat
set.seed(use.seed)
fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="gap_stat", 
             nstart = 25, nboot = 500)+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Gap Statistic (k)",
       title  = paste0("Estimated Number of Clusters by Scree Plot", 
                       #"\n", as.character(estimated.knee), " Clusters Predicted", 
                       "\n", as.character(actual.number.cell), " Cell Types Present"))

ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_gap_stat", ".pdf"), width = 12.8, height = 8.04)
```


