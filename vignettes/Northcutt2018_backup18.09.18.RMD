---
title: "Analysis for Northcutt et al. 2018"
author: "Daniel R. Kick"
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)

# General + Plotting ----------------------------------------------------------
library(tidyverse) #ggplot2, purrr, dplyr, tidyr mostly
library(cowplot) #clean up ggplots ands plotgrid

# Cluster Determination -------------------------------------------------------
library(factoextra) #for fviz_nbclust
library(NbClust) #to automate cluster determination for each dataset
# Clustering ------------------------------------------------------------------
library(BiocGenerics) # This is used for clustering assessment
library(pvclust) #for pvclust
library(dendextend) #for cutree coloring dendrograms
library(NMF) #used for calculating purity metric
library(clues) #used for calculating concurrance metrics


# Classification --------------------------------------------------------------
  #install.packages("caret", dependencies = c("Depends", "Suggests"))
library(caret) # for preProcess and supervised ML models


devtools::load_all() #needed to have access to SNN.R
```

```{r eval=FALSE, include=FALSE}
#general

library(rgl) #for 3d plots


#used in unsupervised ml
library(corrplot) #for corrplot
library(heatmap3) #for heatmap3
library(cluster) #for pam and clusplot
#library(sscClust) #Can't get installed
# For clustering comparison

library(Rtsne) #for t-SNE

#used supervised ml

library(matrixStats)
library(M3Drop)
devtools::load_all()

#from esynvmod
library("extrafont") #help with plotting
#font_import()
loadfonts(device = "win")
library("lemon") #clean up ggplots
library("ggthemes") #color plots
```


```{r Show info to aid reproducibility}
Sys.info()
```

```{r Conrol block}
#What should happen to plots?
#save
#show

#What should happen to output data?
#save
#show

run.snn.cliq <- TRUE # SNN Cliq depend on python. This scritp is written to work on windows and hasn't been tested on Unix/Macos. Needed file is in ../Py. At the point of writing, python version 3.7 has beed tested and works
write.to.dir <- paste0(getwd(), "/inst/extdata/output_files/")
use.seed <- 8743436
```


```{r Pull in datasets}
# Read in all data ------------------------------------------------------------
k05 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto0.05.csv")) %>% as.data.frame()
k2 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto0.2.csv")) %>% as.data.frame()
mrna_raw <- read.csv(paste0(getwd(),"/inst/extdata/RTqPCR.csv"), row.names = "Sample", header = TRUE) %>% as.data.frame()
#seq <- read.csv(paste0(getwd(),"/inst/extdata/scSeq.csv"))

# Transform RTqPCR data ------------------------------------------------------------
mrna_raw <- predict(preProcess(mrna_raw, method = c("medianImpute", "zv")), mrna_raw)
mrna_target <- predict(preProcess(mrna_raw, method = c("center", "scale")), mrna_raw)

mrna_cell <- mrna_raw[,-1]
mrna_cell <- as.data.frame(t(mrna_cell))
mrna_cell <- predict(preProcess(mrna_cell, method = c("center", "scale")), mrna_cell)
mrna_cell <- cbind(Cell = mrna_raw$Cell, as.data.frame(t(mrna_cell)))

# Read in all data ------------------------------------------------------------
```

# Cluster Estimation ----------------------------------------------------------

```{r setup}
# Initial Setup ---------------------------------------------------------------
use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw
name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
max.k <- (nrow(use.input.df)/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.
```

```{r manual testing k eval=FALSE, include=FALSE}

# Cluster Determination -------------------------------------------------------
## Screeplot functions ========================================================
#from sscClust. reproduced here because the library was not installing.
#' Find the knee point of the scree plot
#'
#' @param pcs principal component values sorted decreasingly
#' @details Given sorted decreasingly PCs, find the knee point which have the largest distance to
#' the line defined by the first point and the last point in the scree plot
#' @return index of the knee plot
findKneePoint <- function(pcs)
{
  npts <- length(pcs)
  if(npts<=3){
    return(npts)
  }else{
    P1 <- c(1,pcs[1])
    P2 <- c(npts,pcs[npts])
    v1 <- P1 - P2
    dd <- sapply(2:(npts-1),function(i){
      Pi <- c(i, pcs[i])
      v2 <- Pi - P1
      m <- cbind(v1,v2)
      d <- abs(det(m))/sqrt(sum(v1*v1))
    })
    return(which.max(dd))
  }
}

## Screeplot ==================================================================
# Use map_dbl to run many models with varying value of k (centers)
tot_withinss <- map_dbl(1:max.k,  function(k){
  model <- kmeans(x = use.input.df[,-1], centers = k)
  model$tot.withinss
})

# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
  k = 1:max.k ,
  tot_withinss = tot_withinss
)

find_elbow <- elbow_df
flm <- lm(tot_withinss ~ k, data = find_elbow[c(1, nrow(find_elbow)),])

find_elbow$linear.predict <- flm$coef[[2]]*find_elbow$k + flm$coef[[1]]
estimated.knee <- findKneePoint(find_elbow$tot_withinss)

actual.number.cell <- use.input.df$Cell %>% as.numeric() %>%  max()


# Plot the elbow plot
scree_plt <- fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="wss")+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  geom_vline(xintercept = estimated.knee, color = "steelblue", linetype = 2)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Total Within Group Sum of Squares",
       title  = paste0("Estimated Number of Clusters by Scree Plot",
                       #"\n", as.character(estimated.knee), " Clusters Predicted",
                       "\n", as.character(actual.number.cell), " Cell Types Present"))

#ggsave(scree_plt, device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_scree", ".pdf"), width = 12.8, height = 8.04)



df = structure(list(Birthrate = c(18.2, 8.5, 54.1, 1.4, 2.1, 83.6,
17, 1, 0.8, 61.7, 4.9, 7.9, 2, 14.2, 48.2, 17.1, 10.4, 37.5,
1.6, 49.5, 10.8, 6.2, 7.1, 7.8, 3, 3.7, 4.2, 8.7), GDP = c(1.22,
0.06, 0, 0.54, 2.34, 0.74, 1.03, 1.21, 0, 0.2, 1.41, 0.79, 2.75,
0.03, 11.13, 0.05, 2.99, 0.71, 0, 0.9, 1.15, 0, 1.15, 1.44, 0,
0.71, 1.21, 1.45), Income = c(11.56, 146.75, 167.23, 7, 7, 7,
10.07, 7, 7, 7, 47.43, 20.42, 7.52, 7, 7, 15.98, 15.15, 20.42,
7, 22.6, 7, 7, 18.55, 7, 7.7, 7, 7, 7), Population = c(54, 94,
37, 95, 98, 31, 78, 97, 95, 74, 74, 81, 95, 16, 44, 63, 95, 20,
95, 83, 98, 98, 84, 62, 98, 98, 97, 98)), .Names = c("Birthrate",
"GDP", "Income", "Population"), class = "data.frame", row.names = c(NA,
-28L))

WSS = sapply(1:20, FUN=function(k) {
  kmeans(df, centers=k, nstart=5)$tot.withinss
})
plot(1:20, WSS, type="l")
abline(v=5, col="red", lty=2)

min(which(diff(diff(WSS)) < 0)) - 3
## Screeplot ==================================================================

## Silhouette method ==========================================================
### kmeans =====================================================================
fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="silhouette")+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Average Silhouette Width",
       title  = paste0("Estimated Number of Clusters by Silhouette",
                       #"\n", as.character(estimated.knee), " Clusters Predicted",
                       "\n", as.character(actual.number.cell), " Cell Types Present"))

#ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_silhouette", ".pdf"), width = 12.8, height = 8.04)

#This shows the silhouettes for k=1
#pam(use.input.df[,-1], k = 11) %>% silhouette() %>% plot()

### Partition around metroids ==================================================
library(fpc)
library(cluster)
pamk.best <- fpc::pamk(use.input.df[,-1])

cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(cluster::pam(use.input.df[,-1], pamk.best$nc))

asw <- numeric(max.k)
for (k in 2:max.k){
  asw[[k]] <- pam(use.input.df[,-1], k) $ silinfo $ avg.width
}

k.best <- which.max(asw)
cat("silhouette-optimal number of clusters:", k.best, "\n")

## hclust silhouette ==========================================================
fviz_nbclust(scale(use.input.df[,-1], center = TRUE,  scale = TRUE),
             hcut, method = "silhouette",
             hc_method = "complete")

## Calinsky criterion =========================================================
library(vegan)
fit <- cascadeKM(scale(use.input.df[,-1], center = TRUE,  scale = TRUE), 1, 10, iter = 1000)
plot(fit, sortg = TRUE, grpmts.plot = TRUE)
calinski.best <- as.numeric(which.max(fit$results[2,]))
cat("Calinski criterion optimal number of clusters:", calinski.best, "\n")

## Bayesian Information Criterion =============================================
library(mclust)
bic_clust <- Mclust((as.matrix(use.input.df[,-1])), G = 1:max.k)
m.best <- dim(bic_clust$z)[2]
cat("model-based optimal number of clusters:", m.best, "\n")
#plot(bic_clust)

## Partition around metroids ==================================================
library(apcluster)
d.apclus <- apcluster(negDistMat(r=2), use.input.df[,-1])
cat("affinity propogation optimal number of clusters:", length(d.apclus@clusters), "\n")

heatmap(d.apclus)
#plot(d.apclus, use.input.df[,-1])

## Gap statistic ==============================================================
set.seed(use.seed)
cluster::clusGap(use.input.df[, - 1], kmeans, max.k, B = 100, verbose = interactive())

#Gap stat (orgiinal way)
set.seed(use.seed)
fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="gap_stat",
             nstart = 25, nboot = 100)+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Gap Statistic (k)",
       title  = paste0("Estimated Number of Clusters by Scree Plot",
                       #"\n", as.character(estimated.knee), " Clusters Predicted",
                       "\n", as.character(actual.number.cell), " Cell Types Present"))

#ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_gap_stat", ".pdf"), width = 12.8, height = 8.04)




#  ------------------------------------------------------------
#  ------------------------------------------------------------
#  ------------------------------------------------------------


#https://stackoverflow.com/questions/37012142/r-retrieve-optimal-number-of-clusters-from-scree-plot-

```

```{r automated approach}
## using NbClust to churn out predictions =====================================
automated_clust_k <- function(current.df = use.input.df[, -1], current.max.k = max.k) {
  # nb <- NbClust(use.input.df, diss="NULL", distance = "euclidean",
  #        min.nc=2, max.nc=max.k, method = "kmeans",
  #        index = "alllong", alphaBeale = 0.1)
  # hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])))

  # nb <- NbClust(use.input.df[, -1], distance = "euclidean", min.nc=2, max.nc=max.k, method = "ward.D", index = "all")
  # hist(nb$Best.nc[1,],
  #     breaks = max(na.omit(nb$Best.nc[1,])))

  avail.methods <- c("ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans")
  avail.distances <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski")
  #TODO Ideally this should be vectorized to speed up the process
  cluster.estimates <- list()
  for (use.method in avail.methods) {
    list1 <- list()
    for (use.distance in avail.distances) {
      nb <- NbClust(current.df,
        distance = use.distance,
        min.nc = 2, max.nc = current.max.k,
        method = "ward.D", index = "all"
      )
      list1[[length(list1) + 1]] <- nb$Best.nc["Number_clusters", ]
    }
    cluster.estimates[[length(cluster.estimates) + 1]] <- list1
  }

  new.df <- as.data.frame(matrix(nrow = length(avail.methods) * length(avail.distances), ncol = 28))
  new.df.names <- c("Method", "Distance", names(cluster.estimates[[1]][[1]]))
  names(new.df) <- new.df.names
  for (i in seq_along(avail.methods)) {
    for (j in seq_along(avail.distances)) {
      row.num.to.use <- length(avail.methods) * (i - 1) + j
      len.obj <- length(cluster.estimates[[i]][[j]])

      new.df[row.num.to.use, 1] <- avail.methods[i]
      new.df[row.num.to.use, 2] <- avail.distances[j]

      new.df[row.num.to.use, seq(from = 3, length.out = len.obj)] <- cluster.estimates[[i]][[j]]
    }
  }
  return(new.df)
}
```

```{r iteratively call function}
set_of_ks <- automated_clust_k(current.df = use.input.df[, -1], current.max.k = max.k)
```


# Unsupervised Machine Learning
```{r automate clustering}
# Methods ---------------------------------------------------------------------

## k means ====================================================================
get_kmeans_clustering <- function(input.df = mrna_raw,
                                  target.nclusters = 11) {
  kmeans.m <- kmeans(input.df[, -1], centers = 11)
  return(kmeans.m$cluster)
}

## H cluster ==================================================================
#https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html #great reference!
get_hierarchical_clustering <- function(input.df = mrna_target,
                                        target.nclusters = 12,
                                        use.method.dist = "cor",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10) {
  temp <- input.df[, -1]

  temp.clust <- pvclust(t(temp),
    method.dist = use.method.dist,
    method.hclust = use.method.hclust,
    nboot = use.nboot
  )
  temp.clust <- as.dendrogram(temp.clust$hclust)

  assignment <- cutree(temp.clust, k = target.nclusters)[order.dendrogram(temp.clust)]

  return(assignment)
}
#hclust_methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")
#dist_methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", #"correlation", "uncentered")

## SNN-Cliq ===================================================================
#2 tuning parameters (k, distance)
get_SNN_clustering <- function(input.df = mrna_raw,
                               use.k = 3,
                               use.distance = "euclidean") {
  temp <- input.df[, -1]
  SNN(temp,
    outfile = paste0(getwd(), "/inst/extdata/output_files/temp_edges.txt"),
    k = use.k,
    distance = use.distance
  )

  if (Sys.info()['sysname'] == "Windows"){
    # in CMD run:
    # Py\Cliq.py -i inst\extdata\output_files\temp_edges.txt -o inst\extdata\output_files\temp_clust.txt
    shell("Py\\Cliq.py -i inst\\extdata\\output_files\\temp_edges.txt -o inst\\extdata\\output_files\\temp_clust.txt")
  } else if (Sys.info()['sysname'] == "Darwin"){
    warning("get_SNN_clustering() hasn't been tested on macos!")
    #TODO edit this to work on unix systems
  } else {
    warning("get_SNN_clustering() hasn't been tested on linux!")
    #TODO edit this to work on unix systems
  }

  assignment <- read.table(paste0(getwd(), "/inst/extdata/output_files/temp_clust.txt"),
    header = FALSE, sep = "", dec = "."
  )
  return(assignment)
}

## Evaluate clustering performance ==========================================
get_cluster_comparisons <- function(reference.clustering = mrna_raw$Cell,
                                    generated.clustering) {
  if (length(reference.clustering) != length(generated.clustering)) {
    warning("Input vectors are not of the same length!")
  } else {
    # reference.clustering = mrna_raw$Cell
    # generated.clustering = kmeans.m$cluster
    output <- array(0, dim = 6)

    reference.clustering <- as.numeric(reference.clustering) %>% as.factor()
    generated.clustering <- as.numeric(generated.clustering) %>% as.factor()

    output <- NMF::purity(reference.clustering, generated.clustering)
    names(output) <- "Purity"
    # Get a lot of concurrance measures
    # https://davetang.org/muse/2017/09/21/adjusted-rand-index/
    output <- c(
      output,
      clues::adjustedRand(
        BiocGenerics::as.vector(reference.clustering),
        BiocGenerics::as.vector(generated.clustering)
      )
    )
    return(output)
  }
}


```

```{r clusting inputs}
# for use in block "Run clusterings"
use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw
# for use in block "eval clusterings"
name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"

use.k.param.kmeans <- c(11)
use.k.param.hclust <- c(11)
use.k.param.snncliq <- c(3:9) #number of neighbors to consider
```

```{r}
## sweep over free clustering parameters ======================================
evaluate_clust_params <- function(use.input.df = mrna_raw, # mrna_cell #mrna_target #mrna_raw
                                 name.prefix = "raw_qpcr", # "cell_qpcr" #"target_qpcr" #"raw_qpcr"
                                 use.k.param.kmeans = c(11),
                                 use.k.param.hclust = c(11),
                                 use.k.param.snncliq = c(3:9) # number of neighbors to consider
) {

  # Generate Clusterings --------------------------------------------------------
  ## K Means Clustering =========================================================
  # use.k.param <- c(11)

  temp <- map(use.k.param.kmeans, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })

  param.combinations <- paste("K", as.character(
    rep(use.k.param.kmeans, each = length(use.k.param.kmeans))
  ), sep = ".")

  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations

  ## Hierarchical Clustering ====================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.hclust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df,
        target.nclusters = use.k.param.hclust,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = 10
      )
    })
  })

  param.combinations <- paste("H", as.character(
    rep(use.dist.methods, each = length(use.hclust.methods))
  ), as.character(
    rep(use.hclust.methods, times = length(use.dist.methods))
  ), sep = ".")

  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations
  ## SNN Clustering =============================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.k.param.snncliq, function(iter.k.param) {
      print(iter.dist)

      get_SNN_clustering(
        input.df = use.input.df,
        use.k = iter.k.param, # number of neigbhors should go up to 9 for scPCRc
        use.distance = iter.dist
      ) #
    })
  })

  param.combinations <- paste("SNN", as.character(
    rep(use.dist.methods, each = length(use.k.param.snncliq))
  ), as.character(
    rep(use.k.param.snncliq, times = length(use.dist.methods))
  ), sep = ".")


  SNN.clusters <- do.call(cbind.data.frame, temp)
  names(SNN.clusters) <- param.combinations

  # Evaluate and summarize clusters ---------------------------------------------
  ## Merge Data Frames ==========================================================
  all.clusters <- cbind(K.clusters, H.clusters) %>% cbind(SNN.clusters)
  # some clusterings fail and assing all values zero
  # Some have a TON of clusters
  num.clusters <- map(all.clusters, function(x) {
    print(max(x))
  }) %>% unlist() # get number of clusters in each group
  real.num <- use.input.df$Cell %>% as.numeric() %>% max()
  selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.

  all.clusters <- all.clusters[, selection.vector]
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(use.input.df$Cell), all.clusters[])

  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = use.input.df$Cell, generated.clustering = iter.param)
  })

  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)

  all.clusters.scores.long <- gather(all.clusters.scores, Metric, Value, 1:6)

  ## Return long version of scores ============================================
  return(list(all.clusters.scores, all.clusters.scores.long))
}


all.clusters.scores.long <- evaluate_clust_params(
  use.input.df = mrna_raw, # mrna_cell #mrna_target #mrna_raw
  name.prefix = "raw_qpcr", # "cell_qpcr" #"target_qpcr" #"raw_qpcr"
  use.k.param.kmeans = c(11),
  use.k.param.hclust = c(11),
  use.k.param.snncliq = c(3:9)
)


all.clusters.scores <- all.clusters.scores.long[[1]]


```


```{r}
# run all defined methods -----------------------------------------------------
```

The below code isn't super helpful. the geom_tile is a helpful trick, and we do need to write out the data, but that's it.
```{r eval=FALSE, include=FALSE}
## Make plots of scores =======================================================
score.list <- map(1:6, function(current.col) {
  # metric.labels <- c("Purity", "Rand", "HA", "MA", "FM", "Jaccard")
  metric.labels <- c("Purity", "Rand index", "Hubert and Arabie's ARI", "Morey and Agresti's ARI", "Fowlkes and Mallows's index", "Jaccard index")
  ggplot(all.clusters.scores, aes(x = Clustering, y = all.clusters.scores[, current.col])) +
    geom_point(size = 3, aes(color = all.clusters.scores[, current.col])) +
    scale_color_continuous(low = "steelblue", high = "firebrick") +
    geom_segment(aes(
      x = Clustering,
      xend = Clustering,
      y = 0,
      yend = all.clusters.scores[, current.col]
    )) +
    labs(y = metric.labels[current.col]) +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1),
      legend.position = ""
    )
})

# cowplot::plot_grid(plotlist = score.list)
score.heatmap <- ggplot(all.clusters.scores.long, aes(x = Clustering, y = Metric)) +
  geom_tile(aes(fill = Value), color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

score.list[[length(score.list) + 1]] <- score.heatmap


## write out diagnostic plots =================================================

walk(1:length(score.list), function(i) {
  plot.list <<- score.list

  ggsave(plot = plot.list[[i]], device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_", i, ".pdf"), width = 12.8, height = 8.04)
})

# clusters
write.csv(all.clusters, file = paste0(write.to.dir, name.prefix, "_clusterings.csv"))
# cluster scores
write.csv(all.clusters.scores, file = paste0(write.to.dir, name.prefix, "_cluster_scores.csv"))
# }
```

This is now depricated!
```{r Run clusterings, eval=FALSE, include=FALSE}
#all.dfs <- list(mrna_raw, mrna_target, mrna_cell)
#all.prefixes <- c("raw_qpcr", "target_qpcr", "cell_qpcr")


#for (JJ in seq_along(all.dfs)) {
#  if (length(all.dfs) != length(all.prefixes)) {
#    warning("Dfs and Names of inequal length!")
#  }
#  use.input.df <- all.dfs[[JJ]]
#  name.prefix <- all.prefixes[JJ]


  ## K Means Clustering =========================================================
  use.k.param <- c(11)

  temp <- map(use.k.param, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })

  param.combinations <- paste("K", as.character(
    rep(use.k.param, each = length(use.k.param))
  ), sep = ".")

  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations

  ## Hierarchical Clustering ====================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.hclust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df,
        target.nclusters = 11,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = 10
      )
    })
  })


  param.combinations <- paste("H", as.character(
    rep(use.dist.methods, each = length(use.hclust.methods))
  ), as.character(
    rep(use.hclust.methods, times = length(use.dist.methods))
  ), sep = ".")

  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations
  ## SNN Clustering =============================================================

  use.k.param <- c(3:9)
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.k.param, function(iter.k.param) {
      print(iter.dist)

      get_SNN_clustering(
        input.df = use.input.df,
        use.k = iter.k.param, # number of neigbhors should go up to 9 for scPCRc
        use.distance = iter.dist
      ) #
    })
  })

  param.combinations <- paste("SNN", as.character(
    rep(use.dist.methods, each = length(use.k.param))
  ), as.character(
    rep(use.k.param, times = length(use.dist.methods))
  ), sep = ".")


  SNN.clusters <- do.call(cbind.data.frame, temp)
  names(SNN.clusters) <- param.combinations

  ## SCRATTCH Clustering ========================================================

  # TODO get_SCRATTCH_clustering



#{r eval clusterings}
  ## Merge Data Frames ==========================================================
  all.clusters <- cbind(K.clusters, H.clusters) %>% cbind(SNN.clusters) # TODO add SCRATTCH
  # some clusterings fail and assing all values zero
  # Some have a TON of clusters
  num.clusters <- map(all.clusters, function(x) {
    print(max(x))
  }) %>% unlist() # get number of clusters in each group
  real.num <- use.input.df$Cell %>% as.numeric() %>% max()
  selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.

  all.clusters <- all.clusters[, selection.vector]
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(use.input.df$Cell), all.clusters[])



  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = use.input.df$Cell, generated.clustering = iter.param)
  })

  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)

  all.clusters.scores.long <- gather(all.clusters.scores, Metric, Value, 1:6)

  ## Make plots of scores =======================================================

  score.list <- map(1:6, function(current.col) {
    # metric.labels <- c("Purity", "Rand", "HA", "MA", "FM", "Jaccard")
    metric.labels <- c("Purity", "Rand index", "Hubert and Arabie's ARI", "Morey and Agresti's ARI", "Fowlkes and Mallows's index", "Jaccard index")
    ggplot(all.clusters.scores, aes(x = Clustering, y = all.clusters.scores[, current.col])) +
      geom_point(size = 3, aes(color = all.clusters.scores[, current.col])) +
      scale_color_continuous(low = "steelblue", high = "firebrick") +
      geom_segment(aes(
        x = Clustering,
        xend = Clustering,
        y = 0,
        yend = all.clusters.scores[, current.col]
      )) +
      labs(y = metric.labels[current.col]) +
      theme(
        axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = ""
      )
  })

  # cowplot::plot_grid(plotlist = score.list)
  score.heatmap <- ggplot(all.clusters.scores.long, aes(x = Clustering, y = Metric)) +
    geom_tile(aes(fill = Value), color = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

  score.list[[length(score.list) + 1]] <- score.heatmap


  ## write out diagnostic plots =================================================

  walk(1:length(score.list), function(i) {
    plot.list <<- score.list

    ggsave(plot = plot.list[[i]], device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_", i, ".pdf"), width = 12.8, height = 8.04)
  })

  # clusters
  write.csv(all.clusters, file = paste0(write.to.dir, name.prefix, "_clusterings.csv"))
  # cluster scores
  write.csv(all.clusters.scores, file = paste0(write.to.dir, name.prefix, "_cluster_scores.csv"))
#}
```


Once we know the best clusterings...
pcr
```{r plot best pcr, eval=FALSE}
## Plot the best scoring clusters =============================================

#for pcr best are h clust with correlation and ward.d2

#"G:/MolecularCellClassification/inst/extdata/output_files/raw_qpcr_clusterings.csv"
r.df <- read.csv(paste0(write.to.dir, "raw_qpcr_clusterings.csv")) %>% as.data.frame() %>% .[,c("Cell.Type", "H.correlation.ward.D2")]
t.df <- read.csv(paste0(write.to.dir, "target_qpcr_clusterings.csv")) %>% as.data.frame() %>% .[,c("Cell.Type", "H.correlation.ward.D2")]
c.df <- read.csv(paste0(write.to.dir, "cell_qpcr_clusterings.csv")) %>% as.data.frame() %>% .[,c("Cell.Type", "H.correlation.ward.D2")]

names(r.df) <- c("Cell.Type", "H.correlation.ward.D2")
names(t.df) <- c("Cell.Type", "Scaled.mRNAs.H.correlation.ward.D2")
names(c.df) <- c("Cell.Type", "Scaled.cells.H.correlation.ward.D2")
r.df$Cell.Index <- 1:nrow(r.df)
#best.clusters$cell.index <- 1:nrow(best.clusters)
best.clusters <- full_join(r.df, t.df) %>% full_join(c.df)
best.clusters <- best.clusters %>% gather(Clustering, Group, names(best.clusters)[!(names(best.clusters) %in% c( "Cell.Index"))])

ggplot(best.clusters, aes(x=Clustering, y=Cell.Index, fill=as.factor(Group)))+
  geom_raster()+
  theme(axis.text.x=element_text(angle = 45, hjust=1), legend.position = "")

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr", "_best", ".pdf"), width = 12.8, height = 8.04)

## Plot heatmap ===============================================================
pdf(file = paste0(write.to.dir, "qpcr", "_heatmap", ".pdf"))
  heatmap3::heatmap3(mrna_raw[,-1], method = "ward.D2")
  dev.off()

## Plot dendrograms of best ===================================================

tree.1 <- pvclust(t(mrna_raw[,-1]),
    method.dist = "cor",
    method.hclust = "ward.D2",
    nboot = 100
  )$hclust %>% as.dendrogram() %>%
  dendextend::set("labels_cex", 1) %>%
  dendextend::color_branches(k = 11) %>%
  dendextend::set("labels_col", value = 1:11, k=11)
  #dendextend::rect.dendrogram(k=12) %>%
as.ggdend(tree.1)

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr_raw", "_tree", ".pdf"), width = 12.8, height = 8.04)

tree.2 <- pvclust(t(mrna_target[,-1]),#FIXME
    method.dist = "cor",
    method.hclust = "ward.D2",
    nboot = 100
  )$hclust %>% as.dendrogram() %>%
  dendextend::set("labels_cex", 1) %>%
  dendextend::color_branches(k = 11) %>%
  dendextend::set("labels_col", value = 1:11, k=11)
  #dendextend::rect.dendrogram(k=12) %>%
as.ggdend(tree.2)

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr_target", "_tree", ".pdf"), width = 12.8, height = 8.04)

```

Plotting with respect to cell id
```{r eval=FALSE, include=FALSE}
# Number cells so we get a nice plot
input.df = mrna_raw

input.df.2 <- input.df
num_in_df <- as.data.frame(count(input.df.2, Cell))
input.df.2$cell_index <- 0
for (i in 1:nrow(num_in_df)){
    input.df.2[input.df.2$Cell == num_in_df[i, "Cell"], "cell_index"] <-
      seq(from = 1, to = num_in_df[i, "n"], by = 1)
}

cell_index <- as.factor(input.df.2[["cell_index"]])

input.df.2 <- input.df.2[, !(names(input.df.2) %in% c("cell_index"))]

mutate(input.df.2, cluster = as.factor(kmeans.m$cluster)) %>%
  ggplot( aes(x = Cell, y = cell_index))+
    geom_point(size = 10, shape = 15, alpha = 0.5, aes(color = cluster))+
    #scale_shape_manual(values= 1:nlevels(plot_me$cluster)) +
    scale_shape_manual(values= 1:12) +
    geom_point(size = 5, aes(shape = cluster))
```




# Supervised Machine Learning
```{r}
#use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw

#name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
```


## Models and basic plots
```{r}
#Note: Must contain a column called "Cell"
run_supervised_models <- function(use.seed = 8743436,
                                  input.df = use.input.df){

#use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)


#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA
set.seed(use.seed)
ldam <- train(
  Cell ~ . ,
  data = input.df,
  method = "lda",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#return(list(knnm,ldam,nnmm,nnm,rfm,svm.rad,svm.lin))
return(list(GLMNet=glmnetm,
                          kNN=knnm,
                          LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad,
                          SVM.Linear=svm.lin))
}



ml_models <- map(1:3, function(i){
  use.input.df <- list(mrna_cell, mrna_target, mrna_raw)
  #out <- run_supervised_models(use.seed = 8743436, input.df = use.input.df)
  run_supervised_models(use.seed = 8743436, input.df = use.input.df[[i]])

})

for(i in 1:3){

out <- ml_models[[i]]

name.prefix <- c("cell_qpcr", "target_qpcr", "raw_qpcr")

rValues <- resamples(out)

#save the accuracies for future use
write.csv(as.data.frame(rValues$values),
          file = paste0(write.to.dir, name.prefix,"_model_accuracy.csv"),
          row.names = FALSE)

pdf(file = paste0(write.to.dir, name.prefix[i],"_Accuracy", ".pdf"))
  bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0,1))
  dev.off()

pdf(file = paste0(write.to.dir, name.prefix[i],"_Kappa", ".pdf"))
  bwplot(rValues, metric="Kappa", ylab = c("Models"), xlim = c(0,1))
  dev.off()

}

```

Plot selected models
```{r}
out <- ml_models[[2]]

pdf(file = paste0(write.to.dir, "pcr_SVM", ".pdf"))
  varImp(out$SVM.Linear, scale=TRUE) %>%plot()
  dev.off()

pdf(file = paste0(write.to.dir, "pcr_glmnet", ".pdf"))
  varImp(out$GLMNet, scale=TRUE) %>%plot()
  dev.off()
```

# Repeat with Seq

```{r}
seq_raw <- read.csv(paste0(getwd(),"/inst/extdata/final_singleCell_kallisto_counts.csv"), row.names = "id", header = TRUE) %>% t() %>% as.data.frame()
seq_raw <- predict(preProcess(seq_raw, method = c("zv")), seq_raw)
seq_target <- predict(preProcess(seq_raw, method = c("center", "scale")), seq_raw)

seq_cell <- seq_raw
seq_cell <- as.data.frame(t(seq_cell))
seq_cell <- predict(preProcess(seq_cell, method = c("center", "scale")), seq_cell)
seq_cell <- as.data.frame(t(seq_cell))

split.names <- rownames(seq_raw) %>% strsplit("[.]")
split.names <- unlist(split.names)
Cell.ids <- split.names[seq(1, to = length(split.names), by = 2)]

seq_raw <- cbind(Cell = Cell.ids, seq_raw)
seq_target <- cbind(Cell = Cell.ids, seq_target)
seq_cell <- cbind(Cell = Cell.ids, seq_cell)
#seq_raw$Cell <- Cell.ids
#seq_target$Cell <- Cell.ids
#seq_cell$Cell <- Cell.ids


prcomp(t(seq_cell[,-1]), scale = FALSE) %>% get_eig()
prcomp(seq_cell[,-1], scale = FALSE) %>% get_eig()

#because the full seq is too much to work with locally:
seq_pca <- prcomp(seq_cell[,-1], scale = FALSE)
#pca <- prcomp(t(seq_cell[,-1]), scale = FALSE)
fviz_eig(seq_pca, addlabels = TRUE)
#plot3d(pca$x[,1:3], size = 20, labels = seq_raw$Cell, col = rainbow(4))
#play3d(spin3d(axis = c(0, 0, 1), rpm = 10), duration = 6)
factoextra::get_eigenvalue(seq_pca)

seq_pca <- cbind(seq_cell$Cell, as.data.frame(seq_pca$x))
seq_pca <- rename(seq_pca, Cell = `seq_cell$Cell`)


temp <- seq_raw[,-1]
temp <- t(temp)

x.data <- rowMeans(temp)
y.data <- matrixStats::rowVars(temp)

ggplot()+
  geom_point(aes(x = log10(x.data), y = log10(y.data)), shape = 1)

#https://hemberg-lab.github.io/scRNA.seq.course/biological-analysis.html#feature-selection

Brennecke_HVG <- M3Drop::BrenneckeGetVariableGenes(
  temp,
  fdr = 0.01,
  minBiolDisp = 0.5
)

temp <- temp[(rownames(temp) %in% Brennecke_HVG), ]
temp <- temp %>% t()
seq_hvg <- cbind(Cell = seq_raw[,1], as.data.frame(temp))
```




```{r}
use.input.df <- seq_raw #mrna_cell #mrna_target #mrna_raw
# for use in block "eval clusterings"
name.prefix <- "raw_seq" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
```

```{r}
all.dfs <- list(seq_raw, seq_target, seq_cell, seq_hvg)
all.prefixes <- c("raw_seq", "target_seq", "cell_seq", "hvg_seq")

all.dfs <- list(seq_hvg)
all.prefixes <- c("hvg_seq")

for (JJ in seq_along(all.dfs)) {
  if (length(all.dfs) != length(all.prefixes)) {
    warning("Dfs and Names of inequal length!")
  }
  # Data Setup ------------------------------------------------------------------
  use.input.df <- all.dfs[[JJ]]
  name.prefix <- all.prefixes[JJ]

  # Perform clusterings ---------------------------------------------------------
  ## K Means Clustering =========================================================
  use.k.param <- c(4)

  temp <- map(use.k.param, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })

  param.combinations <- paste("K", as.character(
    rep(use.k.param, each = length(use.k.param))
  ), sep = ".")

  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations

  ## Hierarchical Clustering ====================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.hclust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df,
        target.nclusters = 4,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = 10
      )
    })
  })


  param.combinations <- paste("H", as.character(
    rep(use.dist.methods, each = length(use.hclust.methods))
  ), as.character(
    rep(use.hclust.methods, times = length(use.dist.methods))
  ), sep = ".")

  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations
  ## SNN Clustering =============================================================

  use.k.param <- c(3:8) # 8 is the nubmer of the least common cell present
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.k.param, function(iter.k.param) {
      print(iter.dist)

      get_SNN_clustering(
        input.df = use.input.df,
        use.k = iter.k.param, #
        use.distance = iter.dist
      ) #
    })
  })

  param.combinations <- paste("SNN", as.character(
    rep(use.dist.methods, each = length(use.k.param))
  ), as.character(
    rep(use.k.param, times = length(use.dist.methods))
  ), sep = ".")


  SNN.clusters <- do.call(cbind.data.frame, temp)
  names(SNN.clusters) <- param.combinations



  # Figure and table write out --------------------------------------------------
  ## Merge Data Frames ==========================================================
  all.clusters <- cbind(K.clusters, H.clusters) %>% cbind(SNN.clusters) # TODO add SCRATTCH
  # some clusterings fail and assing all values zero
  # Some have a TON of clusters
  num.clusters <- map(all.clusters, function(x) {
    print(max(x))
  }) %>% unlist() # get number of clusters in each group
  real.num <- use.input.df$Cell %>% as.numeric() %>% max()
  selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.

  all.clusters <- all.clusters[, selection.vector]
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(use.input.df$Cell), all.clusters[])

  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = use.input.df$Cell, generated.clustering = iter.param)
  })

  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)

  all.clusters.scores.long <- gather(all.clusters.scores, Metric, Value, 1:6)

  ## Make plots of scores =======================================================

  score.list <- map(1:6, function(current.col) {
    # metric.labels <- c("Purity", "Rand", "HA", "MA", "FM", "Jaccard")
    metric.labels <- c("Purity", "Rand index", "Hubert and Arabie's ARI", "Morey and Agresti's ARI", "Fowlkes and Mallows's index", "Jaccard index")
    ggplot(all.clusters.scores, aes(x = Clustering, y = all.clusters.scores[, current.col])) +
      geom_point(size = 3, aes(color = all.clusters.scores[, current.col])) +
      scale_color_continuous(low = "steelblue", high = "firebrick") +
      geom_segment(aes(
        x = Clustering,
        xend = Clustering,
        y = 0,
        yend = all.clusters.scores[, current.col]
      )) +
      labs(y = metric.labels[current.col]) +
      theme(
        axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = ""
      )
  })

  # cowplot::plot_grid(plotlist = score.list)
  score.heatmap <- ggplot(all.clusters.scores.long, aes(x = Clustering, y = Metric)) +
    geom_tile(aes(fill = Value), color = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

  score.list[[length(score.list) + 1]] <- score.heatmap


  ## write out diagnostic plots =================================================

  walk(1:length(score.list), function(i) {
    plot.list <<- score.list

    ggsave(plot = plot.list[[i]], device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_", i, ".pdf"), width = 12.8, height = 8.04)
  })

  # clusters
  write.csv(all.clusters, file = paste0(write.to.dir, name.prefix, "_clusterings.csv"))
  # cluster scores
  write.csv(all.clusters.scores, file = paste0(write.to.dir, name.prefix, "_cluster_scores.csv"))
}
```

Once we know the best clusterings...
seq
```{r plot best pcr, eval=FALSE}
## Plot the best scoring clusters =============================================

#for pcr best are h clust with correlation and ward.d2

#"E:/MolecularCellClassification/inst/extdata/output_files/hvg_seq_clusterings.csv"
r.df <- read.csv(paste0(write.to.dir, "raw_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.euclidean.ward.D2",
  "H.maximum.ward.D2",
  "H.manhattan.ward.D2",
  "H.minkowski.ward.D2"
)]
t.df <- read.csv(paste0(write.to.dir, "target_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.canberra.ward.D"
)]
c.df <- read.csv(paste0(write.to.dir, "cell_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.canberra.ward.D"
)]
h.df <- read.csv(paste0(write.to.dir, "hvg_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.correlation.mcquitty"
)]

names(r.df) <- c(
  "Cell.Type",
  "r.H.euclidean.ward.D2",
  "r.H.maximum.ward.D2",
  "r.H.manhattan.ward.D2",
  "r.H.minkowski.ward.D2"
)
names(t.df) <- c("Cell.Type", "t.H.canberra.ward.D")
names(c.df) <- c("Cell.Type", "c.H.canberra.ward.D")
names(h.df) <- c("Cell.Type", "h.H.correlation.mcquitty")

r.df$Cell.Index <- 1:nrow(r.df)
#best.clusters$cell.index <- 1:nrow(best.clusters)
best.clusters <- full_join(r.df, t.df) %>% full_join(c.df) %>% full_join(h.df)
best.clusters <- best.clusters %>% gather(Clustering, Group, names(best.clusters)[!(names(best.clusters) %in% c( "Cell.Index"))])

ggplot(best.clusters, aes(x=Clustering, y=Cell.Index, fill=as.factor(Group)))+
  geom_raster()+
  theme(axis.text.x=element_text(angle = 45, hjust=1), legend.position = "")

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr", "_best", ".pdf"), width = 12.8, height = 8.04)

## Plot heatmap ===============================================================
pdf(file = paste0(write.to.dir, "qpcr", "_heatmap", ".pdf"))
  heatmap3::heatmap3(mrna_raw[,-1], method = "ward.D2")
  dev.off()

## Plot dendrograms of best ===================================================
tree.0 <- pvclust(t(seq_target[,-1]),
    method.dist = "canberra",
    method.hclust = "ward.D",
    nboot = 100
  )$hclust %>% as.dendrogram() %>%
  dendextend::set("labels_cex", 1) %>%
  dendextend::color_branches(k = 4) %>%
  dendextend::set("labels_col", value = 1:4, k=4)
  #dendextend::rect.dendrogram(k=12) %>%
as.ggdend(tree.0)


tree.1 <- pvclust(t(seq_raw[,-1]),
    method.dist = "euclidean",
    method.hclust = "ward.D2",
    nboot = 100
  )$hclust %>% as.dendrogram() %>%
  dendextend::set("labels_cex", 1) %>%
  dendextend::color_branches(k = 4) %>%
  dendextend::set("labels_col", value = 1:4, k=4)
  #dendextend::rect.dendrogram(k=12) %>%
as.ggdend(tree.1)


tree.2 <- pvclust(t(seq_hvg[,-1]),
    method.dist = "correlation",
    method.hclust = "mcquitty",
    nboot = 100
  )$hclust %>% as.dendrogram() %>%
  dendextend::set("labels_cex", 1) %>%
  dendextend::color_branches(k = 4) %>%
  dendextend::set("labels_col", value = 1:4, k=4)
  #dendextend::rect.dendrogram(k=12) %>%
as.ggdend(tree.2)


ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr_raw", "_tree", ".pdf"), width = 12.8, height = 8.04)



```


## DJS want screeplots and ML for scaled by cell data:
```{r}
#diff_0.05 <- read.csv(paste0(getwd(),"/inst/extdata/annotated_pooled_0.05_names.csv"), header=F)
#diff_0.20 <- read.csv(paste0(getwd(), "/inst/extdata/annotated_pooled_0.2_names.csv"), header=F)
diff_0.05 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto_0.05.csv"), header=F)
diff_0.2 <- read.csv(paste0(getwd(), "/inst/extdata/kallisto_0.2.csv"), header=F)

## our inputs: ================================================================
#seq_cell
diff_0.05 <- seq_cell[, diff_0.05$V1]
diff_0.2 <- seq_cell[, diff_0.2$V1]
```


### Screeplots
```{r}
#from sscClust. reproduced here because the library was not installing.
#' Find the knee point of the scree plot
#'
#' @param pcs principal component values sorted decreasingly
#' @details Given sorted decreasingly PCs, find the knee point which have the largest distance to
#' the line defined by the first point and the last point in the scree plot
#' @return index of the knee plot
findKneePoint <- function(pcs){
  npts <- length(pcs)
  if(npts<=3){
    return(npts)
  }else{
    P1 <- c(1,pcs[1])
    P2 <- c(npts,pcs[npts])
    v1 <- P1 - P2
    dd <- sapply(2:(npts-1),function(i){
      Pi <- c(i, pcs[i])
      v2 <- Pi - P1
      m <- cbind(v1,v2)
      d <- abs(det(m))/sqrt(sum(v1*v1))
    })
    return(which.max(dd))
  }
}

for (test.dfs in 1:3){
  print(test.dfs)
  all.input.dfs <- list(seq_cell, diff_0.2, diff_0.05)
  all.name.prefixs <- c("seq_cell", "diff_0.2", "diff_0.05")

  use.input.df <- all.input.dfs[[test.dfs]]
  name.prefix <- all.name.prefixs[test.dfs]

  # scree
  max.k <- (nrow(use.input.df) / 4) %>% ceiling() # assume at least 4 cells of the same type in each sample.

  # Use map_dbl to run many models with varying value of k (centers)
  tot_withinss <- map_dbl(seq(from = 1, to = max.k), function(k) {
    model <- kmeans(x = use.input.df[, !(names(use.input.df) %in% c("Cell"))], centers = k)
    model$tot.withinss
  })

  # Generate a data frame containing both k and tot_withinss
  elbow_df <- data.frame(
    k = 1:max.k,
    tot_withinss = tot_withinss
  )

  find_elbow <- elbow_df
  flm <- lm(tot_withinss ~ k, data = find_elbow[c(1, nrow(find_elbow)), ])

  find_elbow$linear.predict <- flm$coef[[2]] * find_elbow$k + flm$coef[[1]]


  estimated.knee <- findKneePoint(find_elbow$tot_withinss)
  actual.number.cell <- use.input.df$Cell %>% as.numeric() %>% max()


  # Plot the elbow plot
  fviz_nbclust(use.input.df[, !(names(use.input.df) %in% c("Cell"))],
    FUNcluster = kmeans,
    k.max = max.k, method = "wss"
  ) +
    geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3) +
    geom_vline(xintercept = estimated.knee, color = "steelblue", linetype = 2) +
    scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5)) +
    labs(
      x = "Number of Clusters",
      y = "Total Within Group Sum of Squares",
      title = paste0(
        "Estimated Number of Clusters by Scree Plot",
        # "\n", as.character(estimated.knee), " Clusters Predicted",
        "\n", as.character(actual.number.cell), " Cell Types Present"
      )
    )

  ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_scree", ".pdf"), width = 12.8, height = 8.04)
}
```


```{r}
use.seed = 8743436
input.df <- seq_pca
use.cv <- 5


use.seed = 8743436
input.df = seq_pca

#use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)


#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA
set.seed(use.seed)
ldam <- train(
  Cell ~ . ,
  data = input.df,
  method = "lda",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#return(list(knnm,ldam,nnmm,nnm,rfm,svm.rad,svm.lin))
out_pca <- list(GLMNet=glmnetm,
                          kNN=knnm,
                          #LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad,
                          SVM.Linear=svm.lin)





#run_supervised_models(use.seed = 8743436, input.df = (seq_cell))
out_pca <- run_supervised_models(use.seed = 8743436, input.df = seq_pca[, 1:38])
out_0.2 <- run_supervised_models(use.seed = 8743436, input.df = diff_0.2)
out_0.05 <- run_supervised_models(use.seed = 8743436, input.df = diff_0.05)

ml_models <- list(out_pca)

for(i in 1:length(ml_models)){

out <- ml_models[[i]]

name.prefix <- c("pca_seq", "", "")[i]

rValues <- resamples(out)
bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0, 1))


#save the accuracies for future use
write.csv(as.data.frame(rValues$values),
          file = paste0(write.to.dir, name.prefix,"_model_accuracy.csv"),
          row.names = FALSE)

pdf(file = paste0(write.to.dir, name.prefix,"_Accuracy", ".pdf"))
  bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0,1))
  dev.off()

pdf(file = paste0(write.to.dir, name.prefix,"_Kappa", ".pdf"))
  bwplot(rValues, metric="Kappa", ylab = c("Models"), xlim = c(0,1))
  dev.off()

}
```

