---
title: "qPCR_Analysis"
author: "Daniel R. Kick"
date: "July 26, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)

#general
library(tidyverse) #ggplot2, purrr, dplyr, tidyr mostly
library(cowplot) #clean up ggplots ands plotgrid
library(rgl) #for 3d plots


#used in unsupervised ml
library(NbClust)
library(factoextra) #for fviz_nbclust
library(corrplot) #for corrplot
library(pvclust) #for pvclust
library(heatmap3) #for heatmap3
library(dendextend) #for coloring dendrograms
library(cluster) #for pam and clusplot
#library(sscClust) #Can't get installed
# For clustering comparison
library(NMF)
library(BiocGenerics)
library(clues) 

library(Rtsne) #for t-SNE

#used supervised ml
#install.packages("caret", dependencies = c("Depends", "Suggests"))
library(caret) # for preProcess and supervised ML models


library(matrixStats)
library(M3Drop)
devtools::load_all()

```


```{r set up data}
write.to.dir <- "E:/MolecularCellClassification/inst/extdata/output_files/"

use.seed <- 8743436
mrna_raw <- read.csv(paste0(getwd(),"/inst/extdata/final_STG_LC_Absolute_Counts_allSTG-GM2.csv"), row.names = "Sample", header = TRUE) %>% as.data.frame()
mrna_raw <- predict(preProcess(mrna_raw, method = c("medianImpute", "zv")), mrna_raw)
mrna_target <- predict(preProcess(mrna_raw, method = c("center", "scale")), mrna_raw)

mrna_cell <- mrna_raw[,-1]
mrna_cell <- as.data.frame(t(mrna_cell))
mrna_cell <- predict(preProcess(mrna_cell, method = c("center", "scale")), mrna_cell)
mrna_cell <- cbind(Cell = mrna_raw$Cell, as.data.frame(t(mrna_cell)))
```


# Unsupervised Machine Learning
## k means
```{r def k }
get_kmeans_clustering <- function(input.df = mrna_raw,
                                  target.nclusters = 11) {
  kmeans.m <- kmeans(input.df[, -1], centers = 11)
  return(kmeans.m$cluster)
}
```

## Hierarchical Clustering

```{r def hierachical}
#https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html #great reference!
get_hierarchical_clustering <- function(input.df = mrna_target,
                                        target.nclusters = 12,
                                        use.method.dist = "cor",
                                        use.method.hclust = "ward.D",
                                        use.nboot = 10) {
  temp <- input.df[, -1]

  temp.clust <- pvclust(t(temp),
    method.dist = use.method.dist,
    method.hclust = use.method.hclust,
    nboot = use.nboot
  )
  temp.clust <- as.dendrogram(temp.clust$hclust)

  assignment <- cutree(temp.clust, k = target.nclusters)[order.dendrogram(temp.clust)]

  return(assignment)
}
#hclust_methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")
#dist_methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", #"correlation", "uncentered")
```

## SNN-Cliq #2 tuning parameters (k, distance)

```{r def snn}
get_SNN_clustering <- function(input.df = mrna_raw,
                               use.k = 3,
                               use.distance = "euclidean") {
  temp <- input.df[, -1]
  SNN(temp,
    outfile = paste0(getwd(), "/inst/extdata/output_files/temp_edges.txt"),
    k = use.k,
    distance = use.distance
  )
  
  if (Sys.info()['sysname'] == "Windows"){
    # in CMD run:
    # Py\Cliq.py -i inst\extdata\output_files\temp_edges.txt -o inst\extdata\output_files\temp_clust.txt
    shell("Py\\Cliq.py -i inst\\extdata\\output_files\\temp_edges.txt -o inst\\extdata\\output_files\\temp_clust.txt")
  } else if (Sys.info()['sysname'] == "Darwin"){
    warning("get_SNN_clustering() hasn't been tested on macos!")
    #TODO edit this to work on unix systems
  } else {
    warning("get_SNN_clustering() hasn't been tested on linux!")
    #TODO edit this to work on unix systems
  }

  assignment <- read.table(paste0(getwd(), "/inst/extdata/output_files/temp_clust.txt"),
    header = FALSE, sep = "", dec = "."
  )
  return(assignment)
}
```

## SCRATTCH/iCLUST

```{r}
#library(scrattch)
```


## Evaluation

```{r def eval}
get_cluster_comparisons <- function(reference.clustering = mrna_raw$Cell,
                                    generated.clustering) {
  if (length(reference.clustering) != length(generated.clustering)) {
    warning("Input vectors are not of the same length!")
  } else {
    # reference.clustering = mrna_raw$Cell
    # generated.clustering = kmeans.m$cluster
    output <- array(0, dim = 6)
    
    reference.clustering <- as.numeric(reference.clustering) %>% as.factor()
    generated.clustering <- as.numeric(generated.clustering) %>% as.factor()

    output <- NMF::purity(reference.clustering, generated.clustering)
    names(output) <- "Purity"
    # Get a lot of concurrance measures
    # https://davetang.org/muse/2017/09/21/adjusted-rand-index/
    output <- c(
      output,
      clues::adjustedRand(
        BiocGenerics::as.vector(reference.clustering),
        BiocGenerics::as.vector(generated.clustering)
      )
    )
    return(output)
  }
}

```

## Pull it all together:
```{r set inputs}
# for use in block "Run clusterings"
use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw
# for use in block "eval clusterings"
name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
```


```{r Run clusterings}
#all.dfs <- list(mrna_raw, mrna_target, mrna_cell)
#all.prefixes <- c("raw_qpcr", "target_qpcr", "cell_qpcr")


#for (JJ in seq_along(all.dfs)) {
#  if (length(all.dfs) != length(all.prefixes)) {
#    warning("Dfs and Names of inequal length!")
#  }
#  use.input.df <- all.dfs[[JJ]]
#  name.prefix <- all.prefixes[JJ]


  ## K Means Clustering =========================================================
  use.k.param <- c(11)

  temp <- map(use.k.param, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })

  param.combinations <- paste("K", as.character(
    rep(use.k.param, each = length(use.k.param))
  ), sep = ".")

  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations

  ## Hierarchical Clustering ====================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.hclust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df, 
        target.nclusters = 11,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = 10
      )
    })
  })


  param.combinations <- paste("H", as.character(
    rep(use.dist.methods, each = length(use.hclust.methods))
  ), as.character(
    rep(use.hclust.methods, times = length(use.dist.methods))
  ), sep = ".")

  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations
  ## SNN Clustering =============================================================

  use.k.param <- c(3:9)
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.

  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.k.param, function(iter.k.param) {
      print(iter.dist)

      get_SNN_clustering(
        input.df = use.input.df,
        use.k = iter.k.param, # number of neigbhors should go up to 9 for scPCRc
        use.distance = iter.dist
      ) #
    })
  })

  param.combinations <- paste("SNN", as.character(
    rep(use.dist.methods, each = length(use.k.param))
  ), as.character(
    rep(use.k.param, times = length(use.dist.methods))
  ), sep = ".")


  SNN.clusters <- do.call(cbind.data.frame, temp)
  names(SNN.clusters) <- param.combinations

  ## SCRATTCH Clustering ========================================================

  # TODO get_SCRATTCH_clustering
```

```{r eval clusterings}
  ## Merge Data Frames ==========================================================
  all.clusters <- cbind(K.clusters, H.clusters) %>% cbind(SNN.clusters) # TODO add SCRATTCH
  # some clusterings fail and assing all values zero
  # Some have a TON of clusters
  num.clusters <- map(all.clusters, function(x) {
    print(max(x))
  }) %>% unlist() # get number of clusters in each group
  real.num <- use.input.df$Cell %>% as.numeric() %>% max()
  selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.

  all.clusters <- all.clusters[, selection.vector]
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(use.input.df$Cell), all.clusters[])



  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = use.input.df$Cell, generated.clustering = iter.param)
  })

  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)

  all.clusters.scores.long <- gather(all.clusters.scores, Metric, Value, 1:6)

  ## Make plots of scores =======================================================

  score.list <- map(1:6, function(current.col) {
    # metric.labels <- c("Purity", "Rand", "HA", "MA", "FM", "Jaccard")
    metric.labels <- c("Purity", "Rand index", "Hubert and Arabie's ARI", "Morey and Agresti's ARI", "Fowlkes and Mallows's index", "Jaccard index")
    ggplot(all.clusters.scores, aes(x = Clustering, y = all.clusters.scores[, current.col])) +
      geom_point(size = 3, aes(color = all.clusters.scores[, current.col])) +
      scale_color_continuous(low = "steelblue", high = "firebrick") +
      geom_segment(aes(
        x = Clustering,
        xend = Clustering,
        y = 0,
        yend = all.clusters.scores[, current.col]
      )) +
      labs(y = metric.labels[current.col]) +
      theme(
        axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = ""
      )
  })

  # cowplot::plot_grid(plotlist = score.list)
  score.heatmap <- ggplot(all.clusters.scores.long, aes(x = Clustering, y = Metric)) +
    geom_tile(aes(fill = Value), color = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

  score.list[[length(score.list) + 1]] <- score.heatmap


  ## write out diagnostic plots =================================================

  walk(1:length(score.list), function(i) {
    plot.list <<- score.list

    ggsave(plot = plot.list[[i]], device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_", i, ".pdf"), width = 12.8, height = 8.04)
  })

  # clusters
  write.csv(all.clusters, file = paste0(write.to.dir, name.prefix, "_clusterings.csv"))
  # cluster scores
  write.csv(all.clusters.scores, file = paste0(write.to.dir, name.prefix, "_cluster_scores.csv"))
#}
```


Once we know the best clusterings...
pcr
```{r plot best pcr, eval=FALSE}
## Plot the best scoring clusters =============================================

#for pcr best are h clust with correlation and ward.d2

#"G:/MolecularCellClassification/inst/extdata/output_files/raw_qpcr_clusterings.csv"
r.df <- read.csv(paste0(write.to.dir, "raw_qpcr_clusterings.csv")) %>% as.data.frame() %>% .[,c("Cell.Type", "H.correlation.ward.D2")]
t.df <- read.csv(paste0(write.to.dir, "target_qpcr_clusterings.csv")) %>% as.data.frame() %>% .[,c("Cell.Type", "H.correlation.ward.D2")]
c.df <- read.csv(paste0(write.to.dir, "cell_qpcr_clusterings.csv")) %>% as.data.frame() %>% .[,c("Cell.Type", "H.correlation.ward.D2")]

names(r.df) <- c("Cell.Type", "H.correlation.ward.D2")
names(t.df) <- c("Cell.Type", "Scaled.mRNAs.H.correlation.ward.D2")
names(c.df) <- c("Cell.Type", "Scaled.cells.H.correlation.ward.D2")
r.df$Cell.Index <- 1:nrow(r.df)
#best.clusters$cell.index <- 1:nrow(best.clusters)
best.clusters <- full_join(r.df, t.df) %>% full_join(c.df)
best.clusters <- best.clusters %>% gather(Clustering, Group, names(best.clusters)[!(names(best.clusters) %in% c( "Cell.Index"))])

ggplot(best.clusters, aes(x=Clustering, y=Cell.Index, fill=as.factor(Group)))+
  geom_raster()+
  theme(axis.text.x=element_text(angle = 45, hjust=1), legend.position = "")

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr", "_best", ".pdf"), width = 12.8, height = 8.04)

## Plot heatmap ===============================================================
pdf(file = paste0(write.to.dir, "qpcr", "_heatmap", ".pdf"))
  heatmap3::heatmap3(mrna_raw[,-1], method = "ward.D2")
  dev.off()
  
## Plot dendrograms of best ===================================================

tree.1 <- pvclust(t(mrna_raw[,-1]),
    method.dist = "cor",
    method.hclust = "ward.D2",
    nboot = 100
  )$hclust %>% as.dendrogram() %>% 
  dendextend::set("labels_cex", 1) %>% 
  dendextend::color_branches(k = 11) %>% 
  dendextend::set("labels_col", value = 1:11, k=11) 
  #dendextend::rect.dendrogram(k=12) %>% 
as.ggdend(tree.1)

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr_raw", "_tree", ".pdf"), width = 12.8, height = 8.04)

tree.2 <- pvclust(t(mrna_target[,-1]),#FIXME
    method.dist = "cor",
    method.hclust = "ward.D2",
    nboot = 100
  )$hclust %>% as.dendrogram() %>% 
  dendextend::set("labels_cex", 1) %>% 
  dendextend::color_branches(k = 11) %>% 
  dendextend::set("labels_col", value = 1:11, k=11) 
  #dendextend::rect.dendrogram(k=12) %>% 
as.ggdend(tree.2)

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr_target", "_tree", ".pdf"), width = 12.8, height = 8.04)

```

Plotting with respect to cell id
```{r eval=FALSE, include=FALSE}
# Number cells so we get a nice plot
input.df = mrna_raw

input.df.2 <- input.df
num_in_df <- as.data.frame(count(input.df.2, Cell))
input.df.2$cell_index <- 0
for (i in 1:nrow(num_in_df)){ 
    input.df.2[input.df.2$Cell == num_in_df[i, "Cell"], "cell_index"] <- 
      seq(from = 1, to = num_in_df[i, "n"], by = 1)
}

cell_index <- as.factor(input.df.2[["cell_index"]])

input.df.2 <- input.df.2[, !(names(input.df.2) %in% c("cell_index"))]

mutate(input.df.2, cluster = as.factor(kmeans.m$cluster)) %>%
  ggplot( aes(x = Cell, y = cell_index))+
    geom_point(size = 10, shape = 15, alpha = 0.5, aes(color = cluster))+
    #scale_shape_manual(values= 1:nlevels(plot_me$cluster)) +
    scale_shape_manual(values= 1:12) +
    geom_point(size = 5, aes(shape = cluster))
```

# Cluster Estimation
```{r}
use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw

name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
```

## Scree
```{r screeplot functions}
max.k <- (nrow(use.input.df)/4) %>% ceiling() #assume at least 4 cells of the same type in each sample.

# Use map_dbl to run many models with varying value of k (centers)
tot_withinss <- map_dbl(1:max.k,  function(k){
  model <- kmeans(x = use.input.df[,-1], centers = k)
  model$tot.withinss
})

# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
  k = 1:max.k ,
  tot_withinss = tot_withinss
)

find_elbow <- elbow_df
flm <- lm(tot_withinss ~ k, data = find_elbow[c(1, nrow(find_elbow)),])

find_elbow$linear.predict <- flm$coef[[2]]*find_elbow$k + flm$coef[[1]]

#from sscClust. reproduced here because the library was not installing.
#' Find the knee point of the scree plot
#'
#' @param pcs principal component values sorted decreasingly
#' @details Given sorted decreasingly PCs, find the knee point which have the largest distance to
#' the line defined by the first point and the last point in the scree plot
#' @return index of the knee plot
findKneePoint <- function(pcs)
{
  npts <- length(pcs)
  if(npts<=3){
    return(npts)
  }else{
    P1 <- c(1,pcs[1])
    P2 <- c(npts,pcs[npts])
    v1 <- P1 - P2
    dd <- sapply(2:(npts-1),function(i){
      Pi <- c(i, pcs[i])
      v2 <- Pi - P1
      m <- cbind(v1,v2)
      d <- abs(det(m))/sqrt(sum(v1*v1))
    })
    return(which.max(dd))
  }
}

estimated.knee <- findKneePoint(find_elbow$tot_withinss)
actual.number.cell <- use.input.df$Cell %>% as.numeric() %>%  max()
```

```{r}
# Plot the elbow plot
fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="wss")+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  geom_vline(xintercept = estimated.knee, color = "steelblue", linetype = 2)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Total Within Group Sum of Squares",
       title  = paste0("Estimated Number of Clusters by Scree Plot", 
                       #"\n", as.character(estimated.knee), " Clusters Predicted", 
                       "\n", as.character(actual.number.cell), " Cell Types Present"))


ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_scree", ".pdf"), width = 12.8, height = 8.04)
```

## Silhouette
```{r}
fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="silhouette")+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Average Silhouette Width",
       title  = paste0("Estimated Number of Clusters by Silhouette", 
                       #"\n", as.character(estimated.knee), " Clusters Predicted", 
                       "\n", as.character(actual.number.cell), " Cell Types Present"))

ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_silhouette", ".pdf"), width = 12.8, height = 8.04)
#This shows the silhouettes for k=1
#pam(use.input.df[,-1], k = 11) %>% silhouette() %>% plot()
```

## Gap Statistic
```{r}
#Gap stat
set.seed(use.seed)
fviz_nbclust(use.input.df[,-1], FUNcluster = kmeans,
             k.max = max.k, method="gap_stat", 
             nstart = 25, nboot = 500)+
  geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3)+
  scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5))+
  labs(x = "Number of Clusters",
       y = "Gap Statistic (k)",
       title  = paste0("Estimated Number of Clusters by Scree Plot", 
                       #"\n", as.character(estimated.knee), " Clusters Predicted", 
                       "\n", as.character(actual.number.cell), " Cell Types Present"))

ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_gap_stat", ".pdf"), width = 12.8, height = 8.04)
```


# Supervised Machine Learning
```{r}
#use.input.df <- mrna_raw #mrna_cell #mrna_target #mrna_raw

#name.prefix <- "raw_qpcr" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
```


## Models and basic plots
```{r}
#Note: Must contain a column called "Cell"
run_supervised_models <- function(use.seed = 8743436,
                                  input.df = use.input.df){

#use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)

  
#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA
set.seed(use.seed)
ldam <- train(
  Cell ~ . ,
  data = input.df,
  method = "lda",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#return(list(knnm,ldam,nnmm,nnm,rfm,svm.rad,svm.lin))
return(list(GLMNet=glmnetm,
                          kNN=knnm,
                          LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad, 
                          SVM.Linear=svm.lin))
}



ml_models <- map(1:3, function(i){
  use.input.df <- list(mrna_cell, mrna_target, mrna_raw)
  #out <- run_supervised_models(use.seed = 8743436, input.df = use.input.df)
  run_supervised_models(use.seed = 8743436, input.df = use.input.df[[i]])

})

for(i in 1:3){

out <- ml_models[[i]]

name.prefix <- c("cell_qpcr", "target_qpcr", "raw_qpcr")

rValues <- resamples(out)

#save the accuracies for future use
write.csv(as.data.frame(rValues$values), 
          file = paste0(write.to.dir, name.prefix,"_model_accuracy.csv"), 
          row.names = FALSE)

pdf(file = paste0(write.to.dir, name.prefix[i],"_Accuracy", ".pdf"))
  bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0,1))
  dev.off()
  
pdf(file = paste0(write.to.dir, name.prefix[i],"_Kappa", ".pdf"))
  bwplot(rValues, metric="Kappa", ylab = c("Models"), xlim = c(0,1))
  dev.off()
  
}

```

Plot selected models
```{r}
out <- ml_models[[2]]

pdf(file = paste0(write.to.dir, "pcr_SVM", ".pdf"))
  varImp(out$SVM.Linear, scale=TRUE) %>%plot()
  dev.off()

pdf(file = paste0(write.to.dir, "pcr_glmnet", ".pdf"))
  varImp(out$GLMNet, scale=TRUE) %>%plot()
  dev.off()
```

# Repeat with Seq

```{r}
seq_raw <- read.csv(paste0(getwd(),"/inst/extdata/final_singleCell_kallisto_counts.csv"), row.names = "id", header = TRUE) %>% t() %>% as.data.frame()
seq_raw <- predict(preProcess(seq_raw, method = c("zv")), seq_raw)
seq_target <- predict(preProcess(seq_raw, method = c("center", "scale")), seq_raw)

seq_cell <- seq_raw
seq_cell <- as.data.frame(t(seq_cell))
seq_cell <- predict(preProcess(seq_cell, method = c("center", "scale")), seq_cell)
seq_cell <- as.data.frame(t(seq_cell))

split.names <- rownames(seq_raw) %>% strsplit("[.]")
split.names <- unlist(split.names)
Cell.ids <- split.names[seq(1, to = length(split.names), by = 2)]

seq_raw <- cbind(Cell = Cell.ids, seq_raw)
seq_target <- cbind(Cell = Cell.ids, seq_target)
seq_cell <- cbind(Cell = Cell.ids, seq_cell)
#seq_raw$Cell <- Cell.ids
#seq_target$Cell <- Cell.ids
#seq_cell$Cell <- Cell.ids


prcomp(t(seq_cell[,-1]), scale = FALSE) %>% get_eig()
prcomp(seq_cell[,-1], scale = FALSE) %>% get_eig()

#because the full seq is too much to work with locally:
seq_pca <- prcomp(seq_cell[,-1], scale = FALSE)
#pca <- prcomp(t(seq_cell[,-1]), scale = FALSE)
fviz_eig(seq_pca, addlabels = TRUE)
#plot3d(pca$x[,1:3], size = 20, labels = seq_raw$Cell, col = rainbow(4))
#play3d(spin3d(axis = c(0, 0, 1), rpm = 10), duration = 6)
factoextra::get_eigenvalue(seq_pca)

seq_pca <- cbind(seq_cell$Cell, as.data.frame(seq_pca$x))
seq_pca <- rename(seq_pca, Cell = `seq_cell$Cell`)


temp <- seq_raw[,-1]
temp <- t(temp)

x.data <- rowMeans(temp)
y.data <- matrixStats::rowVars(temp)

ggplot()+
  geom_point(aes(x = log10(x.data), y = log10(y.data)), shape = 1)

#https://hemberg-lab.github.io/scRNA.seq.course/biological-analysis.html#feature-selection

Brennecke_HVG <- M3Drop::BrenneckeGetVariableGenes(
  temp,
  fdr = 0.01,
  minBiolDisp = 0.5
)

temp <- temp[(rownames(temp) %in% Brennecke_HVG), ] 
temp <- temp %>% t()
seq_hvg <- cbind(Cell = seq_raw[,1], as.data.frame(temp))
```




```{r}
use.input.df <- seq_raw #mrna_cell #mrna_target #mrna_raw
# for use in block "eval clusterings"
name.prefix <- "raw_seq" #"cell_qpcr" #"target_qpcr" #"raw_qpcr"
```

```{r}
all.dfs <- list(seq_raw, seq_target, seq_cell, seq_hvg)
all.prefixes <- c("raw_seq", "target_seq", "cell_seq", "hvg_seq")

all.dfs <- list(seq_hvg)
all.prefixes <- c("hvg_seq")

for (JJ in seq_along(all.dfs)) {
  if (length(all.dfs) != length(all.prefixes)) {
    warning("Dfs and Names of inequal length!")
  }
  # Data Setup ------------------------------------------------------------------
  use.input.df <- all.dfs[[JJ]]
  name.prefix <- all.prefixes[JJ]
  
  # Perform clusterings ---------------------------------------------------------
  ## K Means Clustering =========================================================
  use.k.param <- c(4)
  
  temp <- map(use.k.param, function(iter.k.param) {
    get_kmeans_clustering(
      input.df = use.input.df,
      target.nclusters = iter.k.param
    )
  })
  
  param.combinations <- paste("K", as.character(
    rep(use.k.param, each = length(use.k.param))
  ), sep = ".")
  
  K.clusters <- do.call(cbind.data.frame, temp)
  names(K.clusters) <- param.combinations
  
  ## Hierarchical Clustering ====================================================
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski", "correlation", "uncentered") # flag thought this might cause trouble
  use.hclust.methods <- c("ward.D", "single", "complete", "average", "mcquitty", "median", "centroid", "ward.D2")
  
  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.hclust.methods, function(iter.hclust) {
      get_hierarchical_clustering(
        input.df = use.input.df,
        target.nclusters = 4,
        use.method.dist = iter.dist, #
        use.method.hclust = iter.hclust, #
        use.nboot = 10
      )
    })
  })
  
  
  param.combinations <- paste("H", as.character(
    rep(use.dist.methods, each = length(use.hclust.methods))
  ), as.character(
    rep(use.hclust.methods, times = length(use.dist.methods))
  ), sep = ".")
  
  H.clusters <- do.call(cbind.data.frame, temp)
  names(H.clusters) <- param.combinations
  ## SNN Clustering =============================================================
  
  use.k.param <- c(3:8) # 8 is the nubmer of the least common cell present
  use.dist.methods <- c("euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski") # Note this can't use cor and uncentered like Hclust can.
  
  temp <- map(use.dist.methods, function(iter.dist) {
    map(use.k.param, function(iter.k.param) {
      print(iter.dist)
  
      get_SNN_clustering(
        input.df = use.input.df,
        use.k = iter.k.param, #
        use.distance = iter.dist
      ) #
    })
  })
  
  param.combinations <- paste("SNN", as.character(
    rep(use.dist.methods, each = length(use.k.param))
  ), as.character(
    rep(use.k.param, times = length(use.dist.methods))
  ), sep = ".")
  
  
  SNN.clusters <- do.call(cbind.data.frame, temp)
  names(SNN.clusters) <- param.combinations
  
  
  
  # Figure and table write out --------------------------------------------------
  ## Merge Data Frames ==========================================================
  all.clusters <- cbind(K.clusters, H.clusters) %>% cbind(SNN.clusters) # TODO add SCRATTCH
  # some clusterings fail and assing all values zero
  # Some have a TON of clusters
  num.clusters <- map(all.clusters, function(x) {
    print(max(x))
  }) %>% unlist() # get number of clusters in each group
  real.num <- use.input.df$Cell %>% as.numeric() %>% max()
  selection.vector <- (num.clusters < (2 * (real.num)) & num.clusters > (floor(real.num / 2)) & num.clusters > 1) # don't consider anything above 2X the real number.
  
  all.clusters <- all.clusters[, selection.vector]
  # added for comparison; positive control
  all.clusters <- cbind(Cell.Type = as.numeric(use.input.df$Cell), all.clusters[])
  
  ## Score Clusterings ==========================================================
  temp <- map(all.clusters, function(iter.param) {
    get_cluster_comparisons(reference.clustering = use.input.df$Cell, generated.clustering = iter.param)
  })
  
  all.clusters.scores <- do.call(cbind.data.frame, temp)
  all.clusters.scores <- t(all.clusters.scores) %>% as.data.frame()
  all.clusters.scores$Clustering <- row.names(all.clusters.scores)
  
  all.clusters.scores.long <- gather(all.clusters.scores, Metric, Value, 1:6)
  
  ## Make plots of scores =======================================================
  
  score.list <- map(1:6, function(current.col) {
    # metric.labels <- c("Purity", "Rand", "HA", "MA", "FM", "Jaccard")
    metric.labels <- c("Purity", "Rand index", "Hubert and Arabie's ARI", "Morey and Agresti's ARI", "Fowlkes and Mallows's index", "Jaccard index")
    ggplot(all.clusters.scores, aes(x = Clustering, y = all.clusters.scores[, current.col])) +
      geom_point(size = 3, aes(color = all.clusters.scores[, current.col])) +
      scale_color_continuous(low = "steelblue", high = "firebrick") +
      geom_segment(aes(
        x = Clustering,
        xend = Clustering,
        y = 0,
        yend = all.clusters.scores[, current.col]
      )) +
      labs(y = metric.labels[current.col]) +
      theme(
        axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = ""
      )
  })
  
  # cowplot::plot_grid(plotlist = score.list)
  score.heatmap <- ggplot(all.clusters.scores.long, aes(x = Clustering, y = Metric)) +
    geom_tile(aes(fill = Value), color = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
  
  score.list[[length(score.list) + 1]] <- score.heatmap
  
  
  ## write out diagnostic plots =================================================
  
  walk(1:length(score.list), function(i) {
    plot.list <<- score.list
  
    ggsave(plot = plot.list[[i]], device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_", i, ".pdf"), width = 12.8, height = 8.04)
  })
  
  # clusters
  write.csv(all.clusters, file = paste0(write.to.dir, name.prefix, "_clusterings.csv"))
  # cluster scores
  write.csv(all.clusters.scores, file = paste0(write.to.dir, name.prefix, "_cluster_scores.csv"))
}
```

Once we know the best clusterings...
seq
```{r plot best pcr, eval=FALSE}
## Plot the best scoring clusters =============================================

#for pcr best are h clust with correlation and ward.d2

#"E:/MolecularCellClassification/inst/extdata/output_files/hvg_seq_clusterings.csv"
r.df <- read.csv(paste0(write.to.dir, "raw_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.euclidean.ward.D2",
  "H.maximum.ward.D2",
  "H.manhattan.ward.D2",
  "H.minkowski.ward.D2"
)]
t.df <- read.csv(paste0(write.to.dir, "target_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.canberra.ward.D"
)]
c.df <- read.csv(paste0(write.to.dir, "cell_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.canberra.ward.D"
)]
h.df <- read.csv(paste0(write.to.dir, "hvg_seq_clusterings.csv")) %>% as.data.frame() %>% .[, c(
  "Cell.Type",
  "H.correlation.mcquitty"
)]

names(r.df) <- c(
  "Cell.Type",
  "r.H.euclidean.ward.D2",
  "r.H.maximum.ward.D2",
  "r.H.manhattan.ward.D2",
  "r.H.minkowski.ward.D2"
)
names(t.df) <- c("Cell.Type", "t.H.canberra.ward.D")
names(c.df) <- c("Cell.Type", "c.H.canberra.ward.D")
names(h.df) <- c("Cell.Type", "h.H.correlation.mcquitty")

r.df$Cell.Index <- 1:nrow(r.df)
#best.clusters$cell.index <- 1:nrow(best.clusters)
best.clusters <- full_join(r.df, t.df) %>% full_join(c.df) %>% full_join(h.df)
best.clusters <- best.clusters %>% gather(Clustering, Group, names(best.clusters)[!(names(best.clusters) %in% c( "Cell.Index"))])

ggplot(best.clusters, aes(x=Clustering, y=Cell.Index, fill=as.factor(Group)))+
  geom_raster()+
  theme(axis.text.x=element_text(angle = 45, hjust=1), legend.position = "")

ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr", "_best", ".pdf"), width = 12.8, height = 8.04)

## Plot heatmap ===============================================================
pdf(file = paste0(write.to.dir, "qpcr", "_heatmap", ".pdf"))
  heatmap3::heatmap3(mrna_raw[,-1], method = "ward.D2")
  dev.off()
  
## Plot dendrograms of best ===================================================
tree.0 <- pvclust(t(seq_target[,-1]),
    method.dist = "canberra",
    method.hclust = "ward.D",
    nboot = 100
  )$hclust %>% as.dendrogram() %>% 
  dendextend::set("labels_cex", 1) %>% 
  dendextend::color_branches(k = 4) %>% 
  dendextend::set("labels_col", value = 1:4, k=4) 
  #dendextend::rect.dendrogram(k=12) %>% 
as.ggdend(tree.0)
  
  
tree.1 <- pvclust(t(seq_raw[,-1]),
    method.dist = "euclidean",
    method.hclust = "ward.D2",
    nboot = 100
  )$hclust %>% as.dendrogram() %>% 
  dendextend::set("labels_cex", 1) %>% 
  dendextend::color_branches(k = 4) %>% 
  dendextend::set("labels_col", value = 1:4, k=4) 
  #dendextend::rect.dendrogram(k=12) %>% 
as.ggdend(tree.1)


tree.2 <- pvclust(t(seq_hvg[,-1]),
    method.dist = "correlation",
    method.hclust = "mcquitty",
    nboot = 100
  )$hclust %>% as.dendrogram() %>% 
  dendextend::set("labels_cex", 1) %>% 
  dendextend::color_branches(k = 4) %>% 
  dendextend::set("labels_col", value = 1:4, k=4) 
  #dendextend::rect.dendrogram(k=12) %>% 
as.ggdend(tree.2)


ggsave(device = "pdf", path = write.to.dir, filename = paste0("qpcr_raw", "_tree", ".pdf"), width = 12.8, height = 8.04)



```


## DJS want screeplots and ML for scaled by cell data:
```{r}
#diff_0.05 <- read.csv(paste0(getwd(),"/inst/extdata/annotated_pooled_0.05_names.csv"), header=F)
#diff_0.20 <- read.csv(paste0(getwd(), "/inst/extdata/annotated_pooled_0.2_names.csv"), header=F)
diff_0.05 <- read.csv(paste0(getwd(),"/inst/extdata/kallisto_0.05.csv"), header=F)
diff_0.2 <- read.csv(paste0(getwd(), "/inst/extdata/kallisto_0.2.csv"), header=F)

## our inputs: ================================================================
#seq_cell
diff_0.05 <- seq_cell[, diff_0.05$V1]
diff_0.2 <- seq_cell[, diff_0.2$V1]
```


### Screeplots
```{r}
#from sscClust. reproduced here because the library was not installing.
#' Find the knee point of the scree plot
#'
#' @param pcs principal component values sorted decreasingly
#' @details Given sorted decreasingly PCs, find the knee point which have the largest distance to
#' the line defined by the first point and the last point in the scree plot
#' @return index of the knee plot
findKneePoint <- function(pcs){
  npts <- length(pcs)
  if(npts<=3){
    return(npts)
  }else{
    P1 <- c(1,pcs[1])
    P2 <- c(npts,pcs[npts])
    v1 <- P1 - P2
    dd <- sapply(2:(npts-1),function(i){
      Pi <- c(i, pcs[i])
      v2 <- Pi - P1
      m <- cbind(v1,v2)
      d <- abs(det(m))/sqrt(sum(v1*v1))
    })
    return(which.max(dd))
  }
}

for (test.dfs in 1:3){
  print(test.dfs)
  all.input.dfs <- list(seq_cell, diff_0.2, diff_0.05)
  all.name.prefixs <- c("seq_cell", "diff_0.2", "diff_0.05")

  use.input.df <- all.input.dfs[[test.dfs]]
  name.prefix <- all.name.prefixs[test.dfs]

  # scree
  max.k <- (nrow(use.input.df) / 4) %>% ceiling() # assume at least 4 cells of the same type in each sample.

  # Use map_dbl to run many models with varying value of k (centers)
  tot_withinss <- map_dbl(seq(from = 1, to = max.k), function(k) {
    model <- kmeans(x = use.input.df[, !(names(use.input.df) %in% c("Cell"))], centers = k)
    model$tot.withinss
  })

  # Generate a data frame containing both k and tot_withinss
  elbow_df <- data.frame(
    k = 1:max.k,
    tot_withinss = tot_withinss
  )

  find_elbow <- elbow_df
  flm <- lm(tot_withinss ~ k, data = find_elbow[c(1, nrow(find_elbow)), ])

  find_elbow$linear.predict <- flm$coef[[2]] * find_elbow$k + flm$coef[[1]]


  estimated.knee <- findKneePoint(find_elbow$tot_withinss)
  actual.number.cell <- use.input.df$Cell %>% as.numeric() %>% max()


  # Plot the elbow plot
  fviz_nbclust(use.input.df[, !(names(use.input.df) %in% c("Cell"))],
    FUNcluster = kmeans,
    k.max = max.k, method = "wss"
  ) +
    geom_vline(xintercept = actual.number.cell, color = "firebrick", linetype = 3) +
    geom_vline(xintercept = estimated.knee, color = "steelblue", linetype = 2) +
    scale_x_discrete(breaks = seq(from = 0, to = max.k, by = 5)) +
    labs(
      x = "Number of Clusters",
      y = "Total Within Group Sum of Squares",
      title = paste0(
        "Estimated Number of Clusters by Scree Plot",
        # "\n", as.character(estimated.knee), " Clusters Predicted",
        "\n", as.character(actual.number.cell), " Cell Types Present"
      )
    )

  ggsave(device = "pdf", path = write.to.dir, filename = paste0(name.prefix, "_scree", ".pdf"), width = 12.8, height = 8.04)
}
```


```{r}
use.seed = 8743436
input.df <- seq_pca
use.cv <- 5


use.seed = 8743436
input.df = seq_pca

#use.seed = 8743436
#input.df = mrna_target

set.seed(use.seed)
glmnetm <- train(
  Cell ~ ., input.df,
  metric = "Accuracy",
  method = "glmnet",
  tuneGrid = expand.grid(
    alpha = seq(0, 1, length = 5),
    lambda = seq(0.0001, 1, length = 100)
  ),
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)
# Plot the results
#plot(glmnetm)

  
#kNN
set.seed(use.seed)
knnm <- train(
  Cell ~ . ,
  tuneGrid = expand.grid(k = seq(from =1, to =20, by = 1)),
  #tuneLength = 20,
  data = input.df,
  method = "knn",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(knnm)
#print(max(knnm$results$Accuracy, na.rm = T))

#LDA
set.seed(use.seed)
ldam <- train(
  Cell ~ . ,
  data = input.df,
  method = "lda",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(ldam)

#neural networks
set.seed(use.seed)
nnmm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(decay = seq(from = 0.1, to = 1, by = 0.05)),
  method = "multinom",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnmm)
#print(max(nnmm$results$Accuracy, na.rm = T)) #81% accuracy

set.seed(use.seed)
nnm <- train(
  Cell ~ . ,
  data = input.df,
  tuneGrid = expand.grid(size = seq(from = 1, to = 12, by = 1),
                        decay = seq(from = 0.1, to = 1.0, by = 0.2)),
  method = "nnet",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#plot(nnm)
#print(max(nnm$results$Accuracy, na.rm = T))

#random forest
max.mtry = 30
set.seed(use.seed)
rfm <- train(
  Cell ~ . ,
  #tuneLength = 3,
  tuneGrid = data.frame(mtry = rep(seq(1, max.mtry, by = 1), times = 2), #mtry can be any number from 2 to the number of columns
                        splitrule = rep(c("extratrees", "gini"), each = max.mtry), #the docs make it look like these are the two to use for classification
                        min.node.size = rep(2, each = (max.mtry*2))),
  data = input.df,
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#print(rfm)
#plot(rfm)
#print(max(rfm$results$Accuracy, na.rm = T))

#svm
set.seed(use.seed)
svm.rad <- train(
  Cell ~ .,
  tuneGrid = expand.grid(sigma = seq(from = 0.001, to = 0.5, by = 0.01),
                    C = seq(from = 0.5, to = 5.5, by = 1)),
  data = input.df,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#svm.rad
#plot(svm.rad)
#print(max(svm.rad$results$Accuracy, na.rm = T))

set.seed(use.seed)
svm.lin <- train(
  Cell ~ .,
  tuneGrid = expand.grid(cost = seq(from = 0.001, to = 0.5, by = 0.01)),
  data = input.df,
  method = "svmLinear2",
  trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE)
)

#return(list(knnm,ldam,nnmm,nnm,rfm,svm.rad,svm.lin))
out_pca <- list(GLMNet=glmnetm,
                          kNN=knnm,
                          #LDA=ldam,
                          NNet=nnm,
                          NNet.Multinom=nnmm,
                          Rand.Forest=rfm,
                          SVM.Radial=svm.rad, 
                          SVM.Linear=svm.lin)





#run_supervised_models(use.seed = 8743436, input.df = (seq_cell))
out_pca <- run_supervised_models(use.seed = 8743436, input.df = seq_pca[, 1:38])
out_0.2 <- run_supervised_models(use.seed = 8743436, input.df = diff_0.2)
out_0.05 <- run_supervised_models(use.seed = 8743436, input.df = diff_0.05)

ml_models <- list(out_pca)

for(i in 1:length(ml_models)){

out <- ml_models[[i]]

name.prefix <- c("pca_seq", "", "")[i]

rValues <- resamples(out)
bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0, 1))


#save the accuracies for future use
write.csv(as.data.frame(rValues$values), 
          file = paste0(write.to.dir, name.prefix,"_model_accuracy.csv"), 
          row.names = FALSE)

pdf(file = paste0(write.to.dir, name.prefix,"_Accuracy", ".pdf"))
  bwplot(rValues, metric = "Accuracy", ylab = c("Models"), xlim = c(0,1))
  dev.off()
  
pdf(file = paste0(write.to.dir, name.prefix,"_Kappa", ".pdf"))
  bwplot(rValues, metric="Kappa", ylab = c("Models"), xlim = c(0,1))
  dev.off()
  
}
```

